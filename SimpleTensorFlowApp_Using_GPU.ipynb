{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ead47c0-ce83-4833-ad89-452d635ae203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b6d3435-31b8-4ffc-ae46-6d18cfe58619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data from sklearn\n",
    "breast_cancer_dataset = sklearn.datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ca3b77b-cc3b-4b65-a4f1-e77606ff20fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e502f9a-5d1a-46c5-ade2-d1b5d03f1e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
      "        1.189e-01],\n",
      "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
      "        8.902e-02],\n",
      "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
      "        8.758e-02],\n",
      "       ...,\n",
      "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
      "        7.820e-02],\n",
      "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
      "        1.240e-01],\n",
      "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
      "        7.039e-02]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
      "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
      "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
      "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
      "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
      "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
      "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), 'frame': None, 'target_names': array(['malignant', 'benign'], dtype='<U9'), 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry\\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        worst/largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 0 is Mean Radius, field\\n        10 is Radius SE, field 20 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n|details-start|\\n**References**\\n|details-split|\\n\\n- W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n  for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n  Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n  San Jose, CA, 1993.\\n- O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n  prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n  July-August 1995.\\n- W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n  to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n  163-171.\\n\\n|details-end|', 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
      "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
      "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
      "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
      "       'smoothness error', 'compactness error', 'concavity error',\n",
      "       'concave points error', 'symmetry error',\n",
      "       'fractal dimension error', 'worst radius', 'worst texture',\n",
      "       'worst perimeter', 'worst area', 'worst smoothness',\n",
      "       'worst compactness', 'worst concavity', 'worst concave points',\n",
      "       'worst symmetry', 'worst fractal dimension'], dtype='<U23'), 'filename': 'breast_cancer.csv', 'data_module': 'sklearn.datasets.data'}\n"
     ]
    }
   ],
   "source": [
    "print(breast_cancer_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b0ccd14-0fd4-4935-92f1-14d47e6d6bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the data to a data frame\n",
    "data_frame = pd.DataFrame(breast_cancer_dataset.data, columns = breast_cancer_dataset.feature_names)\n",
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e767575-05dd-4a44-99e1-321b7f1c1cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the 'target' column to the data frame\n",
    "data_frame['label'] = breast_cancer_dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b69569ba-7e20-49e3-819a-2c0b6d3b5fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "564                 0.05623  ...          26.40           166.10      2027.0   \n",
       "565                 0.05533  ...          38.25           155.00      1731.0   \n",
       "566                 0.05648  ...          34.12           126.70      1124.0   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "568                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  label  \n",
       "564                0.2216          0.2060                  0.07115      0  \n",
       "565                0.1628          0.2572                  0.06637      0  \n",
       "566                0.1418          0.2218                  0.07820      0  \n",
       "567                0.2650          0.4087                  0.12400      0  \n",
       "568                0.0000          0.2871                  0.07039      1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print last 5 rows of the dataframe\n",
    "data_frame.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e956cf6-a8be-468e-9337-bd1a590d0ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
      " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
      " 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1\n",
      " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
      " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(breast_cancer_dataset.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d96e4c8d-a6dc-4953-a915-d8ca20eab45d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 31)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53cf7612-db6f-43f4-a570-a3fa08ffdcc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   mean radius              569 non-null    float64\n",
      " 1   mean texture             569 non-null    float64\n",
      " 2   mean perimeter           569 non-null    float64\n",
      " 3   mean area                569 non-null    float64\n",
      " 4   mean smoothness          569 non-null    float64\n",
      " 5   mean compactness         569 non-null    float64\n",
      " 6   mean concavity           569 non-null    float64\n",
      " 7   mean concave points      569 non-null    float64\n",
      " 8   mean symmetry            569 non-null    float64\n",
      " 9   mean fractal dimension   569 non-null    float64\n",
      " 10  radius error             569 non-null    float64\n",
      " 11  texture error            569 non-null    float64\n",
      " 12  perimeter error          569 non-null    float64\n",
      " 13  area error               569 non-null    float64\n",
      " 14  smoothness error         569 non-null    float64\n",
      " 15  compactness error        569 non-null    float64\n",
      " 16  concavity error          569 non-null    float64\n",
      " 17  concave points error     569 non-null    float64\n",
      " 18  symmetry error           569 non-null    float64\n",
      " 19  fractal dimension error  569 non-null    float64\n",
      " 20  worst radius             569 non-null    float64\n",
      " 21  worst texture            569 non-null    float64\n",
      " 22  worst perimeter          569 non-null    float64\n",
      " 23  worst area               569 non-null    float64\n",
      " 24  worst smoothness         569 non-null    float64\n",
      " 25  worst compactness        569 non-null    float64\n",
      " 26  worst concavity          569 non-null    float64\n",
      " 27  worst concave points     569 non-null    float64\n",
      " 28  worst symmetry           569 non-null    float64\n",
      " 29  worst fractal dimension  569 non-null    float64\n",
      " 30  label                    569 non-null    int32  \n",
      "dtypes: float64(30), int32(1)\n",
      "memory usage: 135.7 KB\n"
     ]
    }
   ],
   "source": [
    "data_frame.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2859f4bd-5303-4ba4-904a-dd67f2c4287e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean radius                0\n",
       "mean texture               0\n",
       "mean perimeter             0\n",
       "mean area                  0\n",
       "mean smoothness            0\n",
       "mean compactness           0\n",
       "mean concavity             0\n",
       "mean concave points        0\n",
       "mean symmetry              0\n",
       "mean fractal dimension     0\n",
       "radius error               0\n",
       "texture error              0\n",
       "perimeter error            0\n",
       "area error                 0\n",
       "smoothness error           0\n",
       "compactness error          0\n",
       "concavity error            0\n",
       "concave points error       0\n",
       "symmetry error             0\n",
       "fractal dimension error    0\n",
       "worst radius               0\n",
       "worst texture              0\n",
       "worst perimeter            0\n",
       "worst area                 0\n",
       "worst smoothness           0\n",
       "worst compactness          0\n",
       "worst concavity            0\n",
       "worst concave points       0\n",
       "worst symmetry             0\n",
       "worst fractal dimension    0\n",
       "label                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04cae360-a9eb-469c-9915-72e6ae19846b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>...</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "      <td>0.627417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>...</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>0.483918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>...</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>...</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>...</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>...</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>...</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean radius  mean texture  mean perimeter    mean area  \\\n",
       "count   569.000000    569.000000      569.000000   569.000000   \n",
       "mean     14.127292     19.289649       91.969033   654.889104   \n",
       "std       3.524049      4.301036       24.298981   351.914129   \n",
       "min       6.981000      9.710000       43.790000   143.500000   \n",
       "25%      11.700000     16.170000       75.170000   420.300000   \n",
       "50%      13.370000     18.840000       86.240000   551.100000   \n",
       "75%      15.780000     21.800000      104.100000   782.700000   \n",
       "max      28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       mean symmetry  mean fractal dimension  ...  worst texture  \\\n",
       "count     569.000000              569.000000  ...     569.000000   \n",
       "mean        0.181162                0.062798  ...      25.677223   \n",
       "std         0.027414                0.007060  ...       6.146258   \n",
       "min         0.106000                0.049960  ...      12.020000   \n",
       "25%         0.161900                0.057700  ...      21.080000   \n",
       "50%         0.179200                0.061540  ...      25.410000   \n",
       "75%         0.195700                0.066120  ...      29.720000   \n",
       "max         0.304000                0.097440  ...      49.540000   \n",
       "\n",
       "       worst perimeter   worst area  worst smoothness  worst compactness  \\\n",
       "count       569.000000   569.000000        569.000000         569.000000   \n",
       "mean        107.261213   880.583128          0.132369           0.254265   \n",
       "std          33.602542   569.356993          0.022832           0.157336   \n",
       "min          50.410000   185.200000          0.071170           0.027290   \n",
       "25%          84.110000   515.300000          0.116600           0.147200   \n",
       "50%          97.660000   686.500000          0.131300           0.211900   \n",
       "75%         125.400000  1084.000000          0.146000           0.339100   \n",
       "max         251.200000  4254.000000          0.222600           1.058000   \n",
       "\n",
       "       worst concavity  worst concave points  worst symmetry  \\\n",
       "count       569.000000            569.000000      569.000000   \n",
       "mean          0.272188              0.114606        0.290076   \n",
       "std           0.208624              0.065732        0.061867   \n",
       "min           0.000000              0.000000        0.156500   \n",
       "25%           0.114500              0.064930        0.250400   \n",
       "50%           0.226700              0.099930        0.282200   \n",
       "75%           0.382900              0.161400        0.317900   \n",
       "max           1.252000              0.291000        0.663800   \n",
       "\n",
       "       worst fractal dimension       label  \n",
       "count               569.000000  569.000000  \n",
       "mean                  0.083946    0.627417  \n",
       "std                   0.018061    0.483918  \n",
       "min                   0.055040    0.000000  \n",
       "25%                   0.071460    0.000000  \n",
       "50%                   0.080040    1.000000  \n",
       "75%                   0.092080    1.000000  \n",
       "max                   0.207500    1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statistical measures about the data\n",
    "data_frame.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd7be37c-9cbd-4faa-b1d0-25c259f74d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    357\n",
       "0    212\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the distribution of Target Varibale\n",
    "data_frame['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b482c26-9a5a-43bd-8e9f-d4d968d22707",
   "metadata": {},
   "source": [
    "1 --> Benign (Not suffering from Cancer/ No Cancer detected)\n",
    "\n",
    "0 --> Malignant (suffering from Cancer/ Cancer detected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "670f9b3a-f0e4-4a2c-85eb-25783d4000a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_frame.drop(columns='label', axis=1)\n",
    "Y = data_frame['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef7d7fcc-bdcf-48c0-a9d1-e47576f0c272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 30 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   mean radius              569 non-null    float64\n",
      " 1   mean texture             569 non-null    float64\n",
      " 2   mean perimeter           569 non-null    float64\n",
      " 3   mean area                569 non-null    float64\n",
      " 4   mean smoothness          569 non-null    float64\n",
      " 5   mean compactness         569 non-null    float64\n",
      " 6   mean concavity           569 non-null    float64\n",
      " 7   mean concave points      569 non-null    float64\n",
      " 8   mean symmetry            569 non-null    float64\n",
      " 9   mean fractal dimension   569 non-null    float64\n",
      " 10  radius error             569 non-null    float64\n",
      " 11  texture error            569 non-null    float64\n",
      " 12  perimeter error          569 non-null    float64\n",
      " 13  area error               569 non-null    float64\n",
      " 14  smoothness error         569 non-null    float64\n",
      " 15  compactness error        569 non-null    float64\n",
      " 16  concavity error          569 non-null    float64\n",
      " 17  concave points error     569 non-null    float64\n",
      " 18  symmetry error           569 non-null    float64\n",
      " 19  fractal dimension error  569 non-null    float64\n",
      " 20  worst radius             569 non-null    float64\n",
      " 21  worst texture            569 non-null    float64\n",
      " 22  worst perimeter          569 non-null    float64\n",
      " 23  worst area               569 non-null    float64\n",
      " 24  worst smoothness         569 non-null    float64\n",
      " 25  worst compactness        569 non-null    float64\n",
      " 26  worst concavity          569 non-null    float64\n",
      " 27  worst concave points     569 non-null    float64\n",
      " 28  worst symmetry           569 non-null    float64\n",
      " 29  worst fractal dimension  569 non-null    float64\n",
      "dtypes: float64(30)\n",
      "memory usage: 133.5 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e09ecb60-91fe-4ecb-8a1f-6f10814ce921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Series name: label\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "569 non-null    int32\n",
      "dtypes: int32(1)\n",
      "memory usage: 2.3 KB\n"
     ]
    }
   ],
   "source": [
    "Y.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e324eeb-4da5-427c-99a4-f58c14f22753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "564    0\n",
      "565    0\n",
      "566    0\n",
      "567    0\n",
      "568    1\n",
      "Name: label, Length: 569, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4660a9bc-f2f4-4872-a702-bb9990ba5961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
      "0          17.99         10.38          122.80     1001.0          0.11840   \n",
      "1          20.57         17.77          132.90     1326.0          0.08474   \n",
      "2          19.69         21.25          130.00     1203.0          0.10960   \n",
      "3          11.42         20.38           77.58      386.1          0.14250   \n",
      "4          20.29         14.34          135.10     1297.0          0.10030   \n",
      "..           ...           ...             ...        ...              ...   \n",
      "564        21.56         22.39          142.00     1479.0          0.11100   \n",
      "565        20.13         28.25          131.20     1261.0          0.09780   \n",
      "566        16.60         28.08          108.30      858.1          0.08455   \n",
      "567        20.60         29.33          140.10     1265.0          0.11780   \n",
      "568         7.76         24.54           47.92      181.0          0.05263   \n",
      "\n",
      "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
      "0             0.27760         0.30010              0.14710         0.2419   \n",
      "1             0.07864         0.08690              0.07017         0.1812   \n",
      "2             0.15990         0.19740              0.12790         0.2069   \n",
      "3             0.28390         0.24140              0.10520         0.2597   \n",
      "4             0.13280         0.19800              0.10430         0.1809   \n",
      "..                ...             ...                  ...            ...   \n",
      "564           0.11590         0.24390              0.13890         0.1726   \n",
      "565           0.10340         0.14400              0.09791         0.1752   \n",
      "566           0.10230         0.09251              0.05302         0.1590   \n",
      "567           0.27700         0.35140              0.15200         0.2397   \n",
      "568           0.04362         0.00000              0.00000         0.1587   \n",
      "\n",
      "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
      "0                   0.07871  ...        25.380          17.33   \n",
      "1                   0.05667  ...        24.990          23.41   \n",
      "2                   0.05999  ...        23.570          25.53   \n",
      "3                   0.09744  ...        14.910          26.50   \n",
      "4                   0.05883  ...        22.540          16.67   \n",
      "..                      ...  ...           ...            ...   \n",
      "564                 0.05623  ...        25.450          26.40   \n",
      "565                 0.05533  ...        23.690          38.25   \n",
      "566                 0.05648  ...        18.980          34.12   \n",
      "567                 0.07016  ...        25.740          39.42   \n",
      "568                 0.05884  ...         9.456          30.37   \n",
      "\n",
      "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
      "0             184.60      2019.0           0.16220            0.66560   \n",
      "1             158.80      1956.0           0.12380            0.18660   \n",
      "2             152.50      1709.0           0.14440            0.42450   \n",
      "3              98.87       567.7           0.20980            0.86630   \n",
      "4             152.20      1575.0           0.13740            0.20500   \n",
      "..               ...         ...               ...                ...   \n",
      "564           166.10      2027.0           0.14100            0.21130   \n",
      "565           155.00      1731.0           0.11660            0.19220   \n",
      "566           126.70      1124.0           0.11390            0.30940   \n",
      "567           184.60      1821.0           0.16500            0.86810   \n",
      "568            59.16       268.6           0.08996            0.06444   \n",
      "\n",
      "     worst concavity  worst concave points  worst symmetry  \\\n",
      "0             0.7119                0.2654          0.4601   \n",
      "1             0.2416                0.1860          0.2750   \n",
      "2             0.4504                0.2430          0.3613   \n",
      "3             0.6869                0.2575          0.6638   \n",
      "4             0.4000                0.1625          0.2364   \n",
      "..               ...                   ...             ...   \n",
      "564           0.4107                0.2216          0.2060   \n",
      "565           0.3215                0.1628          0.2572   \n",
      "566           0.3403                0.1418          0.2218   \n",
      "567           0.9387                0.2650          0.4087   \n",
      "568           0.0000                0.0000          0.2871   \n",
      "\n",
      "     worst fractal dimension  \n",
      "0                    0.11890  \n",
      "1                    0.08902  \n",
      "2                    0.08758  \n",
      "3                    0.17300  \n",
      "4                    0.07678  \n",
      "..                       ...  \n",
      "564                  0.07115  \n",
      "565                  0.06637  \n",
      "566                  0.07820  \n",
      "567                  0.12400  \n",
      "568                  0.07039  \n",
      "\n",
      "[569 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ba75e12-9502-4acb-a020-b6d606b608a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23840864-00b0-4336-b614-f5c5e4c5b7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30) (455, 30) (114, 30)\n",
      "(569,) (455,) (114,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, X_train.shape, X_test.shape)\n",
    "print(Y.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d60e780-1123-45df-ac9b-c63ee645bb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "956321ed-ad93-47c4-bcf9-79524741e346",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test_std = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a063440-5323-44c9-8566-438449ff520e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 30) (114, 30)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_std.shape, X_test_std.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f8b35f24-8f6d-44df-895f-a64404d7991e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing tensorflow and Keras\n",
    "import tensorflow as tf \n",
    "tf.random.set_seed(3)\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e668b8d1-4e10-404b-a69b-e3c1a551e244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPU devices:\n",
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the index of the GPU device you want to use (or press Enter to use CPU):  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU device 0.\n"
     ]
    }
   ],
   "source": [
    "# Check available devices\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if len(physical_devices) == 0:\n",
    "    print(\"No GPU devices available, using CPU.\")\n",
    "else:\n",
    "    print(\"Available GPU devices:\")\n",
    "    for device in physical_devices:\n",
    "        print(device)\n",
    "\n",
    "# Choose GPU device (if available)\n",
    "gpu_index = input(\"Enter the index of the GPU device you want to use (or press Enter to use CPU): \")\n",
    "if gpu_index and gpu_index.isdigit() and int(gpu_index) < len(physical_devices):\n",
    "    gpu_index = int(gpu_index)\n",
    "    tf.config.experimental.set_visible_devices(physical_devices[gpu_index], 'GPU')\n",
    "    print(f\"Using GPU device {gpu_index}.\")\n",
    "else:\n",
    "    print(\"Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5372f5b1-42e4-4fd3-ad26-d8515203eb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "                          keras.layers.Flatten(input_shape=(30,)),\n",
    "                          keras.layers.Dense(20, activation='relu'),\n",
    "                          keras.layers.Dense(2, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0606785a-15ac-4087-8028-3bcba3a76566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the Neural Network\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c87213fc-fd92-4855-853f-0cd3c941dce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.1011 - accuracy: 0.9804 - val_loss: 0.1007 - val_accuracy: 0.9565\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0887 - accuracy: 0.9829 - val_loss: 0.0925 - val_accuracy: 0.9565\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0799 - accuracy: 0.9829 - val_loss: 0.0869 - val_accuracy: 0.9565\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0741 - accuracy: 0.9829 - val_loss: 0.0828 - val_accuracy: 0.9565\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0690 - accuracy: 0.9878 - val_loss: 0.0797 - val_accuracy: 0.9565\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0649 - accuracy: 0.9878 - val_loss: 0.0777 - val_accuracy: 0.9565\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0616 - accuracy: 0.9878 - val_loss: 0.0759 - val_accuracy: 0.9565\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0587 - accuracy: 0.9878 - val_loss: 0.0749 - val_accuracy: 0.9565\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0562 - accuracy: 0.9878 - val_loss: 0.0733 - val_accuracy: 0.9565\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0542 - accuracy: 0.9878 - val_loss: 0.0734 - val_accuracy: 0.9565\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0521 - accuracy: 0.9878 - val_loss: 0.0728 - val_accuracy: 0.9565\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0502 - accuracy: 0.9878 - val_loss: 0.0721 - val_accuracy: 0.9565\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0488 - accuracy: 0.9878 - val_loss: 0.0706 - val_accuracy: 0.9565\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0473 - accuracy: 0.9878 - val_loss: 0.0699 - val_accuracy: 0.9565\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0458 - accuracy: 0.9878 - val_loss: 0.0689 - val_accuracy: 0.9348\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0446 - accuracy: 0.9878 - val_loss: 0.0682 - val_accuracy: 0.9348\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0433 - accuracy: 0.9878 - val_loss: 0.0673 - val_accuracy: 0.9348\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0421 - accuracy: 0.9878 - val_loss: 0.0663 - val_accuracy: 0.9565\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0413 - accuracy: 0.9878 - val_loss: 0.0643 - val_accuracy: 0.9565\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0399 - accuracy: 0.9878 - val_loss: 0.0645 - val_accuracy: 0.9565\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0390 - accuracy: 0.9878 - val_loss: 0.0647 - val_accuracy: 0.9565\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0377 - accuracy: 0.9902 - val_loss: 0.0643 - val_accuracy: 0.9348\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0367 - accuracy: 0.9902 - val_loss: 0.0635 - val_accuracy: 0.9565\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0361 - accuracy: 0.9902 - val_loss: 0.0643 - val_accuracy: 0.9348\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0348 - accuracy: 0.9902 - val_loss: 0.0632 - val_accuracy: 0.9565\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0341 - accuracy: 0.9902 - val_loss: 0.0633 - val_accuracy: 0.9565\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0333 - accuracy: 0.9902 - val_loss: 0.0628 - val_accuracy: 0.9565\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0325 - accuracy: 0.9902 - val_loss: 0.0628 - val_accuracy: 0.9565\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0317 - accuracy: 0.9902 - val_loss: 0.0622 - val_accuracy: 0.9565\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0307 - accuracy: 0.9902 - val_loss: 0.0613 - val_accuracy: 0.9565\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0301 - accuracy: 0.9902 - val_loss: 0.0610 - val_accuracy: 0.9565\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0294 - accuracy: 0.9902 - val_loss: 0.0613 - val_accuracy: 0.9565\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0289 - accuracy: 0.9902 - val_loss: 0.0606 - val_accuracy: 0.9565\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0284 - accuracy: 0.9902 - val_loss: 0.0604 - val_accuracy: 0.9565\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0275 - accuracy: 0.9902 - val_loss: 0.0618 - val_accuracy: 0.9565\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0268 - accuracy: 0.9902 - val_loss: 0.0610 - val_accuracy: 0.9565\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0262 - accuracy: 0.9902 - val_loss: 0.0608 - val_accuracy: 0.9565\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0255 - accuracy: 0.9902 - val_loss: 0.0609 - val_accuracy: 0.9565\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0250 - accuracy: 0.9902 - val_loss: 0.0605 - val_accuracy: 0.9565\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0245 - accuracy: 0.9902 - val_loss: 0.0600 - val_accuracy: 0.9565\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0242 - accuracy: 0.9902 - val_loss: 0.0607 - val_accuracy: 0.9565\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0238 - accuracy: 0.9902 - val_loss: 0.0604 - val_accuracy: 0.9565\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0229 - accuracy: 0.9902 - val_loss: 0.0605 - val_accuracy: 0.9565\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0225 - accuracy: 0.9927 - val_loss: 0.0597 - val_accuracy: 0.9565\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0218 - accuracy: 0.9927 - val_loss: 0.0600 - val_accuracy: 0.9565\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0215 - accuracy: 0.9927 - val_loss: 0.0597 - val_accuracy: 0.9565\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0210 - accuracy: 0.9951 - val_loss: 0.0601 - val_accuracy: 0.9565\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0205 - accuracy: 0.9951 - val_loss: 0.0605 - val_accuracy: 0.9565\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0200 - accuracy: 0.9951 - val_loss: 0.0599 - val_accuracy: 0.9565\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0195 - accuracy: 0.9951 - val_loss: 0.0600 - val_accuracy: 0.9565\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0193 - accuracy: 0.9951 - val_loss: 0.0602 - val_accuracy: 0.9565\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0188 - accuracy: 0.9951 - val_loss: 0.0609 - val_accuracy: 0.9565\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0183 - accuracy: 0.9951 - val_loss: 0.0602 - val_accuracy: 0.9565\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0180 - accuracy: 0.9951 - val_loss: 0.0606 - val_accuracy: 0.9565\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - accuracy: 0.9951 - val_loss: 0.0601 - val_accuracy: 0.9565\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - accuracy: 0.9951 - val_loss: 0.0611 - val_accuracy: 0.9565\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - accuracy: 0.9951 - val_loss: 0.0609 - val_accuracy: 0.9565\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - accuracy: 0.9951 - val_loss: 0.0611 - val_accuracy: 0.9565\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 0.9976 - val_loss: 0.0613 - val_accuracy: 0.9565\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0161 - accuracy: 0.9976 - val_loss: 0.0599 - val_accuracy: 0.9565\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0156 - accuracy: 0.9976 - val_loss: 0.0607 - val_accuracy: 0.9565\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - accuracy: 0.9976 - val_loss: 0.0620 - val_accuracy: 0.9565\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.9976 - val_loss: 0.0611 - val_accuracy: 0.9565\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.9976 - val_loss: 0.0608 - val_accuracy: 0.9565\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9976 - val_loss: 0.0605 - val_accuracy: 0.9565\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 0.9976 - val_loss: 0.0604 - val_accuracy: 0.9565\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - accuracy: 0.9976 - val_loss: 0.0614 - val_accuracy: 0.9565\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - accuracy: 0.9976 - val_loss: 0.0622 - val_accuracy: 0.9565\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - accuracy: 0.9976 - val_loss: 0.0635 - val_accuracy: 0.9565\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0132 - accuracy: 0.9976 - val_loss: 0.0618 - val_accuracy: 0.9565\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - accuracy: 0.9976 - val_loss: 0.0595 - val_accuracy: 0.9565\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - accuracy: 0.9976 - val_loss: 0.0604 - val_accuracy: 0.9565\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 0.9976 - val_loss: 0.0609 - val_accuracy: 0.9565\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0121 - accuracy: 0.9976 - val_loss: 0.0605 - val_accuracy: 0.9565\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 0.9976 - val_loss: 0.0605 - val_accuracy: 0.9565\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0116 - accuracy: 0.9976 - val_loss: 0.0616 - val_accuracy: 0.9565\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9976 - val_loss: 0.0615 - val_accuracy: 0.9565\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 0.9976 - val_loss: 0.0611 - val_accuracy: 0.9565\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 0.9976 - val_loss: 0.0617 - val_accuracy: 0.9565\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0107 - accuracy: 0.9976 - val_loss: 0.0621 - val_accuracy: 0.9565\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9976 - val_loss: 0.0610 - val_accuracy: 0.9565\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0103 - accuracy: 0.9976 - val_loss: 0.0622 - val_accuracy: 0.9565\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0101 - accuracy: 0.9976 - val_loss: 0.0619 - val_accuracy: 0.9565\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0099 - accuracy: 0.9976 - val_loss: 0.0621 - val_accuracy: 0.9565\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 0.9976 - val_loss: 0.0623 - val_accuracy: 0.9565\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 0.9976 - val_loss: 0.0618 - val_accuracy: 0.9565\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 0.9976 - val_loss: 0.0628 - val_accuracy: 0.9565\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0092 - accuracy: 0.9976 - val_loss: 0.0623 - val_accuracy: 0.9565\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0090 - accuracy: 0.9976 - val_loss: 0.0625 - val_accuracy: 0.9565\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0088 - accuracy: 0.9976 - val_loss: 0.0628 - val_accuracy: 0.9565\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 0.0631 - val_accuracy: 0.9565\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.0627 - val_accuracy: 0.9565\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.0632 - val_accuracy: 0.9565\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.0633 - val_accuracy: 0.9565\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.0633 - val_accuracy: 0.9565\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.0647 - val_accuracy: 0.9565\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.0642 - val_accuracy: 0.9565\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.0655 - val_accuracy: 0.9565\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.0652 - val_accuracy: 0.9565\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.0645 - val_accuracy: 0.9565\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.0647 - val_accuracy: 0.9565\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.0644 - val_accuracy: 0.9565\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.0643 - val_accuracy: 0.9565\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.0649 - val_accuracy: 0.9565\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 0.9976 - val_loss: 0.0654 - val_accuracy: 0.9565\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0658 - val_accuracy: 0.9565\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0664 - val_accuracy: 0.9565\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0645 - val_accuracy: 0.9565\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0657 - val_accuracy: 0.9565\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 0.9976 - val_loss: 0.0672 - val_accuracy: 0.9565\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0668 - val_accuracy: 0.9565\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0664 - val_accuracy: 0.9565\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0670 - val_accuracy: 0.9565\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0672 - val_accuracy: 0.9565\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0679 - val_accuracy: 0.9565\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0675 - val_accuracy: 0.9565\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0695 - val_accuracy: 0.9565\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0686 - val_accuracy: 0.9565\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0684 - val_accuracy: 0.9565\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0689 - val_accuracy: 0.9565\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0690 - val_accuracy: 0.9565\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0698 - val_accuracy: 0.9565\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0698 - val_accuracy: 0.9565\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0701 - val_accuracy: 0.9565\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0710 - val_accuracy: 0.9565\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0705 - val_accuracy: 0.9565\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0720 - val_accuracy: 0.9565\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0726 - val_accuracy: 0.9565\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0724 - val_accuracy: 0.9565\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0727 - val_accuracy: 0.9565\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0730 - val_accuracy: 0.9565\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0737 - val_accuracy: 0.9565\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0744 - val_accuracy: 0.9565\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0733 - val_accuracy: 0.9565\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0744 - val_accuracy: 0.9565\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0754 - val_accuracy: 0.9565\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0742 - val_accuracy: 0.9565\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0754 - val_accuracy: 0.9565\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0762 - val_accuracy: 0.9565\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0768 - val_accuracy: 0.9565\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0759 - val_accuracy: 0.9565\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0771 - val_accuracy: 0.9565\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0759 - val_accuracy: 0.9565\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0772 - val_accuracy: 0.9565\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0777 - val_accuracy: 0.9565\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0778 - val_accuracy: 0.9565\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0798 - val_accuracy: 0.9565\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0793 - val_accuracy: 0.9565\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0798 - val_accuracy: 0.9565\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0799 - val_accuracy: 0.9565\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0792 - val_accuracy: 0.9565\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0808 - val_accuracy: 0.9565\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0796 - val_accuracy: 0.9565\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0803 - val_accuracy: 0.9565\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0815 - val_accuracy: 0.9565\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0812 - val_accuracy: 0.9565\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0818 - val_accuracy: 0.9565\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0826 - val_accuracy: 0.9565\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0817 - val_accuracy: 0.9565\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0822 - val_accuracy: 0.9565\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0829 - val_accuracy: 0.9565\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0841 - val_accuracy: 0.9565\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0835 - val_accuracy: 0.9565\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0827 - val_accuracy: 0.9565\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0847 - val_accuracy: 0.9565\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0854 - val_accuracy: 0.9565\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0853 - val_accuracy: 0.9565\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0865 - val_accuracy: 0.9565\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0860 - val_accuracy: 0.9565\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0865 - val_accuracy: 0.9565\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0882 - val_accuracy: 0.9565\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0877 - val_accuracy: 0.9565\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0864 - val_accuracy: 0.9565\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0869 - val_accuracy: 0.9565\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0898 - val_accuracy: 0.9565\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0897 - val_accuracy: 0.9565\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0885 - val_accuracy: 0.9565\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0898 - val_accuracy: 0.9565\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0899 - val_accuracy: 0.9565\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0888 - val_accuracy: 0.9565\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0910 - val_accuracy: 0.9565\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0915 - val_accuracy: 0.9565\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0919 - val_accuracy: 0.9565\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0920 - val_accuracy: 0.9565\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0921 - val_accuracy: 0.9565\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0926 - val_accuracy: 0.9565\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0931 - val_accuracy: 0.9565\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0923 - val_accuracy: 0.9565\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0924 - val_accuracy: 0.9565\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0937 - val_accuracy: 0.9565\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0940 - val_accuracy: 0.9565\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0939 - val_accuracy: 0.9565\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0958 - val_accuracy: 0.9565\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0961 - val_accuracy: 0.9565\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0950 - val_accuracy: 0.9565\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0955 - val_accuracy: 0.9565\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0951 - val_accuracy: 0.9565\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0959 - val_accuracy: 0.9565\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0958 - val_accuracy: 0.9565\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0968 - val_accuracy: 0.9565\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0975 - val_accuracy: 0.9565\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0966 - val_accuracy: 0.9565\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0977 - val_accuracy: 0.9565\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0973 - val_accuracy: 0.9565\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0988 - val_accuracy: 0.9565\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0984 - val_accuracy: 0.9565\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0997 - val_accuracy: 0.9565\n",
      "Epoch 209/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1003 - val_accuracy: 0.9565\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1001 - val_accuracy: 0.9565\n",
      "Epoch 211/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0995 - val_accuracy: 0.9565\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1001 - val_accuracy: 0.9565\n",
      "Epoch 213/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1003 - val_accuracy: 0.9565\n",
      "Epoch 214/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1018 - val_accuracy: 0.9565\n",
      "Epoch 215/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1020 - val_accuracy: 0.9565\n",
      "Epoch 216/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1008 - val_accuracy: 0.9565\n",
      "Epoch 217/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1025 - val_accuracy: 0.9565\n",
      "Epoch 218/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1024 - val_accuracy: 0.9565\n",
      "Epoch 219/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1033 - val_accuracy: 0.9565\n",
      "Epoch 220/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1044 - val_accuracy: 0.9565\n",
      "Epoch 221/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1033 - val_accuracy: 0.9565\n",
      "Epoch 222/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1029 - val_accuracy: 0.9565\n",
      "Epoch 223/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1040 - val_accuracy: 0.9565\n",
      "Epoch 224/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1046 - val_accuracy: 0.9565\n",
      "Epoch 225/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1049 - val_accuracy: 0.9565\n",
      "Epoch 226/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1044 - val_accuracy: 0.9565\n",
      "Epoch 227/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1062 - val_accuracy: 0.9565\n",
      "Epoch 228/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1063 - val_accuracy: 0.9565\n",
      "Epoch 229/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1064 - val_accuracy: 0.9565\n",
      "Epoch 230/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1065 - val_accuracy: 0.9565\n",
      "Epoch 231/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1064 - val_accuracy: 0.9565\n",
      "Epoch 232/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1068 - val_accuracy: 0.9565\n",
      "Epoch 233/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1068 - val_accuracy: 0.9565\n",
      "Epoch 234/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1071 - val_accuracy: 0.9565\n",
      "Epoch 235/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1076 - val_accuracy: 0.9565\n",
      "Epoch 236/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1081 - val_accuracy: 0.9565\n",
      "Epoch 237/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1080 - val_accuracy: 0.9565\n",
      "Epoch 238/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1082 - val_accuracy: 0.9565\n",
      "Epoch 239/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1099 - val_accuracy: 0.9565\n",
      "Epoch 240/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1098 - val_accuracy: 0.9565\n",
      "Epoch 241/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1093 - val_accuracy: 0.9565\n",
      "Epoch 242/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1108 - val_accuracy: 0.9565\n",
      "Epoch 243/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1095 - val_accuracy: 0.9565\n",
      "Epoch 244/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 9.8075e-04 - accuracy: 1.0000 - val_loss: 0.1108 - val_accuracy: 0.9565\n",
      "Epoch 245/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 9.7360e-04 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9565\n",
      "Epoch 246/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.7126e-04 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9565\n",
      "Epoch 247/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 9.5729e-04 - accuracy: 1.0000 - val_loss: 0.1117 - val_accuracy: 0.9565\n",
      "Epoch 248/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 9.4161e-04 - accuracy: 1.0000 - val_loss: 0.1120 - val_accuracy: 0.9565\n",
      "Epoch 249/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 9.2967e-04 - accuracy: 1.0000 - val_loss: 0.1124 - val_accuracy: 0.9565\n",
      "Epoch 250/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 9.1182e-04 - accuracy: 1.0000 - val_loss: 0.1129 - val_accuracy: 0.9565\n",
      "Epoch 251/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 9.1431e-04 - accuracy: 1.0000 - val_loss: 0.1130 - val_accuracy: 0.9565\n",
      "Epoch 252/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 9.0129e-04 - accuracy: 1.0000 - val_loss: 0.1135 - val_accuracy: 0.9565\n",
      "Epoch 253/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.8626e-04 - accuracy: 1.0000 - val_loss: 0.1131 - val_accuracy: 0.9565\n",
      "Epoch 254/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.7588e-04 - accuracy: 1.0000 - val_loss: 0.1137 - val_accuracy: 0.9565\n",
      "Epoch 255/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.6707e-04 - accuracy: 1.0000 - val_loss: 0.1139 - val_accuracy: 0.9565\n",
      "Epoch 256/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 8.6500e-04 - accuracy: 1.0000 - val_loss: 0.1144 - val_accuracy: 0.9565\n",
      "Epoch 257/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.5233e-04 - accuracy: 1.0000 - val_loss: 0.1146 - val_accuracy: 0.9565\n",
      "Epoch 258/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 8.4406e-04 - accuracy: 1.0000 - val_loss: 0.1143 - val_accuracy: 0.9565\n",
      "Epoch 259/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 8.3281e-04 - accuracy: 1.0000 - val_loss: 0.1153 - val_accuracy: 0.9565\n",
      "Epoch 260/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 8.2706e-04 - accuracy: 1.0000 - val_loss: 0.1155 - val_accuracy: 0.9565\n",
      "Epoch 261/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.1523e-04 - accuracy: 1.0000 - val_loss: 0.1160 - val_accuracy: 0.9565\n",
      "Epoch 262/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 8.1604e-04 - accuracy: 1.0000 - val_loss: 0.1170 - val_accuracy: 0.9565\n",
      "Epoch 263/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 8.0104e-04 - accuracy: 1.0000 - val_loss: 0.1163 - val_accuracy: 0.9565\n",
      "Epoch 264/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 7.8646e-04 - accuracy: 1.0000 - val_loss: 0.1171 - val_accuracy: 0.9565\n",
      "Epoch 265/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 7.8276e-04 - accuracy: 1.0000 - val_loss: 0.1181 - val_accuracy: 0.9565\n",
      "Epoch 266/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 7.7301e-04 - accuracy: 1.0000 - val_loss: 0.1183 - val_accuracy: 0.9565\n",
      "Epoch 267/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 7.6728e-04 - accuracy: 1.0000 - val_loss: 0.1178 - val_accuracy: 0.9565\n",
      "Epoch 268/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 7.5772e-04 - accuracy: 1.0000 - val_loss: 0.1184 - val_accuracy: 0.9565\n",
      "Epoch 269/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 7.6475e-04 - accuracy: 1.0000 - val_loss: 0.1200 - val_accuracy: 0.9565\n",
      "Epoch 270/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 7.7458e-04 - accuracy: 1.0000 - val_loss: 0.1171 - val_accuracy: 0.9565\n",
      "Epoch 271/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.4390e-04 - accuracy: 1.0000 - val_loss: 0.1188 - val_accuracy: 0.9565\n",
      "Epoch 272/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 7.2588e-04 - accuracy: 1.0000 - val_loss: 0.1197 - val_accuracy: 0.9565\n",
      "Epoch 273/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.2515e-04 - accuracy: 1.0000 - val_loss: 0.1187 - val_accuracy: 0.9565\n",
      "Epoch 274/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 7.0454e-04 - accuracy: 1.0000 - val_loss: 0.1203 - val_accuracy: 0.9565\n",
      "Epoch 275/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 7.1854e-04 - accuracy: 1.0000 - val_loss: 0.1217 - val_accuracy: 0.9565\n",
      "Epoch 276/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 7.0045e-04 - accuracy: 1.0000 - val_loss: 0.1208 - val_accuracy: 0.9565\n",
      "Epoch 277/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.8866e-04 - accuracy: 1.0000 - val_loss: 0.1209 - val_accuracy: 0.9565\n",
      "Epoch 278/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.8801e-04 - accuracy: 1.0000 - val_loss: 0.1221 - val_accuracy: 0.9565\n",
      "Epoch 279/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.7040e-04 - accuracy: 1.0000 - val_loss: 0.1209 - val_accuracy: 0.9565\n",
      "Epoch 280/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.6726e-04 - accuracy: 1.0000 - val_loss: 0.1212 - val_accuracy: 0.9565\n",
      "Epoch 281/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.6722e-04 - accuracy: 1.0000 - val_loss: 0.1219 - val_accuracy: 0.9565\n",
      "Epoch 282/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.5513e-04 - accuracy: 1.0000 - val_loss: 0.1221 - val_accuracy: 0.9565\n",
      "Epoch 283/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.5434e-04 - accuracy: 1.0000 - val_loss: 0.1230 - val_accuracy: 0.9565\n",
      "Epoch 284/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.3885e-04 - accuracy: 1.0000 - val_loss: 0.1230 - val_accuracy: 0.9565\n",
      "Epoch 285/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.3819e-04 - accuracy: 1.0000 - val_loss: 0.1217 - val_accuracy: 0.9565\n",
      "Epoch 286/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.3249e-04 - accuracy: 1.0000 - val_loss: 0.1224 - val_accuracy: 0.9565\n",
      "Epoch 287/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.2078e-04 - accuracy: 1.0000 - val_loss: 0.1229 - val_accuracy: 0.9565\n",
      "Epoch 288/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.1593e-04 - accuracy: 1.0000 - val_loss: 0.1242 - val_accuracy: 0.9565\n",
      "Epoch 289/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.0798e-04 - accuracy: 1.0000 - val_loss: 0.1237 - val_accuracy: 0.9565\n",
      "Epoch 290/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.0588e-04 - accuracy: 1.0000 - val_loss: 0.1251 - val_accuracy: 0.9565\n",
      "Epoch 291/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.9539e-04 - accuracy: 1.0000 - val_loss: 0.1239 - val_accuracy: 0.9565\n",
      "Epoch 292/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5.9539e-04 - accuracy: 1.0000 - val_loss: 0.1246 - val_accuracy: 0.9565\n",
      "Epoch 293/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5.9081e-04 - accuracy: 1.0000 - val_loss: 0.1253 - val_accuracy: 0.9565\n",
      "Epoch 294/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.7944e-04 - accuracy: 1.0000 - val_loss: 0.1256 - val_accuracy: 0.9565\n",
      "Epoch 295/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5.7732e-04 - accuracy: 1.0000 - val_loss: 0.1267 - val_accuracy: 0.9565\n",
      "Epoch 296/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5.6809e-04 - accuracy: 1.0000 - val_loss: 0.1272 - val_accuracy: 0.9565\n",
      "Epoch 297/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5.6174e-04 - accuracy: 1.0000 - val_loss: 0.1261 - val_accuracy: 0.9565\n",
      "Epoch 298/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5.5670e-04 - accuracy: 1.0000 - val_loss: 0.1265 - val_accuracy: 0.9565\n",
      "Epoch 299/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.5574e-04 - accuracy: 1.0000 - val_loss: 0.1268 - val_accuracy: 0.9565\n",
      "Epoch 300/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.5173e-04 - accuracy: 1.0000 - val_loss: 0.1275 - val_accuracy: 0.9565\n",
      "Epoch 301/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.3908e-04 - accuracy: 1.0000 - val_loss: 0.1283 - val_accuracy: 0.9565\n",
      "Epoch 302/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.4347e-04 - accuracy: 1.0000 - val_loss: 0.1279 - val_accuracy: 0.9565\n",
      "Epoch 303/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.3887e-04 - accuracy: 1.0000 - val_loss: 0.1282 - val_accuracy: 0.9565\n",
      "Epoch 304/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.3602e-04 - accuracy: 1.0000 - val_loss: 0.1276 - val_accuracy: 0.9565\n",
      "Epoch 305/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.2037e-04 - accuracy: 1.0000 - val_loss: 0.1285 - val_accuracy: 0.9565\n",
      "Epoch 306/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.1772e-04 - accuracy: 1.0000 - val_loss: 0.1284 - val_accuracy: 0.9565\n",
      "Epoch 307/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.0555e-04 - accuracy: 1.0000 - val_loss: 0.1291 - val_accuracy: 0.9565\n",
      "Epoch 308/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5.0563e-04 - accuracy: 1.0000 - val_loss: 0.1299 - val_accuracy: 0.9565\n",
      "Epoch 309/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5.0431e-04 - accuracy: 1.0000 - val_loss: 0.1308 - val_accuracy: 0.9565\n",
      "Epoch 310/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.1594e-04 - accuracy: 1.0000 - val_loss: 0.1298 - val_accuracy: 0.9565\n",
      "Epoch 311/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.9807e-04 - accuracy: 1.0000 - val_loss: 0.1317 - val_accuracy: 0.9565\n",
      "Epoch 312/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.8796e-04 - accuracy: 1.0000 - val_loss: 0.1315 - val_accuracy: 0.9565\n",
      "Epoch 313/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.7989e-04 - accuracy: 1.0000 - val_loss: 0.1313 - val_accuracy: 0.9565\n",
      "Epoch 314/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.7886e-04 - accuracy: 1.0000 - val_loss: 0.1313 - val_accuracy: 0.9565\n",
      "Epoch 315/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.8231e-04 - accuracy: 1.0000 - val_loss: 0.1331 - val_accuracy: 0.9565\n",
      "Epoch 316/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.7041e-04 - accuracy: 1.0000 - val_loss: 0.1323 - val_accuracy: 0.9565\n",
      "Epoch 317/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.6103e-04 - accuracy: 1.0000 - val_loss: 0.1324 - val_accuracy: 0.9565\n",
      "Epoch 318/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.5702e-04 - accuracy: 1.0000 - val_loss: 0.1323 - val_accuracy: 0.9565\n",
      "Epoch 319/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.5640e-04 - accuracy: 1.0000 - val_loss: 0.1324 - val_accuracy: 0.9565\n",
      "Epoch 320/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.4793e-04 - accuracy: 1.0000 - val_loss: 0.1326 - val_accuracy: 0.9565\n",
      "Epoch 321/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.5484e-04 - accuracy: 1.0000 - val_loss: 0.1343 - val_accuracy: 0.9565\n",
      "Epoch 322/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.4151e-04 - accuracy: 1.0000 - val_loss: 0.1338 - val_accuracy: 0.9565\n",
      "Epoch 323/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.3868e-04 - accuracy: 1.0000 - val_loss: 0.1334 - val_accuracy: 0.9565\n",
      "Epoch 324/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.3228e-04 - accuracy: 1.0000 - val_loss: 0.1343 - val_accuracy: 0.9565\n",
      "Epoch 325/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.2885e-04 - accuracy: 1.0000 - val_loss: 0.1349 - val_accuracy: 0.9565\n",
      "Epoch 326/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.2460e-04 - accuracy: 1.0000 - val_loss: 0.1350 - val_accuracy: 0.9565\n",
      "Epoch 327/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.1654e-04 - accuracy: 1.0000 - val_loss: 0.1352 - val_accuracy: 0.9565\n",
      "Epoch 328/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.2108e-04 - accuracy: 1.0000 - val_loss: 0.1366 - val_accuracy: 0.9565\n",
      "Epoch 329/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.0997e-04 - accuracy: 1.0000 - val_loss: 0.1358 - val_accuracy: 0.9565\n",
      "Epoch 330/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.0782e-04 - accuracy: 1.0000 - val_loss: 0.1353 - val_accuracy: 0.9565\n",
      "Epoch 331/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.0470e-04 - accuracy: 1.0000 - val_loss: 0.1356 - val_accuracy: 0.9565\n",
      "Epoch 332/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.0590e-04 - accuracy: 1.0000 - val_loss: 0.1369 - val_accuracy: 0.9565\n",
      "Epoch 333/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.9515e-04 - accuracy: 1.0000 - val_loss: 0.1367 - val_accuracy: 0.9565\n",
      "Epoch 334/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.9281e-04 - accuracy: 1.0000 - val_loss: 0.1368 - val_accuracy: 0.9565\n",
      "Epoch 335/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.8952e-04 - accuracy: 1.0000 - val_loss: 0.1376 - val_accuracy: 0.9565\n",
      "Epoch 336/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.8540e-04 - accuracy: 1.0000 - val_loss: 0.1379 - val_accuracy: 0.9565\n",
      "Epoch 337/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.8680e-04 - accuracy: 1.0000 - val_loss: 0.1375 - val_accuracy: 0.9565\n",
      "Epoch 338/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.7944e-04 - accuracy: 1.0000 - val_loss: 0.1387 - val_accuracy: 0.9565\n",
      "Epoch 339/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.7473e-04 - accuracy: 1.0000 - val_loss: 0.1388 - val_accuracy: 0.9565\n",
      "Epoch 340/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.7144e-04 - accuracy: 1.0000 - val_loss: 0.1394 - val_accuracy: 0.9565\n",
      "Epoch 341/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.6809e-04 - accuracy: 1.0000 - val_loss: 0.1386 - val_accuracy: 0.9565\n",
      "Epoch 342/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.6457e-04 - accuracy: 1.0000 - val_loss: 0.1392 - val_accuracy: 0.9565\n",
      "Epoch 343/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.6627e-04 - accuracy: 1.0000 - val_loss: 0.1400 - val_accuracy: 0.9565\n",
      "Epoch 344/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.5706e-04 - accuracy: 1.0000 - val_loss: 0.1400 - val_accuracy: 0.9565\n",
      "Epoch 345/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.5699e-04 - accuracy: 1.0000 - val_loss: 0.1401 - val_accuracy: 0.9565\n",
      "Epoch 346/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.5255e-04 - accuracy: 1.0000 - val_loss: 0.1407 - val_accuracy: 0.9565\n",
      "Epoch 347/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.4886e-04 - accuracy: 1.0000 - val_loss: 0.1404 - val_accuracy: 0.9565\n",
      "Epoch 348/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.4812e-04 - accuracy: 1.0000 - val_loss: 0.1420 - val_accuracy: 0.9565\n",
      "Epoch 349/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.4607e-04 - accuracy: 1.0000 - val_loss: 0.1405 - val_accuracy: 0.9565\n",
      "Epoch 350/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.4326e-04 - accuracy: 1.0000 - val_loss: 0.1423 - val_accuracy: 0.9565\n",
      "Epoch 351/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.4126e-04 - accuracy: 1.0000 - val_loss: 0.1419 - val_accuracy: 0.9565\n",
      "Epoch 352/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.3349e-04 - accuracy: 1.0000 - val_loss: 0.1424 - val_accuracy: 0.9565\n",
      "Epoch 353/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.2926e-04 - accuracy: 1.0000 - val_loss: 0.1424 - val_accuracy: 0.9565\n",
      "Epoch 354/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.2901e-04 - accuracy: 1.0000 - val_loss: 0.1418 - val_accuracy: 0.9565\n",
      "Epoch 355/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.2263e-04 - accuracy: 1.0000 - val_loss: 0.1425 - val_accuracy: 0.9565\n",
      "Epoch 356/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.2284e-04 - accuracy: 1.0000 - val_loss: 0.1437 - val_accuracy: 0.9565\n",
      "Epoch 357/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.1727e-04 - accuracy: 1.0000 - val_loss: 0.1434 - val_accuracy: 0.9565\n",
      "Epoch 358/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.1555e-04 - accuracy: 1.0000 - val_loss: 0.1430 - val_accuracy: 0.9565\n",
      "Epoch 359/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.1412e-04 - accuracy: 1.0000 - val_loss: 0.1429 - val_accuracy: 0.9565\n",
      "Epoch 360/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.0854e-04 - accuracy: 1.0000 - val_loss: 0.1436 - val_accuracy: 0.9565\n",
      "Epoch 361/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.1001e-04 - accuracy: 1.0000 - val_loss: 0.1448 - val_accuracy: 0.9565\n",
      "Epoch 362/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.0811e-04 - accuracy: 1.0000 - val_loss: 0.1442 - val_accuracy: 0.9565\n",
      "Epoch 363/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.0445e-04 - accuracy: 1.0000 - val_loss: 0.1444 - val_accuracy: 0.9565\n",
      "Epoch 364/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.0246e-04 - accuracy: 1.0000 - val_loss: 0.1463 - val_accuracy: 0.9565\n",
      "Epoch 365/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.9659e-04 - accuracy: 1.0000 - val_loss: 0.1453 - val_accuracy: 0.9565\n",
      "Epoch 366/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.9239e-04 - accuracy: 1.0000 - val_loss: 0.1461 - val_accuracy: 0.9565\n",
      "Epoch 367/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.9411e-04 - accuracy: 1.0000 - val_loss: 0.1457 - val_accuracy: 0.9565\n",
      "Epoch 368/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.8927e-04 - accuracy: 1.0000 - val_loss: 0.1465 - val_accuracy: 0.9565\n",
      "Epoch 369/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.8618e-04 - accuracy: 1.0000 - val_loss: 0.1455 - val_accuracy: 0.9565\n",
      "Epoch 370/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.8613e-04 - accuracy: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9565\n",
      "Epoch 371/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.8117e-04 - accuracy: 1.0000 - val_loss: 0.1472 - val_accuracy: 0.9565\n",
      "Epoch 372/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.7851e-04 - accuracy: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9565\n",
      "Epoch 373/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.7509e-04 - accuracy: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9565\n",
      "Epoch 374/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.7833e-04 - accuracy: 1.0000 - val_loss: 0.1477 - val_accuracy: 0.9565\n",
      "Epoch 375/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.7325e-04 - accuracy: 1.0000 - val_loss: 0.1479 - val_accuracy: 0.9565\n",
      "Epoch 376/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.7002e-04 - accuracy: 1.0000 - val_loss: 0.1483 - val_accuracy: 0.9565\n",
      "Epoch 377/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.6492e-04 - accuracy: 1.0000 - val_loss: 0.1486 - val_accuracy: 0.9565\n",
      "Epoch 378/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.6434e-04 - accuracy: 1.0000 - val_loss: 0.1485 - val_accuracy: 0.9565\n",
      "Epoch 379/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.5970e-04 - accuracy: 1.0000 - val_loss: 0.1491 - val_accuracy: 0.9565\n",
      "Epoch 380/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.6269e-04 - accuracy: 1.0000 - val_loss: 0.1494 - val_accuracy: 0.9565\n",
      "Epoch 381/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.5707e-04 - accuracy: 1.0000 - val_loss: 0.1497 - val_accuracy: 0.9565\n",
      "Epoch 382/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.5542e-04 - accuracy: 1.0000 - val_loss: 0.1503 - val_accuracy: 0.9565\n",
      "Epoch 383/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.5132e-04 - accuracy: 1.0000 - val_loss: 0.1499 - val_accuracy: 0.9565\n",
      "Epoch 384/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.5083e-04 - accuracy: 1.0000 - val_loss: 0.1498 - val_accuracy: 0.9565\n",
      "Epoch 385/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.4853e-04 - accuracy: 1.0000 - val_loss: 0.1502 - val_accuracy: 0.9565\n",
      "Epoch 386/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.4670e-04 - accuracy: 1.0000 - val_loss: 0.1499 - val_accuracy: 0.9565\n",
      "Epoch 387/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.4456e-04 - accuracy: 1.0000 - val_loss: 0.1508 - val_accuracy: 0.9565\n",
      "Epoch 388/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.4609e-04 - accuracy: 1.0000 - val_loss: 0.1520 - val_accuracy: 0.9565\n",
      "Epoch 389/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.4701e-04 - accuracy: 1.0000 - val_loss: 0.1503 - val_accuracy: 0.9565\n",
      "Epoch 390/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.3850e-04 - accuracy: 1.0000 - val_loss: 0.1512 - val_accuracy: 0.9565\n",
      "Epoch 391/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.3751e-04 - accuracy: 1.0000 - val_loss: 0.1525 - val_accuracy: 0.9565\n",
      "Epoch 392/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.3467e-04 - accuracy: 1.0000 - val_loss: 0.1531 - val_accuracy: 0.9565\n",
      "Epoch 393/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.3313e-04 - accuracy: 1.0000 - val_loss: 0.1521 - val_accuracy: 0.9565\n",
      "Epoch 394/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.2919e-04 - accuracy: 1.0000 - val_loss: 0.1522 - val_accuracy: 0.9565\n",
      "Epoch 395/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.2573e-04 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9565\n",
      "Epoch 396/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.2752e-04 - accuracy: 1.0000 - val_loss: 0.1540 - val_accuracy: 0.9565\n",
      "Epoch 397/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.2529e-04 - accuracy: 1.0000 - val_loss: 0.1538 - val_accuracy: 0.9565\n",
      "Epoch 398/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.2076e-04 - accuracy: 1.0000 - val_loss: 0.1542 - val_accuracy: 0.9565\n",
      "Epoch 399/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.1945e-04 - accuracy: 1.0000 - val_loss: 0.1546 - val_accuracy: 0.9565\n",
      "Epoch 400/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.1672e-04 - accuracy: 1.0000 - val_loss: 0.1550 - val_accuracy: 0.9565\n",
      "Epoch 401/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.1474e-04 - accuracy: 1.0000 - val_loss: 0.1548 - val_accuracy: 0.9565\n",
      "Epoch 402/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.1554e-04 - accuracy: 1.0000 - val_loss: 0.1548 - val_accuracy: 0.9565\n",
      "Epoch 403/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.1410e-04 - accuracy: 1.0000 - val_loss: 0.1564 - val_accuracy: 0.9565\n",
      "Epoch 404/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.1344e-04 - accuracy: 1.0000 - val_loss: 0.1547 - val_accuracy: 0.9565\n",
      "Epoch 405/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.0968e-04 - accuracy: 1.0000 - val_loss: 0.1559 - val_accuracy: 0.9565\n",
      "Epoch 406/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.0658e-04 - accuracy: 1.0000 - val_loss: 0.1552 - val_accuracy: 0.9565\n",
      "Epoch 407/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.0373e-04 - accuracy: 1.0000 - val_loss: 0.1562 - val_accuracy: 0.9565\n",
      "Epoch 408/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.0349e-04 - accuracy: 1.0000 - val_loss: 0.1569 - val_accuracy: 0.9565\n",
      "Epoch 409/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.0263e-04 - accuracy: 1.0000 - val_loss: 0.1580 - val_accuracy: 0.9565\n",
      "Epoch 410/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.0209e-04 - accuracy: 1.0000 - val_loss: 0.1567 - val_accuracy: 0.9565\n",
      "Epoch 411/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.9726e-04 - accuracy: 1.0000 - val_loss: 0.1574 - val_accuracy: 0.9565\n",
      "Epoch 412/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.9689e-04 - accuracy: 1.0000 - val_loss: 0.1572 - val_accuracy: 0.9565\n",
      "Epoch 413/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.9481e-04 - accuracy: 1.0000 - val_loss: 0.1581 - val_accuracy: 0.9565\n",
      "Epoch 414/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.9342e-04 - accuracy: 1.0000 - val_loss: 0.1584 - val_accuracy: 0.9565\n",
      "Epoch 415/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.9140e-04 - accuracy: 1.0000 - val_loss: 0.1581 - val_accuracy: 0.9565\n",
      "Epoch 416/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.8818e-04 - accuracy: 1.0000 - val_loss: 0.1585 - val_accuracy: 0.9565\n",
      "Epoch 417/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.8698e-04 - accuracy: 1.0000 - val_loss: 0.1592 - val_accuracy: 0.9565\n",
      "Epoch 418/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.8723e-04 - accuracy: 1.0000 - val_loss: 0.1588 - val_accuracy: 0.9565\n",
      "Epoch 419/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.8575e-04 - accuracy: 1.0000 - val_loss: 0.1601 - val_accuracy: 0.9565\n",
      "Epoch 420/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.8262e-04 - accuracy: 1.0000 - val_loss: 0.1600 - val_accuracy: 0.9565\n",
      "Epoch 421/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.8071e-04 - accuracy: 1.0000 - val_loss: 0.1602 - val_accuracy: 0.9565\n",
      "Epoch 422/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.7943e-04 - accuracy: 1.0000 - val_loss: 0.1600 - val_accuracy: 0.9565\n",
      "Epoch 423/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.7852e-04 - accuracy: 1.0000 - val_loss: 0.1605 - val_accuracy: 0.9565\n",
      "Epoch 424/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.7711e-04 - accuracy: 1.0000 - val_loss: 0.1607 - val_accuracy: 0.9565\n",
      "Epoch 425/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.7472e-04 - accuracy: 1.0000 - val_loss: 0.1603 - val_accuracy: 0.9565\n",
      "Epoch 426/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.7409e-04 - accuracy: 1.0000 - val_loss: 0.1608 - val_accuracy: 0.9565\n",
      "Epoch 427/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.7270e-04 - accuracy: 1.0000 - val_loss: 0.1619 - val_accuracy: 0.9565\n",
      "Epoch 428/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.7197e-04 - accuracy: 1.0000 - val_loss: 0.1616 - val_accuracy: 0.9565\n",
      "Epoch 429/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.7072e-04 - accuracy: 1.0000 - val_loss: 0.1629 - val_accuracy: 0.9565\n",
      "Epoch 430/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6741e-04 - accuracy: 1.0000 - val_loss: 0.1620 - val_accuracy: 0.9565\n",
      "Epoch 431/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.6664e-04 - accuracy: 1.0000 - val_loss: 0.1619 - val_accuracy: 0.9565\n",
      "Epoch 432/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.6541e-04 - accuracy: 1.0000 - val_loss: 0.1619 - val_accuracy: 0.9565\n",
      "Epoch 433/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.6507e-04 - accuracy: 1.0000 - val_loss: 0.1627 - val_accuracy: 0.9565\n",
      "Epoch 434/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.6443e-04 - accuracy: 1.0000 - val_loss: 0.1628 - val_accuracy: 0.9565\n",
      "Epoch 435/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.6132e-04 - accuracy: 1.0000 - val_loss: 0.1633 - val_accuracy: 0.9565\n",
      "Epoch 436/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6154e-04 - accuracy: 1.0000 - val_loss: 0.1650 - val_accuracy: 0.9565\n",
      "Epoch 437/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.5839e-04 - accuracy: 1.0000 - val_loss: 0.1642 - val_accuracy: 0.9565\n",
      "Epoch 438/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.5625e-04 - accuracy: 1.0000 - val_loss: 0.1640 - val_accuracy: 0.9565\n",
      "Epoch 439/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.5620e-04 - accuracy: 1.0000 - val_loss: 0.1639 - val_accuracy: 0.9565\n",
      "Epoch 440/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.5360e-04 - accuracy: 1.0000 - val_loss: 0.1649 - val_accuracy: 0.9565\n",
      "Epoch 441/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.5326e-04 - accuracy: 1.0000 - val_loss: 0.1645 - val_accuracy: 0.9565\n",
      "Epoch 442/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.5390e-04 - accuracy: 1.0000 - val_loss: 0.1656 - val_accuracy: 0.9565\n",
      "Epoch 443/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.5017e-04 - accuracy: 1.0000 - val_loss: 0.1655 - val_accuracy: 0.9565\n",
      "Epoch 444/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.4911e-04 - accuracy: 1.0000 - val_loss: 0.1660 - val_accuracy: 0.9565\n",
      "Epoch 445/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4920e-04 - accuracy: 1.0000 - val_loss: 0.1663 - val_accuracy: 0.9565\n",
      "Epoch 446/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.4682e-04 - accuracy: 1.0000 - val_loss: 0.1656 - val_accuracy: 0.9565\n",
      "Epoch 447/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.4563e-04 - accuracy: 1.0000 - val_loss: 0.1660 - val_accuracy: 0.9565\n",
      "Epoch 448/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.4698e-04 - accuracy: 1.0000 - val_loss: 0.1666 - val_accuracy: 0.9565\n",
      "Epoch 449/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.4384e-04 - accuracy: 1.0000 - val_loss: 0.1669 - val_accuracy: 0.9565\n",
      "Epoch 450/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.4199e-04 - accuracy: 1.0000 - val_loss: 0.1665 - val_accuracy: 0.9565\n",
      "Epoch 451/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.4125e-04 - accuracy: 1.0000 - val_loss: 0.1670 - val_accuracy: 0.9565\n",
      "Epoch 452/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.3981e-04 - accuracy: 1.0000 - val_loss: 0.1671 - val_accuracy: 0.9565\n",
      "Epoch 453/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3839e-04 - accuracy: 1.0000 - val_loss: 0.1677 - val_accuracy: 0.9565\n",
      "Epoch 454/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3826e-04 - accuracy: 1.0000 - val_loss: 0.1688 - val_accuracy: 0.9565\n",
      "Epoch 455/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3749e-04 - accuracy: 1.0000 - val_loss: 0.1678 - val_accuracy: 0.9565\n",
      "Epoch 456/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.3664e-04 - accuracy: 1.0000 - val_loss: 0.1686 - val_accuracy: 0.9565\n",
      "Epoch 457/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.3391e-04 - accuracy: 1.0000 - val_loss: 0.1693 - val_accuracy: 0.9565\n",
      "Epoch 458/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.3452e-04 - accuracy: 1.0000 - val_loss: 0.1697 - val_accuracy: 0.9565\n",
      "Epoch 459/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.3253e-04 - accuracy: 1.0000 - val_loss: 0.1686 - val_accuracy: 0.9565\n",
      "Epoch 460/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.3106e-04 - accuracy: 1.0000 - val_loss: 0.1696 - val_accuracy: 0.9565\n",
      "Epoch 461/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2912e-04 - accuracy: 1.0000 - val_loss: 0.1694 - val_accuracy: 0.9565\n",
      "Epoch 462/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.2833e-04 - accuracy: 1.0000 - val_loss: 0.1697 - val_accuracy: 0.9565\n",
      "Epoch 463/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2754e-04 - accuracy: 1.0000 - val_loss: 0.1705 - val_accuracy: 0.9565\n",
      "Epoch 464/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2669e-04 - accuracy: 1.0000 - val_loss: 0.1703 - val_accuracy: 0.9565\n",
      "Epoch 465/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.2533e-04 - accuracy: 1.0000 - val_loss: 0.1710 - val_accuracy: 0.9565\n",
      "Epoch 466/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.2577e-04 - accuracy: 1.0000 - val_loss: 0.1717 - val_accuracy: 0.9565\n",
      "Epoch 467/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.2418e-04 - accuracy: 1.0000 - val_loss: 0.1723 - val_accuracy: 0.9565\n",
      "Epoch 468/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.2173e-04 - accuracy: 1.0000 - val_loss: 0.1724 - val_accuracy: 0.9565\n",
      "Epoch 469/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.2092e-04 - accuracy: 1.0000 - val_loss: 0.1713 - val_accuracy: 0.9565\n",
      "Epoch 470/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1988e-04 - accuracy: 1.0000 - val_loss: 0.1714 - val_accuracy: 0.9565\n",
      "Epoch 471/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.1930e-04 - accuracy: 1.0000 - val_loss: 0.1723 - val_accuracy: 0.9565\n",
      "Epoch 472/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.1851e-04 - accuracy: 1.0000 - val_loss: 0.1724 - val_accuracy: 0.9565\n",
      "Epoch 473/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.1792e-04 - accuracy: 1.0000 - val_loss: 0.1732 - val_accuracy: 0.9565\n",
      "Epoch 474/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.1608e-04 - accuracy: 1.0000 - val_loss: 0.1726 - val_accuracy: 0.9565\n",
      "Epoch 475/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.1584e-04 - accuracy: 1.0000 - val_loss: 0.1728 - val_accuracy: 0.9565\n",
      "Epoch 476/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1432e-04 - accuracy: 1.0000 - val_loss: 0.1737 - val_accuracy: 0.9565\n",
      "Epoch 477/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.1401e-04 - accuracy: 1.0000 - val_loss: 0.1743 - val_accuracy: 0.9565\n",
      "Epoch 478/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1260e-04 - accuracy: 1.0000 - val_loss: 0.1742 - val_accuracy: 0.9565\n",
      "Epoch 479/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1206e-04 - accuracy: 1.0000 - val_loss: 0.1734 - val_accuracy: 0.9565\n",
      "Epoch 480/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.1123e-04 - accuracy: 1.0000 - val_loss: 0.1741 - val_accuracy: 0.9565\n",
      "Epoch 481/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1000e-04 - accuracy: 1.0000 - val_loss: 0.1747 - val_accuracy: 0.9565\n",
      "Epoch 482/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.0843e-04 - accuracy: 1.0000 - val_loss: 0.1751 - val_accuracy: 0.9565\n",
      "Epoch 483/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.0939e-04 - accuracy: 1.0000 - val_loss: 0.1762 - val_accuracy: 0.9565\n",
      "Epoch 484/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0748e-04 - accuracy: 1.0000 - val_loss: 0.1755 - val_accuracy: 0.9565\n",
      "Epoch 485/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.0681e-04 - accuracy: 1.0000 - val_loss: 0.1756 - val_accuracy: 0.9565\n",
      "Epoch 486/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.0567e-04 - accuracy: 1.0000 - val_loss: 0.1758 - val_accuracy: 0.9565\n",
      "Epoch 487/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.0493e-04 - accuracy: 1.0000 - val_loss: 0.1768 - val_accuracy: 0.9565\n",
      "Epoch 488/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.0359e-04 - accuracy: 1.0000 - val_loss: 0.1768 - val_accuracy: 0.9565\n",
      "Epoch 489/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.0284e-04 - accuracy: 1.0000 - val_loss: 0.1768 - val_accuracy: 0.9565\n",
      "Epoch 490/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.0282e-04 - accuracy: 1.0000 - val_loss: 0.1774 - val_accuracy: 0.9565\n",
      "Epoch 491/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.0251e-04 - accuracy: 1.0000 - val_loss: 0.1783 - val_accuracy: 0.9565\n",
      "Epoch 492/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.9976e-05 - accuracy: 1.0000 - val_loss: 0.1772 - val_accuracy: 0.9565\n",
      "Epoch 493/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.0025e-04 - accuracy: 1.0000 - val_loss: 0.1774 - val_accuracy: 0.9565\n",
      "Epoch 494/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 9.8697e-05 - accuracy: 1.0000 - val_loss: 0.1775 - val_accuracy: 0.9565\n",
      "Epoch 495/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 9.9208e-05 - accuracy: 1.0000 - val_loss: 0.1785 - val_accuracy: 0.9565\n",
      "Epoch 496/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 9.7485e-05 - accuracy: 1.0000 - val_loss: 0.1781 - val_accuracy: 0.9565\n",
      "Epoch 497/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 9.6202e-05 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 0.9565\n",
      "Epoch 498/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 9.7717e-05 - accuracy: 1.0000 - val_loss: 0.1801 - val_accuracy: 0.9565\n",
      "Epoch 499/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 9.4859e-05 - accuracy: 1.0000 - val_loss: 0.1797 - val_accuracy: 0.9565\n",
      "Epoch 500/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.3734e-05 - accuracy: 1.0000 - val_loss: 0.1797 - val_accuracy: 0.9565\n",
      "Epoch 501/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 9.3928e-05 - accuracy: 1.0000 - val_loss: 0.1796 - val_accuracy: 0.9565\n",
      "Epoch 502/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 9.2709e-05 - accuracy: 1.0000 - val_loss: 0.1802 - val_accuracy: 0.9565\n",
      "Epoch 503/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 9.2522e-05 - accuracy: 1.0000 - val_loss: 0.1806 - val_accuracy: 0.9565\n",
      "Epoch 504/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 9.1940e-05 - accuracy: 1.0000 - val_loss: 0.1816 - val_accuracy: 0.9565\n",
      "Epoch 505/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 9.0017e-05 - accuracy: 1.0000 - val_loss: 0.1812 - val_accuracy: 0.9565\n",
      "Epoch 506/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 8.9545e-05 - accuracy: 1.0000 - val_loss: 0.1811 - val_accuracy: 0.9565\n",
      "Epoch 507/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.9368e-05 - accuracy: 1.0000 - val_loss: 0.1815 - val_accuracy: 0.9565\n",
      "Epoch 508/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 8.7958e-05 - accuracy: 1.0000 - val_loss: 0.1816 - val_accuracy: 0.9565\n",
      "Epoch 509/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.8815e-05 - accuracy: 1.0000 - val_loss: 0.1820 - val_accuracy: 0.9565\n",
      "Epoch 510/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.8381e-05 - accuracy: 1.0000 - val_loss: 0.1806 - val_accuracy: 0.9565\n",
      "Epoch 511/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.6971e-05 - accuracy: 1.0000 - val_loss: 0.1826 - val_accuracy: 0.9565\n",
      "Epoch 512/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.6068e-05 - accuracy: 1.0000 - val_loss: 0.1822 - val_accuracy: 0.9565\n",
      "Epoch 513/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.4835e-05 - accuracy: 1.0000 - val_loss: 0.1828 - val_accuracy: 0.9565\n",
      "Epoch 514/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.3913e-05 - accuracy: 1.0000 - val_loss: 0.1832 - val_accuracy: 0.9565\n",
      "Epoch 515/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 8.3500e-05 - accuracy: 1.0000 - val_loss: 0.1834 - val_accuracy: 0.9565\n",
      "Epoch 516/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.3511e-05 - accuracy: 1.0000 - val_loss: 0.1845 - val_accuracy: 0.9565\n",
      "Epoch 517/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.2575e-05 - accuracy: 1.0000 - val_loss: 0.1839 - val_accuracy: 0.9565\n",
      "Epoch 518/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.1104e-05 - accuracy: 1.0000 - val_loss: 0.1841 - val_accuracy: 0.9565\n",
      "Epoch 519/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 8.1731e-05 - accuracy: 1.0000 - val_loss: 0.1851 - val_accuracy: 0.9565\n",
      "Epoch 520/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 8.1120e-05 - accuracy: 1.0000 - val_loss: 0.1842 - val_accuracy: 0.9565\n",
      "Epoch 521/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 7.9666e-05 - accuracy: 1.0000 - val_loss: 0.1846 - val_accuracy: 0.9565\n",
      "Epoch 522/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 7.8662e-05 - accuracy: 1.0000 - val_loss: 0.1850 - val_accuracy: 0.9565\n",
      "Epoch 523/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 7.8269e-05 - accuracy: 1.0000 - val_loss: 0.1863 - val_accuracy: 0.9565\n",
      "Epoch 524/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 7.9057e-05 - accuracy: 1.0000 - val_loss: 0.1852 - val_accuracy: 0.9565\n",
      "Epoch 525/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 7.7364e-05 - accuracy: 1.0000 - val_loss: 0.1860 - val_accuracy: 0.9565\n",
      "Epoch 526/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 7.7511e-05 - accuracy: 1.0000 - val_loss: 0.1875 - val_accuracy: 0.9565\n",
      "Epoch 527/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 7.5536e-05 - accuracy: 1.0000 - val_loss: 0.1880 - val_accuracy: 0.9565\n",
      "Epoch 528/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 7.6638e-05 - accuracy: 1.0000 - val_loss: 0.1866 - val_accuracy: 0.9565\n",
      "Epoch 529/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.4585e-05 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 0.9565\n",
      "Epoch 530/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 7.5010e-05 - accuracy: 1.0000 - val_loss: 0.1885 - val_accuracy: 0.9565\n",
      "Epoch 531/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 7.3360e-05 - accuracy: 1.0000 - val_loss: 0.1883 - val_accuracy: 0.9565\n",
      "Epoch 532/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 7.2794e-05 - accuracy: 1.0000 - val_loss: 0.1886 - val_accuracy: 0.9565\n",
      "Epoch 533/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 7.2958e-05 - accuracy: 1.0000 - val_loss: 0.1873 - val_accuracy: 0.9565\n",
      "Epoch 534/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 7.2244e-05 - accuracy: 1.0000 - val_loss: 0.1885 - val_accuracy: 0.9565\n",
      "Epoch 535/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 7.1490e-05 - accuracy: 1.0000 - val_loss: 0.1887 - val_accuracy: 0.9565\n",
      "Epoch 536/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 7.1479e-05 - accuracy: 1.0000 - val_loss: 0.1873 - val_accuracy: 0.9565\n",
      "Epoch 537/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 7.1567e-05 - accuracy: 1.0000 - val_loss: 0.1886 - val_accuracy: 0.9565\n",
      "Epoch 538/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.9597e-05 - accuracy: 1.0000 - val_loss: 0.1884 - val_accuracy: 0.9565\n",
      "Epoch 539/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.9187e-05 - accuracy: 1.0000 - val_loss: 0.1886 - val_accuracy: 0.9565\n",
      "Epoch 540/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.8244e-05 - accuracy: 1.0000 - val_loss: 0.1890 - val_accuracy: 0.9565\n",
      "Epoch 541/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.8742e-05 - accuracy: 1.0000 - val_loss: 0.1900 - val_accuracy: 0.9565\n",
      "Epoch 542/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.7754e-05 - accuracy: 1.0000 - val_loss: 0.1911 - val_accuracy: 0.9565\n",
      "Epoch 543/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.6746e-05 - accuracy: 1.0000 - val_loss: 0.1914 - val_accuracy: 0.9565\n",
      "Epoch 544/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.6159e-05 - accuracy: 1.0000 - val_loss: 0.1908 - val_accuracy: 0.9565\n",
      "Epoch 545/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.6627e-05 - accuracy: 1.0000 - val_loss: 0.1920 - val_accuracy: 0.9565\n",
      "Epoch 546/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.5296e-05 - accuracy: 1.0000 - val_loss: 0.1922 - val_accuracy: 0.9565\n",
      "Epoch 547/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.4416e-05 - accuracy: 1.0000 - val_loss: 0.1911 - val_accuracy: 0.9565\n",
      "Epoch 548/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.4050e-05 - accuracy: 1.0000 - val_loss: 0.1914 - val_accuracy: 0.9565\n",
      "Epoch 549/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.3776e-05 - accuracy: 1.0000 - val_loss: 0.1914 - val_accuracy: 0.9565\n",
      "Epoch 550/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.3718e-05 - accuracy: 1.0000 - val_loss: 0.1930 - val_accuracy: 0.9565\n",
      "Epoch 551/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.3119e-05 - accuracy: 1.0000 - val_loss: 0.1926 - val_accuracy: 0.9565\n",
      "Epoch 552/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.3003e-05 - accuracy: 1.0000 - val_loss: 0.1917 - val_accuracy: 0.9565\n",
      "Epoch 553/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.2311e-05 - accuracy: 1.0000 - val_loss: 0.1930 - val_accuracy: 0.9565\n",
      "Epoch 554/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.1928e-05 - accuracy: 1.0000 - val_loss: 0.1925 - val_accuracy: 0.9565\n",
      "Epoch 555/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.0731e-05 - accuracy: 1.0000 - val_loss: 0.1934 - val_accuracy: 0.9565\n",
      "Epoch 556/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.0260e-05 - accuracy: 1.0000 - val_loss: 0.1935 - val_accuracy: 0.9565\n",
      "Epoch 557/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.9941e-05 - accuracy: 1.0000 - val_loss: 0.1943 - val_accuracy: 0.9565\n",
      "Epoch 558/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.9355e-05 - accuracy: 1.0000 - val_loss: 0.1943 - val_accuracy: 0.9565\n",
      "Epoch 559/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.8906e-05 - accuracy: 1.0000 - val_loss: 0.1941 - val_accuracy: 0.9565\n",
      "Epoch 560/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.8553e-05 - accuracy: 1.0000 - val_loss: 0.1941 - val_accuracy: 0.9565\n",
      "Epoch 561/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.7693e-05 - accuracy: 1.0000 - val_loss: 0.1949 - val_accuracy: 0.9565\n",
      "Epoch 562/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.7357e-05 - accuracy: 1.0000 - val_loss: 0.1955 - val_accuracy: 0.9565\n",
      "Epoch 563/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.7467e-05 - accuracy: 1.0000 - val_loss: 0.1952 - val_accuracy: 0.9565\n",
      "Epoch 564/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.6537e-05 - accuracy: 1.0000 - val_loss: 0.1960 - val_accuracy: 0.9565\n",
      "Epoch 565/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 5.5959e-05 - accuracy: 1.0000 - val_loss: 0.1963 - val_accuracy: 0.9565\n",
      "Epoch 566/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.5822e-05 - accuracy: 1.0000 - val_loss: 0.1971 - val_accuracy: 0.9565\n",
      "Epoch 567/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5.5466e-05 - accuracy: 1.0000 - val_loss: 0.1965 - val_accuracy: 0.9565\n",
      "Epoch 568/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.4663e-05 - accuracy: 1.0000 - val_loss: 0.1966 - val_accuracy: 0.9565\n",
      "Epoch 569/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5.4606e-05 - accuracy: 1.0000 - val_loss: 0.1971 - val_accuracy: 0.9565\n",
      "Epoch 570/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.3734e-05 - accuracy: 1.0000 - val_loss: 0.1973 - val_accuracy: 0.9565\n",
      "Epoch 571/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.3642e-05 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 0.9565\n",
      "Epoch 572/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5.2858e-05 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 0.9565\n",
      "Epoch 573/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.2536e-05 - accuracy: 1.0000 - val_loss: 0.1981 - val_accuracy: 0.9565\n",
      "Epoch 574/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.2510e-05 - accuracy: 1.0000 - val_loss: 0.1980 - val_accuracy: 0.9565\n",
      "Epoch 575/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.2649e-05 - accuracy: 1.0000 - val_loss: 0.1985 - val_accuracy: 0.9565\n",
      "Epoch 576/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 5.1436e-05 - accuracy: 1.0000 - val_loss: 0.1994 - val_accuracy: 0.9565\n",
      "Epoch 577/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5.1463e-05 - accuracy: 1.0000 - val_loss: 0.1984 - val_accuracy: 0.9565\n",
      "Epoch 578/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5.0558e-05 - accuracy: 1.0000 - val_loss: 0.1997 - val_accuracy: 0.9565\n",
      "Epoch 579/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.0351e-05 - accuracy: 1.0000 - val_loss: 0.1996 - val_accuracy: 0.9565\n",
      "Epoch 580/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5.0169e-05 - accuracy: 1.0000 - val_loss: 0.1993 - val_accuracy: 0.9565\n",
      "Epoch 581/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.9440e-05 - accuracy: 1.0000 - val_loss: 0.1999 - val_accuracy: 0.9565\n",
      "Epoch 582/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.9032e-05 - accuracy: 1.0000 - val_loss: 0.2007 - val_accuracy: 0.9565\n",
      "Epoch 583/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.8654e-05 - accuracy: 1.0000 - val_loss: 0.2011 - val_accuracy: 0.9565\n",
      "Epoch 584/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.8502e-05 - accuracy: 1.0000 - val_loss: 0.2010 - val_accuracy: 0.9565\n",
      "Epoch 585/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.8082e-05 - accuracy: 1.0000 - val_loss: 0.2020 - val_accuracy: 0.9565\n",
      "Epoch 586/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.7633e-05 - accuracy: 1.0000 - val_loss: 0.2017 - val_accuracy: 0.9565\n",
      "Epoch 587/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.7159e-05 - accuracy: 1.0000 - val_loss: 0.2013 - val_accuracy: 0.9565\n",
      "Epoch 588/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.7415e-05 - accuracy: 1.0000 - val_loss: 0.2023 - val_accuracy: 0.9565\n",
      "Epoch 589/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.6667e-05 - accuracy: 1.0000 - val_loss: 0.2020 - val_accuracy: 0.9565\n",
      "Epoch 590/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.6357e-05 - accuracy: 1.0000 - val_loss: 0.2029 - val_accuracy: 0.9565\n",
      "Epoch 591/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.5661e-05 - accuracy: 1.0000 - val_loss: 0.2024 - val_accuracy: 0.9565\n",
      "Epoch 592/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.5493e-05 - accuracy: 1.0000 - val_loss: 0.2027 - val_accuracy: 0.9565\n",
      "Epoch 593/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.5091e-05 - accuracy: 1.0000 - val_loss: 0.2032 - val_accuracy: 0.9565\n",
      "Epoch 594/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.5038e-05 - accuracy: 1.0000 - val_loss: 0.2026 - val_accuracy: 0.9565\n",
      "Epoch 595/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.4616e-05 - accuracy: 1.0000 - val_loss: 0.2036 - val_accuracy: 0.9565\n",
      "Epoch 596/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.4057e-05 - accuracy: 1.0000 - val_loss: 0.2041 - val_accuracy: 0.9565\n",
      "Epoch 597/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.3480e-05 - accuracy: 1.0000 - val_loss: 0.2045 - val_accuracy: 0.9565\n",
      "Epoch 598/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.3475e-05 - accuracy: 1.0000 - val_loss: 0.2048 - val_accuracy: 0.9565\n",
      "Epoch 599/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.2872e-05 - accuracy: 1.0000 - val_loss: 0.2043 - val_accuracy: 0.9565\n",
      "Epoch 600/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.2806e-05 - accuracy: 1.0000 - val_loss: 0.2046 - val_accuracy: 0.9565\n",
      "Epoch 601/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.2956e-05 - accuracy: 1.0000 - val_loss: 0.2043 - val_accuracy: 0.9565\n",
      "Epoch 602/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.2103e-05 - accuracy: 1.0000 - val_loss: 0.2053 - val_accuracy: 0.9565\n",
      "Epoch 603/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.1627e-05 - accuracy: 1.0000 - val_loss: 0.2054 - val_accuracy: 0.9565\n",
      "Epoch 604/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.1463e-05 - accuracy: 1.0000 - val_loss: 0.2065 - val_accuracy: 0.9565\n",
      "Epoch 605/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.0941e-05 - accuracy: 1.0000 - val_loss: 0.2068 - val_accuracy: 0.9565\n",
      "Epoch 606/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.1058e-05 - accuracy: 1.0000 - val_loss: 0.2071 - val_accuracy: 0.9565\n",
      "Epoch 607/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.0399e-05 - accuracy: 1.0000 - val_loss: 0.2069 - val_accuracy: 0.9565\n",
      "Epoch 608/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.0125e-05 - accuracy: 1.0000 - val_loss: 0.2072 - val_accuracy: 0.9565\n",
      "Epoch 609/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.9963e-05 - accuracy: 1.0000 - val_loss: 0.2081 - val_accuracy: 0.9565\n",
      "Epoch 610/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.9987e-05 - accuracy: 1.0000 - val_loss: 0.2088 - val_accuracy: 0.9565\n",
      "Epoch 611/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.9316e-05 - accuracy: 1.0000 - val_loss: 0.2073 - val_accuracy: 0.9565\n",
      "Epoch 612/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.9075e-05 - accuracy: 1.0000 - val_loss: 0.2076 - val_accuracy: 0.9565\n",
      "Epoch 613/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.8784e-05 - accuracy: 1.0000 - val_loss: 0.2083 - val_accuracy: 0.9565\n",
      "Epoch 614/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.8418e-05 - accuracy: 1.0000 - val_loss: 0.2084 - val_accuracy: 0.9565\n",
      "Epoch 615/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.7951e-05 - accuracy: 1.0000 - val_loss: 0.2088 - val_accuracy: 0.9565\n",
      "Epoch 616/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.7625e-05 - accuracy: 1.0000 - val_loss: 0.2090 - val_accuracy: 0.9565\n",
      "Epoch 617/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.7710e-05 - accuracy: 1.0000 - val_loss: 0.2082 - val_accuracy: 0.9565\n",
      "Epoch 618/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.7851e-05 - accuracy: 1.0000 - val_loss: 0.2096 - val_accuracy: 0.9565\n",
      "Epoch 619/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.6770e-05 - accuracy: 1.0000 - val_loss: 0.2096 - val_accuracy: 0.9565\n",
      "Epoch 620/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.6510e-05 - accuracy: 1.0000 - val_loss: 0.2100 - val_accuracy: 0.9565\n",
      "Epoch 621/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.6881e-05 - accuracy: 1.0000 - val_loss: 0.2110 - val_accuracy: 0.9565\n",
      "Epoch 622/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.6148e-05 - accuracy: 1.0000 - val_loss: 0.2097 - val_accuracy: 0.9565\n",
      "Epoch 623/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.6413e-05 - accuracy: 1.0000 - val_loss: 0.2107 - val_accuracy: 0.9565\n",
      "Epoch 624/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.5409e-05 - accuracy: 1.0000 - val_loss: 0.2112 - val_accuracy: 0.9565\n",
      "Epoch 625/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.5078e-05 - accuracy: 1.0000 - val_loss: 0.2108 - val_accuracy: 0.9565\n",
      "Epoch 626/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.4837e-05 - accuracy: 1.0000 - val_loss: 0.2106 - val_accuracy: 0.9565\n",
      "Epoch 627/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.4675e-05 - accuracy: 1.0000 - val_loss: 0.2111 - val_accuracy: 0.9565\n",
      "Epoch 628/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.4726e-05 - accuracy: 1.0000 - val_loss: 0.2111 - val_accuracy: 0.9565\n",
      "Epoch 629/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.4051e-05 - accuracy: 1.0000 - val_loss: 0.2118 - val_accuracy: 0.9565\n",
      "Epoch 630/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.3760e-05 - accuracy: 1.0000 - val_loss: 0.2124 - val_accuracy: 0.9565\n",
      "Epoch 631/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.3623e-05 - accuracy: 1.0000 - val_loss: 0.2129 - val_accuracy: 0.9565\n",
      "Epoch 632/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.3766e-05 - accuracy: 1.0000 - val_loss: 0.2142 - val_accuracy: 0.9565\n",
      "Epoch 633/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.3384e-05 - accuracy: 1.0000 - val_loss: 0.2132 - val_accuracy: 0.9565\n",
      "Epoch 634/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.2970e-05 - accuracy: 1.0000 - val_loss: 0.2139 - val_accuracy: 0.9565\n",
      "Epoch 635/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.2973e-05 - accuracy: 1.0000 - val_loss: 0.2147 - val_accuracy: 0.9565\n",
      "Epoch 636/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.2419e-05 - accuracy: 1.0000 - val_loss: 0.2135 - val_accuracy: 0.9565\n",
      "Epoch 637/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.2412e-05 - accuracy: 1.0000 - val_loss: 0.2147 - val_accuracy: 0.9565\n",
      "Epoch 638/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.1908e-05 - accuracy: 1.0000 - val_loss: 0.2156 - val_accuracy: 0.9565\n",
      "Epoch 639/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.1638e-05 - accuracy: 1.0000 - val_loss: 0.2142 - val_accuracy: 0.9565\n",
      "Epoch 640/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.1412e-05 - accuracy: 1.0000 - val_loss: 0.2143 - val_accuracy: 0.9565\n",
      "Epoch 641/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.1097e-05 - accuracy: 1.0000 - val_loss: 0.2147 - val_accuracy: 0.9565\n",
      "Epoch 642/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.1202e-05 - accuracy: 1.0000 - val_loss: 0.2160 - val_accuracy: 0.9565\n",
      "Epoch 643/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.0582e-05 - accuracy: 1.0000 - val_loss: 0.2160 - val_accuracy: 0.9565\n",
      "Epoch 644/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.0572e-05 - accuracy: 1.0000 - val_loss: 0.2166 - val_accuracy: 0.9565\n",
      "Epoch 645/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.0099e-05 - accuracy: 1.0000 - val_loss: 0.2169 - val_accuracy: 0.9565\n",
      "Epoch 646/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.9857e-05 - accuracy: 1.0000 - val_loss: 0.2166 - val_accuracy: 0.9565\n",
      "Epoch 647/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.0122e-05 - accuracy: 1.0000 - val_loss: 0.2176 - val_accuracy: 0.9565\n",
      "Epoch 648/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.9350e-05 - accuracy: 1.0000 - val_loss: 0.2174 - val_accuracy: 0.9565\n",
      "Epoch 649/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.9175e-05 - accuracy: 1.0000 - val_loss: 0.2176 - val_accuracy: 0.9565\n",
      "Epoch 650/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.9117e-05 - accuracy: 1.0000 - val_loss: 0.2181 - val_accuracy: 0.9565\n",
      "Epoch 651/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.8930e-05 - accuracy: 1.0000 - val_loss: 0.2175 - val_accuracy: 0.9565\n",
      "Epoch 652/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.8563e-05 - accuracy: 1.0000 - val_loss: 0.2185 - val_accuracy: 0.9565\n",
      "Epoch 653/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.8438e-05 - accuracy: 1.0000 - val_loss: 0.2181 - val_accuracy: 0.9565\n",
      "Epoch 654/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.8366e-05 - accuracy: 1.0000 - val_loss: 0.2183 - val_accuracy: 0.9565\n",
      "Epoch 655/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.7885e-05 - accuracy: 1.0000 - val_loss: 0.2192 - val_accuracy: 0.9565\n",
      "Epoch 656/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.7992e-05 - accuracy: 1.0000 - val_loss: 0.2205 - val_accuracy: 0.9565\n",
      "Epoch 657/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.7965e-05 - accuracy: 1.0000 - val_loss: 0.2191 - val_accuracy: 0.9565\n",
      "Epoch 658/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.7438e-05 - accuracy: 1.0000 - val_loss: 0.2203 - val_accuracy: 0.9565\n",
      "Epoch 659/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.7467e-05 - accuracy: 1.0000 - val_loss: 0.2212 - val_accuracy: 0.9565\n",
      "Epoch 660/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.6773e-05 - accuracy: 1.0000 - val_loss: 0.2206 - val_accuracy: 0.9565\n",
      "Epoch 661/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.7065e-05 - accuracy: 1.0000 - val_loss: 0.2195 - val_accuracy: 0.9565\n",
      "Epoch 662/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.6721e-05 - accuracy: 1.0000 - val_loss: 0.2211 - val_accuracy: 0.9565\n",
      "Epoch 663/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.6335e-05 - accuracy: 1.0000 - val_loss: 0.2215 - val_accuracy: 0.9565\n",
      "Epoch 664/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.6583e-05 - accuracy: 1.0000 - val_loss: 0.2208 - val_accuracy: 0.9565\n",
      "Epoch 665/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.6059e-05 - accuracy: 1.0000 - val_loss: 0.2217 - val_accuracy: 0.9565\n",
      "Epoch 666/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.5561e-05 - accuracy: 1.0000 - val_loss: 0.2222 - val_accuracy: 0.9565\n",
      "Epoch 667/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.5606e-05 - accuracy: 1.0000 - val_loss: 0.2219 - val_accuracy: 0.9565\n",
      "Epoch 668/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.5401e-05 - accuracy: 1.0000 - val_loss: 0.2232 - val_accuracy: 0.9565\n",
      "Epoch 669/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.5204e-05 - accuracy: 1.0000 - val_loss: 0.2228 - val_accuracy: 0.9565\n",
      "Epoch 670/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.5061e-05 - accuracy: 1.0000 - val_loss: 0.2223 - val_accuracy: 0.9565\n",
      "Epoch 671/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.4777e-05 - accuracy: 1.0000 - val_loss: 0.2234 - val_accuracy: 0.9565\n",
      "Epoch 672/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.4678e-05 - accuracy: 1.0000 - val_loss: 0.2233 - val_accuracy: 0.9565\n",
      "Epoch 673/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.4352e-05 - accuracy: 1.0000 - val_loss: 0.2233 - val_accuracy: 0.9565\n",
      "Epoch 674/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.4266e-05 - accuracy: 1.0000 - val_loss: 0.2236 - val_accuracy: 0.9565\n",
      "Epoch 675/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.4007e-05 - accuracy: 1.0000 - val_loss: 0.2246 - val_accuracy: 0.9565\n",
      "Epoch 676/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.3814e-05 - accuracy: 1.0000 - val_loss: 0.2243 - val_accuracy: 0.9565\n",
      "Epoch 677/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.3834e-05 - accuracy: 1.0000 - val_loss: 0.2254 - val_accuracy: 0.9565\n",
      "Epoch 678/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.3699e-05 - accuracy: 1.0000 - val_loss: 0.2245 - val_accuracy: 0.9565\n",
      "Epoch 679/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.3412e-05 - accuracy: 1.0000 - val_loss: 0.2245 - val_accuracy: 0.9565\n",
      "Epoch 680/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.3166e-05 - accuracy: 1.0000 - val_loss: 0.2254 - val_accuracy: 0.9565\n",
      "Epoch 681/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.2945e-05 - accuracy: 1.0000 - val_loss: 0.2258 - val_accuracy: 0.9565\n",
      "Epoch 682/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.2830e-05 - accuracy: 1.0000 - val_loss: 0.2262 - val_accuracy: 0.9565\n",
      "Epoch 683/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.2687e-05 - accuracy: 1.0000 - val_loss: 0.2264 - val_accuracy: 0.9565\n",
      "Epoch 684/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.2356e-05 - accuracy: 1.0000 - val_loss: 0.2267 - val_accuracy: 0.9565\n",
      "Epoch 685/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.2412e-05 - accuracy: 1.0000 - val_loss: 0.2264 - val_accuracy: 0.9565\n",
      "Epoch 686/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.2064e-05 - accuracy: 1.0000 - val_loss: 0.2271 - val_accuracy: 0.9565\n",
      "Epoch 687/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.2032e-05 - accuracy: 1.0000 - val_loss: 0.2273 - val_accuracy: 0.9565\n",
      "Epoch 688/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.1883e-05 - accuracy: 1.0000 - val_loss: 0.2281 - val_accuracy: 0.9565\n",
      "Epoch 689/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.1776e-05 - accuracy: 1.0000 - val_loss: 0.2278 - val_accuracy: 0.9565\n",
      "Epoch 690/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.1545e-05 - accuracy: 1.0000 - val_loss: 0.2290 - val_accuracy: 0.9565\n",
      "Epoch 691/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.1305e-05 - accuracy: 1.0000 - val_loss: 0.2284 - val_accuracy: 0.9565\n",
      "Epoch 692/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.1086e-05 - accuracy: 1.0000 - val_loss: 0.2280 - val_accuracy: 0.9565\n",
      "Epoch 693/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.0986e-05 - accuracy: 1.0000 - val_loss: 0.2285 - val_accuracy: 0.9565\n",
      "Epoch 694/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.0901e-05 - accuracy: 1.0000 - val_loss: 0.2287 - val_accuracy: 0.9565\n",
      "Epoch 695/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.0710e-05 - accuracy: 1.0000 - val_loss: 0.2292 - val_accuracy: 0.9565\n",
      "Epoch 696/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.0657e-05 - accuracy: 1.0000 - val_loss: 0.2287 - val_accuracy: 0.9565\n",
      "Epoch 697/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.0260e-05 - accuracy: 1.0000 - val_loss: 0.2296 - val_accuracy: 0.9565\n",
      "Epoch 698/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.0214e-05 - accuracy: 1.0000 - val_loss: 0.2304 - val_accuracy: 0.9565\n",
      "Epoch 699/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.0033e-05 - accuracy: 1.0000 - val_loss: 0.2304 - val_accuracy: 0.9565\n",
      "Epoch 700/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.0029e-05 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.9565\n",
      "Epoch 701/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.9799e-05 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.9565\n",
      "Epoch 702/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.9823e-05 - accuracy: 1.0000 - val_loss: 0.2312 - val_accuracy: 0.9565\n",
      "Epoch 703/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.9652e-05 - accuracy: 1.0000 - val_loss: 0.2311 - val_accuracy: 0.9565\n",
      "Epoch 704/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.9455e-05 - accuracy: 1.0000 - val_loss: 0.2309 - val_accuracy: 0.9565\n",
      "Epoch 705/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.9164e-05 - accuracy: 1.0000 - val_loss: 0.2313 - val_accuracy: 0.9565\n",
      "Epoch 706/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.9175e-05 - accuracy: 1.0000 - val_loss: 0.2323 - val_accuracy: 0.9565\n",
      "Epoch 707/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.8819e-05 - accuracy: 1.0000 - val_loss: 0.2325 - val_accuracy: 0.9565\n",
      "Epoch 708/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.8774e-05 - accuracy: 1.0000 - val_loss: 0.2320 - val_accuracy: 0.9565\n",
      "Epoch 709/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.8625e-05 - accuracy: 1.0000 - val_loss: 0.2321 - val_accuracy: 0.9565\n",
      "Epoch 710/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.8416e-05 - accuracy: 1.0000 - val_loss: 0.2328 - val_accuracy: 0.9565\n",
      "Epoch 711/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.8473e-05 - accuracy: 1.0000 - val_loss: 0.2339 - val_accuracy: 0.9565\n",
      "Epoch 712/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.8347e-05 - accuracy: 1.0000 - val_loss: 0.2339 - val_accuracy: 0.9565\n",
      "Epoch 713/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.8329e-05 - accuracy: 1.0000 - val_loss: 0.2330 - val_accuracy: 0.9565\n",
      "Epoch 714/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.8146e-05 - accuracy: 1.0000 - val_loss: 0.2333 - val_accuracy: 0.9565\n",
      "Epoch 715/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.7800e-05 - accuracy: 1.0000 - val_loss: 0.2342 - val_accuracy: 0.9565\n",
      "Epoch 716/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.7694e-05 - accuracy: 1.0000 - val_loss: 0.2346 - val_accuracy: 0.9565\n",
      "Epoch 717/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.7611e-05 - accuracy: 1.0000 - val_loss: 0.2349 - val_accuracy: 0.9565\n",
      "Epoch 718/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.7361e-05 - accuracy: 1.0000 - val_loss: 0.2354 - val_accuracy: 0.9565\n",
      "Epoch 719/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.7527e-05 - accuracy: 1.0000 - val_loss: 0.2339 - val_accuracy: 0.9565\n",
      "Epoch 720/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.7148e-05 - accuracy: 1.0000 - val_loss: 0.2352 - val_accuracy: 0.9565\n",
      "Epoch 721/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.7097e-05 - accuracy: 1.0000 - val_loss: 0.2352 - val_accuracy: 0.9565\n",
      "Epoch 722/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.6854e-05 - accuracy: 1.0000 - val_loss: 0.2362 - val_accuracy: 0.9565\n",
      "Epoch 723/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.7023e-05 - accuracy: 1.0000 - val_loss: 0.2371 - val_accuracy: 0.9565\n",
      "Epoch 724/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6600e-05 - accuracy: 1.0000 - val_loss: 0.2367 - val_accuracy: 0.9565\n",
      "Epoch 725/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.6503e-05 - accuracy: 1.0000 - val_loss: 0.2367 - val_accuracy: 0.9565\n",
      "Epoch 726/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.6472e-05 - accuracy: 1.0000 - val_loss: 0.2368 - val_accuracy: 0.9565\n",
      "Epoch 727/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.6272e-05 - accuracy: 1.0000 - val_loss: 0.2376 - val_accuracy: 0.9565\n",
      "Epoch 728/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.6143e-05 - accuracy: 1.0000 - val_loss: 0.2376 - val_accuracy: 0.9565\n",
      "Epoch 729/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.6121e-05 - accuracy: 1.0000 - val_loss: 0.2373 - val_accuracy: 0.9565\n",
      "Epoch 730/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5912e-05 - accuracy: 1.0000 - val_loss: 0.2382 - val_accuracy: 0.9565\n",
      "Epoch 731/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.5805e-05 - accuracy: 1.0000 - val_loss: 0.2387 - val_accuracy: 0.9565\n",
      "Epoch 732/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.5755e-05 - accuracy: 1.0000 - val_loss: 0.2393 - val_accuracy: 0.9565\n",
      "Epoch 733/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.5511e-05 - accuracy: 1.0000 - val_loss: 0.2390 - val_accuracy: 0.9565\n",
      "Epoch 734/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.5474e-05 - accuracy: 1.0000 - val_loss: 0.2391 - val_accuracy: 0.9565\n",
      "Epoch 735/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.5430e-05 - accuracy: 1.0000 - val_loss: 0.2393 - val_accuracy: 0.9565\n",
      "Epoch 736/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5303e-05 - accuracy: 1.0000 - val_loss: 0.2402 - val_accuracy: 0.9565\n",
      "Epoch 737/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.5078e-05 - accuracy: 1.0000 - val_loss: 0.2402 - val_accuracy: 0.9565\n",
      "Epoch 738/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.5061e-05 - accuracy: 1.0000 - val_loss: 0.2401 - val_accuracy: 0.9565\n",
      "Epoch 739/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.4908e-05 - accuracy: 1.0000 - val_loss: 0.2405 - val_accuracy: 0.9565\n",
      "Epoch 740/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.4772e-05 - accuracy: 1.0000 - val_loss: 0.2405 - val_accuracy: 0.9565\n",
      "Epoch 741/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.4710e-05 - accuracy: 1.0000 - val_loss: 0.2405 - val_accuracy: 0.9565\n",
      "Epoch 742/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.4702e-05 - accuracy: 1.0000 - val_loss: 0.2420 - val_accuracy: 0.9565\n",
      "Epoch 743/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.4470e-05 - accuracy: 1.0000 - val_loss: 0.2421 - val_accuracy: 0.9565\n",
      "Epoch 744/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.4400e-05 - accuracy: 1.0000 - val_loss: 0.2417 - val_accuracy: 0.9565\n",
      "Epoch 745/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.4283e-05 - accuracy: 1.0000 - val_loss: 0.2422 - val_accuracy: 0.9565\n",
      "Epoch 746/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.4157e-05 - accuracy: 1.0000 - val_loss: 0.2417 - val_accuracy: 0.9565\n",
      "Epoch 747/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.4104e-05 - accuracy: 1.0000 - val_loss: 0.2424 - val_accuracy: 0.9565\n",
      "Epoch 748/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.4008e-05 - accuracy: 1.0000 - val_loss: 0.2434 - val_accuracy: 0.9565\n",
      "Epoch 749/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.3819e-05 - accuracy: 1.0000 - val_loss: 0.2432 - val_accuracy: 0.9565\n",
      "Epoch 750/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3858e-05 - accuracy: 1.0000 - val_loss: 0.2419 - val_accuracy: 0.9565\n",
      "Epoch 751/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.3611e-05 - accuracy: 1.0000 - val_loss: 0.2428 - val_accuracy: 0.9565\n",
      "Epoch 752/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.3509e-05 - accuracy: 1.0000 - val_loss: 0.2437 - val_accuracy: 0.9565\n",
      "Epoch 753/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.3496e-05 - accuracy: 1.0000 - val_loss: 0.2441 - val_accuracy: 0.9565\n",
      "Epoch 754/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.3498e-05 - accuracy: 1.0000 - val_loss: 0.2455 - val_accuracy: 0.9565\n",
      "Epoch 755/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.3379e-05 - accuracy: 1.0000 - val_loss: 0.2442 - val_accuracy: 0.9565\n",
      "Epoch 756/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.3207e-05 - accuracy: 1.0000 - val_loss: 0.2449 - val_accuracy: 0.9565\n",
      "Epoch 757/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.3180e-05 - accuracy: 1.0000 - val_loss: 0.2445 - val_accuracy: 0.9565\n",
      "Epoch 758/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.2949e-05 - accuracy: 1.0000 - val_loss: 0.2456 - val_accuracy: 0.9565\n",
      "Epoch 759/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.2919e-05 - accuracy: 1.0000 - val_loss: 0.2461 - val_accuracy: 0.9565\n",
      "Epoch 760/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.2858e-05 - accuracy: 1.0000 - val_loss: 0.2458 - val_accuracy: 0.9565\n",
      "Epoch 761/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.2738e-05 - accuracy: 1.0000 - val_loss: 0.2467 - val_accuracy: 0.9565\n",
      "Epoch 762/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.2613e-05 - accuracy: 1.0000 - val_loss: 0.2467 - val_accuracy: 0.9565\n",
      "Epoch 763/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.2584e-05 - accuracy: 1.0000 - val_loss: 0.2462 - val_accuracy: 0.9565\n",
      "Epoch 764/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.2432e-05 - accuracy: 1.0000 - val_loss: 0.2467 - val_accuracy: 0.9565\n",
      "Epoch 765/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.2272e-05 - accuracy: 1.0000 - val_loss: 0.2474 - val_accuracy: 0.9565\n",
      "Epoch 766/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.2261e-05 - accuracy: 1.0000 - val_loss: 0.2470 - val_accuracy: 0.9565\n",
      "Epoch 767/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.2211e-05 - accuracy: 1.0000 - val_loss: 0.2479 - val_accuracy: 0.9565\n",
      "Epoch 768/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.2096e-05 - accuracy: 1.0000 - val_loss: 0.2488 - val_accuracy: 0.9565\n",
      "Epoch 769/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1852e-05 - accuracy: 1.0000 - val_loss: 0.2481 - val_accuracy: 0.9565\n",
      "Epoch 770/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.1872e-05 - accuracy: 1.0000 - val_loss: 0.2479 - val_accuracy: 0.9565\n",
      "Epoch 771/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.1854e-05 - accuracy: 1.0000 - val_loss: 0.2484 - val_accuracy: 0.9565\n",
      "Epoch 772/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1828e-05 - accuracy: 1.0000 - val_loss: 0.2476 - val_accuracy: 0.9565\n",
      "Epoch 773/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1621e-05 - accuracy: 1.0000 - val_loss: 0.2484 - val_accuracy: 0.9565\n",
      "Epoch 774/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1469e-05 - accuracy: 1.0000 - val_loss: 0.2489 - val_accuracy: 0.9565\n",
      "Epoch 775/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.1359e-05 - accuracy: 1.0000 - val_loss: 0.2492 - val_accuracy: 0.9565\n",
      "Epoch 776/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.1393e-05 - accuracy: 1.0000 - val_loss: 0.2497 - val_accuracy: 0.9565\n",
      "Epoch 777/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.1254e-05 - accuracy: 1.0000 - val_loss: 0.2506 - val_accuracy: 0.9565\n",
      "Epoch 778/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1196e-05 - accuracy: 1.0000 - val_loss: 0.2504 - val_accuracy: 0.9565\n",
      "Epoch 779/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1112e-05 - accuracy: 1.0000 - val_loss: 0.2502 - val_accuracy: 0.9565\n",
      "Epoch 780/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.1057e-05 - accuracy: 1.0000 - val_loss: 0.2510 - val_accuracy: 0.9565\n",
      "Epoch 781/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.0909e-05 - accuracy: 1.0000 - val_loss: 0.2515 - val_accuracy: 0.9565\n",
      "Epoch 782/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.0880e-05 - accuracy: 1.0000 - val_loss: 0.2520 - val_accuracy: 0.9565\n",
      "Epoch 783/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0798e-05 - accuracy: 1.0000 - val_loss: 0.2515 - val_accuracy: 0.9565\n",
      "Epoch 784/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.0693e-05 - accuracy: 1.0000 - val_loss: 0.2522 - val_accuracy: 0.9565\n",
      "Epoch 785/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.0640e-05 - accuracy: 1.0000 - val_loss: 0.2530 - val_accuracy: 0.9565\n",
      "Epoch 786/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.0543e-05 - accuracy: 1.0000 - val_loss: 0.2533 - val_accuracy: 0.9565\n",
      "Epoch 787/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0453e-05 - accuracy: 1.0000 - val_loss: 0.2525 - val_accuracy: 0.9565\n",
      "Epoch 788/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.0429e-05 - accuracy: 1.0000 - val_loss: 0.2526 - val_accuracy: 0.9565\n",
      "Epoch 789/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.0581e-05 - accuracy: 1.0000 - val_loss: 0.2537 - val_accuracy: 0.9565\n",
      "Epoch 790/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.0216e-05 - accuracy: 1.0000 - val_loss: 0.2532 - val_accuracy: 0.9565\n",
      "Epoch 791/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.0188e-05 - accuracy: 1.0000 - val_loss: 0.2529 - val_accuracy: 0.9565\n",
      "Epoch 792/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.0095e-05 - accuracy: 1.0000 - val_loss: 0.2535 - val_accuracy: 0.9565\n",
      "Epoch 793/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.9746e-06 - accuracy: 1.0000 - val_loss: 0.2537 - val_accuracy: 0.9565\n",
      "Epoch 794/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.0130e-05 - accuracy: 1.0000 - val_loss: 0.2553 - val_accuracy: 0.9565\n",
      "Epoch 795/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.8918e-06 - accuracy: 1.0000 - val_loss: 0.2554 - val_accuracy: 0.9565\n",
      "Epoch 796/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.7230e-06 - accuracy: 1.0000 - val_loss: 0.2552 - val_accuracy: 0.9565\n",
      "Epoch 797/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.6803e-06 - accuracy: 1.0000 - val_loss: 0.2551 - val_accuracy: 0.9565\n",
      "Epoch 798/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.6419e-06 - accuracy: 1.0000 - val_loss: 0.2549 - val_accuracy: 0.9565\n",
      "Epoch 799/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.5742e-06 - accuracy: 1.0000 - val_loss: 0.2556 - val_accuracy: 0.9565\n",
      "Epoch 800/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 9.5580e-06 - accuracy: 1.0000 - val_loss: 0.2550 - val_accuracy: 0.9565\n",
      "Epoch 801/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 9.6045e-06 - accuracy: 1.0000 - val_loss: 0.2565 - val_accuracy: 0.9565\n",
      "Epoch 802/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 9.3658e-06 - accuracy: 1.0000 - val_loss: 0.2567 - val_accuracy: 0.9565\n",
      "Epoch 803/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 9.2915e-06 - accuracy: 1.0000 - val_loss: 0.2575 - val_accuracy: 0.9565\n",
      "Epoch 804/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 9.1960e-06 - accuracy: 1.0000 - val_loss: 0.2568 - val_accuracy: 0.9565\n",
      "Epoch 805/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 9.1395e-06 - accuracy: 1.0000 - val_loss: 0.2564 - val_accuracy: 0.9565\n",
      "Epoch 806/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 9.0934e-06 - accuracy: 1.0000 - val_loss: 0.2579 - val_accuracy: 0.9565\n",
      "Epoch 807/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 9.0106e-06 - accuracy: 1.0000 - val_loss: 0.2585 - val_accuracy: 0.9565\n",
      "Epoch 808/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.9433e-06 - accuracy: 1.0000 - val_loss: 0.2582 - val_accuracy: 0.9565\n",
      "Epoch 809/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.8869e-06 - accuracy: 1.0000 - val_loss: 0.2584 - val_accuracy: 0.9565\n",
      "Epoch 810/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 8.7814e-06 - accuracy: 1.0000 - val_loss: 0.2584 - val_accuracy: 0.9565\n",
      "Epoch 811/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.7581e-06 - accuracy: 1.0000 - val_loss: 0.2585 - val_accuracy: 0.9565\n",
      "Epoch 812/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.7051e-06 - accuracy: 1.0000 - val_loss: 0.2589 - val_accuracy: 0.9565\n",
      "Epoch 813/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.6098e-06 - accuracy: 1.0000 - val_loss: 0.2591 - val_accuracy: 0.9565\n",
      "Epoch 814/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 8.5509e-06 - accuracy: 1.0000 - val_loss: 0.2598 - val_accuracy: 0.9565\n",
      "Epoch 815/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 8.5081e-06 - accuracy: 1.0000 - val_loss: 0.2598 - val_accuracy: 0.9565\n",
      "Epoch 816/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.4757e-06 - accuracy: 1.0000 - val_loss: 0.2608 - val_accuracy: 0.9565\n",
      "Epoch 817/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.4046e-06 - accuracy: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.9565\n",
      "Epoch 818/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.3190e-06 - accuracy: 1.0000 - val_loss: 0.2599 - val_accuracy: 0.9565\n",
      "Epoch 819/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.3530e-06 - accuracy: 1.0000 - val_loss: 0.2610 - val_accuracy: 0.9565\n",
      "Epoch 820/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.1651e-06 - accuracy: 1.0000 - val_loss: 0.2608 - val_accuracy: 0.9565\n",
      "Epoch 821/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 8.1539e-06 - accuracy: 1.0000 - val_loss: 0.2610 - val_accuracy: 0.9565\n",
      "Epoch 822/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.1121e-06 - accuracy: 1.0000 - val_loss: 0.2614 - val_accuracy: 0.9565\n",
      "Epoch 823/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.0809e-06 - accuracy: 1.0000 - val_loss: 0.2616 - val_accuracy: 0.9565\n",
      "Epoch 824/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 7.9519e-06 - accuracy: 1.0000 - val_loss: 0.2616 - val_accuracy: 0.9565\n",
      "Epoch 825/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 7.9155e-06 - accuracy: 1.0000 - val_loss: 0.2616 - val_accuracy: 0.9565\n",
      "Epoch 826/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 7.8255e-06 - accuracy: 1.0000 - val_loss: 0.2620 - val_accuracy: 0.9565\n",
      "Epoch 827/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 7.7645e-06 - accuracy: 1.0000 - val_loss: 0.2625 - val_accuracy: 0.9565\n",
      "Epoch 828/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 7.7613e-06 - accuracy: 1.0000 - val_loss: 0.2630 - val_accuracy: 0.9565\n",
      "Epoch 829/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 7.6762e-06 - accuracy: 1.0000 - val_loss: 0.2637 - val_accuracy: 0.9565\n",
      "Epoch 830/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 7.6523e-06 - accuracy: 1.0000 - val_loss: 0.2636 - val_accuracy: 0.9565\n",
      "Epoch 831/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 7.6156e-06 - accuracy: 1.0000 - val_loss: 0.2629 - val_accuracy: 0.9565\n",
      "Epoch 832/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 7.5402e-06 - accuracy: 1.0000 - val_loss: 0.2640 - val_accuracy: 0.9565\n",
      "Epoch 833/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 7.4399e-06 - accuracy: 1.0000 - val_loss: 0.2643 - val_accuracy: 0.9565\n",
      "Epoch 834/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 7.4148e-06 - accuracy: 1.0000 - val_loss: 0.2644 - val_accuracy: 0.9565\n",
      "Epoch 835/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 7.3365e-06 - accuracy: 1.0000 - val_loss: 0.2647 - val_accuracy: 0.9565\n",
      "Epoch 836/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 7.2908e-06 - accuracy: 1.0000 - val_loss: 0.2648 - val_accuracy: 0.9565\n",
      "Epoch 837/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 7.3070e-06 - accuracy: 1.0000 - val_loss: 0.2654 - val_accuracy: 0.9565\n",
      "Epoch 838/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 7.1832e-06 - accuracy: 1.0000 - val_loss: 0.2652 - val_accuracy: 0.9565\n",
      "Epoch 839/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 7.1669e-06 - accuracy: 1.0000 - val_loss: 0.2654 - val_accuracy: 0.9565\n",
      "Epoch 840/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 7.1208e-06 - accuracy: 1.0000 - val_loss: 0.2666 - val_accuracy: 0.9565\n",
      "Epoch 841/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.0186e-06 - accuracy: 1.0000 - val_loss: 0.2659 - val_accuracy: 0.9565\n",
      "Epoch 842/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 7.0096e-06 - accuracy: 1.0000 - val_loss: 0.2656 - val_accuracy: 0.9565\n",
      "Epoch 843/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 7.0008e-06 - accuracy: 1.0000 - val_loss: 0.2668 - val_accuracy: 0.9565\n",
      "Epoch 844/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.8773e-06 - accuracy: 1.0000 - val_loss: 0.2671 - val_accuracy: 0.9565\n",
      "Epoch 845/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.8648e-06 - accuracy: 1.0000 - val_loss: 0.2671 - val_accuracy: 0.9565\n",
      "Epoch 846/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.7599e-06 - accuracy: 1.0000 - val_loss: 0.2673 - val_accuracy: 0.9565\n",
      "Epoch 847/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.7208e-06 - accuracy: 1.0000 - val_loss: 0.2677 - val_accuracy: 0.9565\n",
      "Epoch 848/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.7193e-06 - accuracy: 1.0000 - val_loss: 0.2684 - val_accuracy: 0.9565\n",
      "Epoch 849/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 6.6739e-06 - accuracy: 1.0000 - val_loss: 0.2674 - val_accuracy: 0.9565\n",
      "Epoch 850/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.5635e-06 - accuracy: 1.0000 - val_loss: 0.2684 - val_accuracy: 0.9565\n",
      "Epoch 851/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 6.5026e-06 - accuracy: 1.0000 - val_loss: 0.2686 - val_accuracy: 0.9565\n",
      "Epoch 852/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.5209e-06 - accuracy: 1.0000 - val_loss: 0.2698 - val_accuracy: 0.9565\n",
      "Epoch 853/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.4591e-06 - accuracy: 1.0000 - val_loss: 0.2698 - val_accuracy: 0.9565\n",
      "Epoch 854/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.4189e-06 - accuracy: 1.0000 - val_loss: 0.2697 - val_accuracy: 0.9565\n",
      "Epoch 855/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.3720e-06 - accuracy: 1.0000 - val_loss: 0.2703 - val_accuracy: 0.9565\n",
      "Epoch 856/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.3373e-06 - accuracy: 1.0000 - val_loss: 0.2696 - val_accuracy: 0.9565\n",
      "Epoch 857/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.2599e-06 - accuracy: 1.0000 - val_loss: 0.2699 - val_accuracy: 0.9565\n",
      "Epoch 858/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.2287e-06 - accuracy: 1.0000 - val_loss: 0.2698 - val_accuracy: 0.9565\n",
      "Epoch 859/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.1614e-06 - accuracy: 1.0000 - val_loss: 0.2709 - val_accuracy: 0.9565\n",
      "Epoch 860/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.1512e-06 - accuracy: 1.0000 - val_loss: 0.2710 - val_accuracy: 0.9565\n",
      "Epoch 861/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.1706e-06 - accuracy: 1.0000 - val_loss: 0.2721 - val_accuracy: 0.9565\n",
      "Epoch 862/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.0856e-06 - accuracy: 1.0000 - val_loss: 0.2710 - val_accuracy: 0.9565\n",
      "Epoch 863/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.9848e-06 - accuracy: 1.0000 - val_loss: 0.2716 - val_accuracy: 0.9565\n",
      "Epoch 864/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.9661e-06 - accuracy: 1.0000 - val_loss: 0.2724 - val_accuracy: 0.9565\n",
      "Epoch 865/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.9017e-06 - accuracy: 1.0000 - val_loss: 0.2723 - val_accuracy: 0.9565\n",
      "Epoch 866/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.8548e-06 - accuracy: 1.0000 - val_loss: 0.2724 - val_accuracy: 0.9565\n",
      "Epoch 867/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.8615e-06 - accuracy: 1.0000 - val_loss: 0.2731 - val_accuracy: 0.9565\n",
      "Epoch 868/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.8137e-06 - accuracy: 1.0000 - val_loss: 0.2726 - val_accuracy: 0.9565\n",
      "Epoch 869/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.7208e-06 - accuracy: 1.0000 - val_loss: 0.2729 - val_accuracy: 0.9565\n",
      "Epoch 870/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.6762e-06 - accuracy: 1.0000 - val_loss: 0.2733 - val_accuracy: 0.9565\n",
      "Epoch 871/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.6345e-06 - accuracy: 1.0000 - val_loss: 0.2729 - val_accuracy: 0.9565\n",
      "Epoch 872/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 5.6584e-06 - accuracy: 1.0000 - val_loss: 0.2727 - val_accuracy: 0.9565\n",
      "Epoch 873/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.6380e-06 - accuracy: 1.0000 - val_loss: 0.2744 - val_accuracy: 0.9565\n",
      "Epoch 874/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.5750e-06 - accuracy: 1.0000 - val_loss: 0.2749 - val_accuracy: 0.9565\n",
      "Epoch 875/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.5413e-06 - accuracy: 1.0000 - val_loss: 0.2741 - val_accuracy: 0.9565\n",
      "Epoch 876/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 5.4754e-06 - accuracy: 1.0000 - val_loss: 0.2745 - val_accuracy: 0.9565\n",
      "Epoch 877/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 5.4029e-06 - accuracy: 1.0000 - val_loss: 0.2751 - val_accuracy: 0.9565\n",
      "Epoch 878/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.3638e-06 - accuracy: 1.0000 - val_loss: 0.2754 - val_accuracy: 0.9565\n",
      "Epoch 879/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5.4077e-06 - accuracy: 1.0000 - val_loss: 0.2768 - val_accuracy: 0.9565\n",
      "Epoch 880/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.2819e-06 - accuracy: 1.0000 - val_loss: 0.2766 - val_accuracy: 0.9565\n",
      "Epoch 881/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.3413e-06 - accuracy: 1.0000 - val_loss: 0.2749 - val_accuracy: 0.9565\n",
      "Epoch 882/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.2167e-06 - accuracy: 1.0000 - val_loss: 0.2753 - val_accuracy: 0.9565\n",
      "Epoch 883/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 5.2393e-06 - accuracy: 1.0000 - val_loss: 0.2770 - val_accuracy: 0.9565\n",
      "Epoch 884/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5.1753e-06 - accuracy: 1.0000 - val_loss: 0.2765 - val_accuracy: 0.9565\n",
      "Epoch 885/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.1199e-06 - accuracy: 1.0000 - val_loss: 0.2766 - val_accuracy: 0.9565\n",
      "Epoch 886/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.0407e-06 - accuracy: 1.0000 - val_loss: 0.2767 - val_accuracy: 0.9565\n",
      "Epoch 887/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 5.0328e-06 - accuracy: 1.0000 - val_loss: 0.2774 - val_accuracy: 0.9565\n",
      "Epoch 888/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 5.0340e-06 - accuracy: 1.0000 - val_loss: 0.2770 - val_accuracy: 0.9565\n",
      "Epoch 889/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.9334e-06 - accuracy: 1.0000 - val_loss: 0.2780 - val_accuracy: 0.9565\n",
      "Epoch 890/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.0173e-06 - accuracy: 1.0000 - val_loss: 0.2795 - val_accuracy: 0.9565\n",
      "Epoch 891/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.8710e-06 - accuracy: 1.0000 - val_loss: 0.2784 - val_accuracy: 0.9565\n",
      "Epoch 892/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.8850e-06 - accuracy: 1.0000 - val_loss: 0.2785 - val_accuracy: 0.9565\n",
      "Epoch 893/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.7927e-06 - accuracy: 1.0000 - val_loss: 0.2780 - val_accuracy: 0.9565\n",
      "Epoch 894/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.7799e-06 - accuracy: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.9565\n",
      "Epoch 895/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.7239e-06 - accuracy: 1.0000 - val_loss: 0.2786 - val_accuracy: 0.9565\n",
      "Epoch 896/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.7053e-06 - accuracy: 1.0000 - val_loss: 0.2792 - val_accuracy: 0.9565\n",
      "Epoch 897/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.6551e-06 - accuracy: 1.0000 - val_loss: 0.2794 - val_accuracy: 0.9565\n",
      "Epoch 898/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.6341e-06 - accuracy: 1.0000 - val_loss: 0.2804 - val_accuracy: 0.9565\n",
      "Epoch 899/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.6580e-06 - accuracy: 1.0000 - val_loss: 0.2811 - val_accuracy: 0.9565\n",
      "Epoch 900/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.6365e-06 - accuracy: 1.0000 - val_loss: 0.2803 - val_accuracy: 0.9565\n",
      "Epoch 901/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.5671e-06 - accuracy: 1.0000 - val_loss: 0.2808 - val_accuracy: 0.9565\n",
      "Epoch 902/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.5371e-06 - accuracy: 1.0000 - val_loss: 0.2814 - val_accuracy: 0.9565\n",
      "Epoch 903/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.4878e-06 - accuracy: 1.0000 - val_loss: 0.2809 - val_accuracy: 0.9565\n",
      "Epoch 904/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.4779e-06 - accuracy: 1.0000 - val_loss: 0.2819 - val_accuracy: 0.9565\n",
      "Epoch 905/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.4106e-06 - accuracy: 1.0000 - val_loss: 0.2826 - val_accuracy: 0.9565\n",
      "Epoch 906/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.4809e-06 - accuracy: 1.0000 - val_loss: 0.2812 - val_accuracy: 0.9565\n",
      "Epoch 907/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.3891e-06 - accuracy: 1.0000 - val_loss: 0.2824 - val_accuracy: 0.9565\n",
      "Epoch 908/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.3150e-06 - accuracy: 1.0000 - val_loss: 0.2825 - val_accuracy: 0.9565\n",
      "Epoch 909/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.3051e-06 - accuracy: 1.0000 - val_loss: 0.2832 - val_accuracy: 0.9565\n",
      "Epoch 910/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.2530e-06 - accuracy: 1.0000 - val_loss: 0.2831 - val_accuracy: 0.9565\n",
      "Epoch 911/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.2270e-06 - accuracy: 1.0000 - val_loss: 0.2828 - val_accuracy: 0.9565\n",
      "Epoch 912/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.2026e-06 - accuracy: 1.0000 - val_loss: 0.2830 - val_accuracy: 0.9565\n",
      "Epoch 913/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.1644e-06 - accuracy: 1.0000 - val_loss: 0.2832 - val_accuracy: 0.9565\n",
      "Epoch 914/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.1725e-06 - accuracy: 1.0000 - val_loss: 0.2830 - val_accuracy: 0.9565\n",
      "Epoch 915/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.0944e-06 - accuracy: 1.0000 - val_loss: 0.2837 - val_accuracy: 0.9565\n",
      "Epoch 916/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.1076e-06 - accuracy: 1.0000 - val_loss: 0.2840 - val_accuracy: 0.9565\n",
      "Epoch 917/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.0857e-06 - accuracy: 1.0000 - val_loss: 0.2855 - val_accuracy: 0.9565\n",
      "Epoch 918/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.0469e-06 - accuracy: 1.0000 - val_loss: 0.2849 - val_accuracy: 0.9565\n",
      "Epoch 919/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.0053e-06 - accuracy: 1.0000 - val_loss: 0.2853 - val_accuracy: 0.9565\n",
      "Epoch 920/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.9747e-06 - accuracy: 1.0000 - val_loss: 0.2852 - val_accuracy: 0.9565\n",
      "Epoch 921/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.9444e-06 - accuracy: 1.0000 - val_loss: 0.2853 - val_accuracy: 0.9565\n",
      "Epoch 922/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.9333e-06 - accuracy: 1.0000 - val_loss: 0.2868 - val_accuracy: 0.9565\n",
      "Epoch 923/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.8872e-06 - accuracy: 1.0000 - val_loss: 0.2859 - val_accuracy: 0.9565\n",
      "Epoch 924/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.8374e-06 - accuracy: 1.0000 - val_loss: 0.2865 - val_accuracy: 0.9565\n",
      "Epoch 925/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.8563e-06 - accuracy: 1.0000 - val_loss: 0.2873 - val_accuracy: 0.9565\n",
      "Epoch 926/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.7940e-06 - accuracy: 1.0000 - val_loss: 0.2867 - val_accuracy: 0.9565\n",
      "Epoch 927/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.7841e-06 - accuracy: 1.0000 - val_loss: 0.2872 - val_accuracy: 0.9565\n",
      "Epoch 928/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.7753e-06 - accuracy: 1.0000 - val_loss: 0.2866 - val_accuracy: 0.9565\n",
      "Epoch 929/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.7112e-06 - accuracy: 1.0000 - val_loss: 0.2873 - val_accuracy: 0.9565\n",
      "Epoch 930/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.7039e-06 - accuracy: 1.0000 - val_loss: 0.2877 - val_accuracy: 0.9565\n",
      "Epoch 931/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.6658e-06 - accuracy: 1.0000 - val_loss: 0.2877 - val_accuracy: 0.9565\n",
      "Epoch 932/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.6585e-06 - accuracy: 1.0000 - val_loss: 0.2883 - val_accuracy: 0.9565\n",
      "Epoch 933/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.6116e-06 - accuracy: 1.0000 - val_loss: 0.2886 - val_accuracy: 0.9565\n",
      "Epoch 934/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.6366e-06 - accuracy: 1.0000 - val_loss: 0.2897 - val_accuracy: 0.9565\n",
      "Epoch 935/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.6072e-06 - accuracy: 1.0000 - val_loss: 0.2890 - val_accuracy: 0.9565\n",
      "Epoch 936/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.5542e-06 - accuracy: 1.0000 - val_loss: 0.2890 - val_accuracy: 0.9565\n",
      "Epoch 937/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.4915e-06 - accuracy: 1.0000 - val_loss: 0.2896 - val_accuracy: 0.9565\n",
      "Epoch 938/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.4859e-06 - accuracy: 1.0000 - val_loss: 0.2902 - val_accuracy: 0.9565\n",
      "Epoch 939/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.4402e-06 - accuracy: 1.0000 - val_loss: 0.2900 - val_accuracy: 0.9565\n",
      "Epoch 940/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.4253e-06 - accuracy: 1.0000 - val_loss: 0.2903 - val_accuracy: 0.9565\n",
      "Epoch 941/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.3912e-06 - accuracy: 1.0000 - val_loss: 0.2901 - val_accuracy: 0.9565\n",
      "Epoch 942/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.4172e-06 - accuracy: 1.0000 - val_loss: 0.2915 - val_accuracy: 0.9565\n",
      "Epoch 943/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.3612e-06 - accuracy: 1.0000 - val_loss: 0.2910 - val_accuracy: 0.9565\n",
      "Epoch 944/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.3324e-06 - accuracy: 1.0000 - val_loss: 0.2909 - val_accuracy: 0.9565\n",
      "Epoch 945/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.3038e-06 - accuracy: 1.0000 - val_loss: 0.2908 - val_accuracy: 0.9565\n",
      "Epoch 946/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.3193e-06 - accuracy: 1.0000 - val_loss: 0.2916 - val_accuracy: 0.9565\n",
      "Epoch 947/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.2546e-06 - accuracy: 1.0000 - val_loss: 0.2912 - val_accuracy: 0.9565\n",
      "Epoch 948/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.2304e-06 - accuracy: 1.0000 - val_loss: 0.2914 - val_accuracy: 0.9565\n",
      "Epoch 949/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.2295e-06 - accuracy: 1.0000 - val_loss: 0.2914 - val_accuracy: 0.9565\n",
      "Epoch 950/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.2126e-06 - accuracy: 1.0000 - val_loss: 0.2927 - val_accuracy: 0.9565\n",
      "Epoch 951/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.1800e-06 - accuracy: 1.0000 - val_loss: 0.2922 - val_accuracy: 0.9565\n",
      "Epoch 952/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.1654e-06 - accuracy: 1.0000 - val_loss: 0.2930 - val_accuracy: 0.9565\n",
      "Epoch 953/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.1765e-06 - accuracy: 1.0000 - val_loss: 0.2943 - val_accuracy: 0.9565\n",
      "Epoch 954/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.1345e-06 - accuracy: 1.0000 - val_loss: 0.2933 - val_accuracy: 0.9565\n",
      "Epoch 955/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.0972e-06 - accuracy: 1.0000 - val_loss: 0.2934 - val_accuracy: 0.9565\n",
      "Epoch 956/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.0969e-06 - accuracy: 1.0000 - val_loss: 0.2942 - val_accuracy: 0.9565\n",
      "Epoch 957/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.0380e-06 - accuracy: 1.0000 - val_loss: 0.2936 - val_accuracy: 0.9565\n",
      "Epoch 958/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.0182e-06 - accuracy: 1.0000 - val_loss: 0.2934 - val_accuracy: 0.9565\n",
      "Epoch 959/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.0121e-06 - accuracy: 1.0000 - val_loss: 0.2947 - val_accuracy: 0.9565\n",
      "Epoch 960/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.9666e-06 - accuracy: 1.0000 - val_loss: 0.2946 - val_accuracy: 0.9565\n",
      "Epoch 961/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.9460e-06 - accuracy: 1.0000 - val_loss: 0.2949 - val_accuracy: 0.9565\n",
      "Epoch 962/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.9180e-06 - accuracy: 1.0000 - val_loss: 0.2950 - val_accuracy: 0.9565\n",
      "Epoch 963/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.9285e-06 - accuracy: 1.0000 - val_loss: 0.2960 - val_accuracy: 0.9565\n",
      "Epoch 964/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.8833e-06 - accuracy: 1.0000 - val_loss: 0.2957 - val_accuracy: 0.9565\n",
      "Epoch 965/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.8801e-06 - accuracy: 1.0000 - val_loss: 0.2952 - val_accuracy: 0.9565\n",
      "Epoch 966/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.8454e-06 - accuracy: 1.0000 - val_loss: 0.2961 - val_accuracy: 0.9565\n",
      "Epoch 967/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.8311e-06 - accuracy: 1.0000 - val_loss: 0.2963 - val_accuracy: 0.9565\n",
      "Epoch 968/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.8189e-06 - accuracy: 1.0000 - val_loss: 0.2973 - val_accuracy: 0.9565\n",
      "Epoch 969/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.7836e-06 - accuracy: 1.0000 - val_loss: 0.2969 - val_accuracy: 0.9565\n",
      "Epoch 970/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.7655e-06 - accuracy: 1.0000 - val_loss: 0.2975 - val_accuracy: 0.9565\n",
      "Epoch 971/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.7609e-06 - accuracy: 1.0000 - val_loss: 0.2973 - val_accuracy: 0.9565\n",
      "Epoch 972/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.7282e-06 - accuracy: 1.0000 - val_loss: 0.2975 - val_accuracy: 0.9565\n",
      "Epoch 973/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.7521e-06 - accuracy: 1.0000 - val_loss: 0.2985 - val_accuracy: 0.9565\n",
      "Epoch 974/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.6924e-06 - accuracy: 1.0000 - val_loss: 0.2990 - val_accuracy: 0.9565\n",
      "Epoch 975/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.6592e-06 - accuracy: 1.0000 - val_loss: 0.2982 - val_accuracy: 0.9565\n",
      "Epoch 976/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.6825e-06 - accuracy: 1.0000 - val_loss: 0.2978 - val_accuracy: 0.9565\n",
      "Epoch 977/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.6207e-06 - accuracy: 1.0000 - val_loss: 0.2985 - val_accuracy: 0.9565\n",
      "Epoch 978/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.6280e-06 - accuracy: 1.0000 - val_loss: 0.2984 - val_accuracy: 0.9565\n",
      "Epoch 979/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.6088e-06 - accuracy: 1.0000 - val_loss: 0.2994 - val_accuracy: 0.9565\n",
      "Epoch 980/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.5773e-06 - accuracy: 1.0000 - val_loss: 0.3002 - val_accuracy: 0.9565\n",
      "Epoch 981/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.5566e-06 - accuracy: 1.0000 - val_loss: 0.2995 - val_accuracy: 0.9565\n",
      "Epoch 982/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.5776e-06 - accuracy: 1.0000 - val_loss: 0.3009 - val_accuracy: 0.9565\n",
      "Epoch 983/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.5129e-06 - accuracy: 1.0000 - val_loss: 0.3000 - val_accuracy: 0.9565\n",
      "Epoch 984/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.5344e-06 - accuracy: 1.0000 - val_loss: 0.2997 - val_accuracy: 0.9565\n",
      "Epoch 985/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.4960e-06 - accuracy: 1.0000 - val_loss: 0.3005 - val_accuracy: 0.9565\n",
      "Epoch 986/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.4762e-06 - accuracy: 1.0000 - val_loss: 0.3001 - val_accuracy: 0.9565\n",
      "Epoch 987/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.4502e-06 - accuracy: 1.0000 - val_loss: 0.3012 - val_accuracy: 0.9565\n",
      "Epoch 988/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.4537e-06 - accuracy: 1.0000 - val_loss: 0.3022 - val_accuracy: 0.9565\n",
      "Epoch 989/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.4237e-06 - accuracy: 1.0000 - val_loss: 0.3020 - val_accuracy: 0.9565\n",
      "Epoch 990/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.4112e-06 - accuracy: 1.0000 - val_loss: 0.3024 - val_accuracy: 0.9565\n",
      "Epoch 991/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.3811e-06 - accuracy: 1.0000 - val_loss: 0.3023 - val_accuracy: 0.9565\n",
      "Epoch 992/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.3899e-06 - accuracy: 1.0000 - val_loss: 0.3026 - val_accuracy: 0.9565\n",
      "Epoch 993/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.3462e-06 - accuracy: 1.0000 - val_loss: 0.3023 - val_accuracy: 0.9565\n",
      "Epoch 994/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.3374e-06 - accuracy: 1.0000 - val_loss: 0.3033 - val_accuracy: 0.9565\n",
      "Epoch 995/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.3118e-06 - accuracy: 1.0000 - val_loss: 0.3034 - val_accuracy: 0.9565\n",
      "Epoch 996/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.3010e-06 - accuracy: 1.0000 - val_loss: 0.3039 - val_accuracy: 0.9565\n",
      "Epoch 997/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.3319e-06 - accuracy: 1.0000 - val_loss: 0.3028 - val_accuracy: 0.9565\n",
      "Epoch 998/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.2707e-06 - accuracy: 1.0000 - val_loss: 0.3031 - val_accuracy: 0.9565\n",
      "Epoch 999/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.2433e-06 - accuracy: 1.0000 - val_loss: 0.3044 - val_accuracy: 0.9565\n",
      "Epoch 1000/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.2430e-06 - accuracy: 1.0000 - val_loss: 0.3053 - val_accuracy: 0.9565\n"
     ]
    }
   ],
   "source": [
    "# training the Meural Network\n",
    "\n",
    "history = model.fit(X_train_std, Y_train, validation_split=0.1, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "54fd0799-10a3-4dde-8e2f-851c2e3601ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x14723378d00>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABRfUlEQVR4nO3deVxU5f4H8M8wwMzgCKggCKIgkmgqLigX94ouinnNzO1aIpZe94VrKrmmFbboT0JT82aamUtuWRZepNQ0BEUxDfcNJRY3QFAQZp7fH15OTSABDnMG5vN+veZ1mec8c+Z7DuT53Oc85xyFEEKAiIiIyIJYyV0AERERkakxABEREZHFYQAiIiIii8MARERERBaHAYiIiIgsDgMQERERWRwGICIiIrI4DEBERERkcRiAiIiIyOIwABGRSV29ehUKhQLr1q2r9Gf3798PhUKB/fv3G70uIrIsDEBERERkcRiAiIiIyOIwABERySw/P1/uEogsDgMQkYVZsGABFAoFzp8/j1deeQUODg5wdnbG3LlzIYTA9evX0b9/f9jb28PV1RVLliwptY6srCy89tprcHFxgVqthp+fH9avX1+qX3Z2NkaOHAkHBwc4OjoiNDQU2dnZZdZ19uxZvPzyy6hfvz7UajX8/f2xe/fuKm3jtWvXMH78eLRo0QIajQYNGjTAoEGDcPXq1TJrnDZtGjw9PaFSqdC4cWOMGDECt27dkvoUFBRgwYIFeOqpp6BWq9GoUSO89NJLuHTpEoDHz00qa77TyJEjodVqcenSJYSEhKBu3boYPnw4AOCnn37CoEGD0KRJE6hUKnh4eGDatGl48OBBmftr8ODBcHZ2hkajQYsWLTB79mwAwI8//giFQoGdO3eW+tyXX34JhUKB+Pj4yu5WolrFWu4CiEgeQ4YMQcuWLbF48WLs2bMHb7/9NurXr4/Vq1fj2WefxXvvvYeNGzdi+vTp6NSpE3r06AEAePDgAXr16oWLFy9i4sSJ8PLywldffYWRI0ciOzsbU6ZMAQAIIdC/f38cOnQIY8eORcuWLbFz506EhoaWquXXX39F165d4e7ujlmzZqFOnTrYunUrXnzxRWzfvh0DBgyo1LYdPXoUP//8M4YOHYrGjRvj6tWrWLlyJXr16oWUlBTY2dkBAPLy8tC9e3ecOXMGo0aNQocOHXDr1i3s3r0bN27cgJOTE3Q6HV544QXExcVh6NChmDJlCu7du4fY2FicPn0a3t7eld73xcXFCA4ORrdu3fDhhx9K9Xz11Ve4f/8+xo0bhwYNGiAxMRHR0dG4ceMGvvrqK+nzv/zyC7p37w4bGxuMGTMGnp6euHTpEr755hu888476NWrFzw8PLBx48ZS+27jxo3w9vZGYGBgpesmqlUEEVmU+fPnCwBizJgxUltxcbFo3LixUCgUYvHixVL73bt3hUajEaGhoVLbsmXLBADxxRdfSG0PHz4UgYGBQqvVitzcXCGEELt27RIAxPvvv2/wPd27dxcAxGeffSa1P/fcc6JNmzaioKBAatPr9aJLly7Cx8dHavvxxx8FAPHjjz+Wu433798v1RYfHy8AiM8//1xqmzdvngAgduzYUaq/Xq8XQgixdu1aAUAsXbr0sX0eV9eVK1dKbWtoaKgAIGbNmlWhuiMjI4VCoRDXrl2T2nr06CHq1q1r0PbHeoQQIiIiQqhUKpGdnS21ZWVlCWtrazF//vxS30NkaXgKjMhCvf7669LPSqUS/v7+EELgtddek9odHR3RokULXL58WWr77rvv4OrqimHDhkltNjY2mDx5MvLy8nDgwAGpn7W1NcaNG2fwPZMmTTKo486dO/jhhx8wePBg3Lt3D7du3cKtW7dw+/ZtBAcH48KFC0hLS6vUtmk0GunnoqIi3L59G82bN4ejoyOOHz8uLdu+fTv8/PzKHGFSKBRSHycnp1J1/7FPVfxxv5RVd35+Pm7duoUuXbpACIETJ04AAG7evImDBw9i1KhRaNKkyWPrGTFiBAoLC7Ft2zapbcuWLSguLsYrr7xS5bqJagsGICIL9eeDp4ODA9RqNZycnEq13717V3p/7do1+Pj4wMrK8J+Pli1bSstL/rdRo0bQarUG/Vq0aGHw/uLFixBCYO7cuXB2djZ4zZ8/H8CjOUeV8eDBA8ybNw8eHh5QqVRwcnKCs7MzsrOzkZOTI/W7dOkSWrduXe66Ll26hBYtWsDa2ngzBqytrdG4ceNS7ampqRg5ciTq168PrVYLZ2dn9OzZEwCkukvC6F/V7evri06dOmHjxo1S28aNG/G3v/0NzZs3N9amENVYnANEZKGUSmWF2oBH83mqi16vBwBMnz4dwcHBZfap7AF70qRJ+OyzzzB16lQEBgbCwcEBCoUCQ4cOlb7PmB43EqTT6cpsV6lUpQKkTqfD888/jzt37mDmzJnw9fVFnTp1kJaWhpEjR1ap7hEjRmDKlCm4ceMGCgsLceTIESxfvrzS6yGqjRiAiKhSmjZtil9++QV6vd7gIH727Flpecn/xsXFIS8vz2AU6Ny5cwbra9asGYBHp9GCgoKMUuO2bdsQGhpqcAVbQUFBqSvQvL29cfr06XLX5e3tjYSEBBQVFcHGxqbMPvXq1QOAUusvGQ2riFOnTuH8+fNYv349RowYIbXHxsYa9CvZX39VNwAMHToU4eHh2LRpEx48eAAbGxsMGTKkwjUR1WY8BUZElRISEoKMjAxs2bJFaisuLkZ0dDS0Wq10yiYkJATFxcVYuXKl1E+n0yE6OtpgfQ0bNkSvXr2wevVqpKenl/q+mzdvVrpGpVJZatQqOjq61IjMwIEDcfLkyTIvFy/5/MCBA3Hr1q0yR05K+jRt2hRKpRIHDx40WP7xxx9XquY/rrPk56ioKIN+zs7O6NGjB9auXYvU1NQy6ynh5OSEPn364IsvvsDGjRvRu3fvUqc4iSwVR4CIqFLGjBmD1atXY+TIkUhKSoKnpye2bduGw4cPY9myZahbty4AoF+/fujatStmzZqFq1evolWrVtixY4fBHJwSK1asQLdu3dCmTRuMHj0azZo1Q2ZmJuLj43Hjxg2cPHmyUjW+8MIL2LBhAxwcHNCqVSvEx8dj3759aNCggUG/N954A9u2bcOgQYMwatQodOzYEXfu3MHu3buxatUq+Pn5YcSIEfj8888RHh6OxMREdO/eHfn5+di3bx/Gjx+P/v37w8HBAYMGDUJ0dDQUCgW8vb3x7bffVmrukq+vL7y9vTF9+nSkpaXB3t4e27dvN5h/VeKjjz5Ct27d0KFDB4wZMwZeXl64evUq9uzZg+TkZIO+I0aMwMsvvwwAWLRoUaX2I1GtJtflZ0Qkj5LL4G/evGnQHhoaKurUqVOqf8+ePcXTTz9t0JaZmSnCwsKEk5OTsLW1FW3atDG41LvE7du3xauvvirs7e2Fg4ODePXVV8WJEydKXRouhBCXLl0SI0aMEK6ursLGxka4u7uLF154QWzbtk3qU9HL4O/evSvVp9VqRXBwsDh79qxo2rSpwSX9JTVOnDhRuLu7C1tbW9G4cWMRGhoqbt26JfW5f/++mD17tvDy8hI2NjbC1dVVvPzyy+LSpUtSn5s3b4qBAwcKOzs7Ua9ePfGvf/1LnD59uszL4Mvaz0IIkZKSIoKCgoRWqxVOTk5i9OjR4uTJk2Xur9OnT4sBAwYIR0dHoVarRYsWLcTcuXNLrbOwsFDUq1dPODg4iAcPHpS734gsiUKIapzdSEREsiouLoabmxv69euHTz/9VO5yiMwG5wAREdViu3btws2bNw0mVhMRwBEgIqJaKCEhAb/88gsWLVoEJycngxtAEhFHgIiIaqWVK1di3LhxaNiwIT7//HO5yyEyOxwBIiIiIovDESAiIiKyOAxAREREZHF4I8Qy6PV6/Pbbb6hbt+4TPe2ZiIiITEcIgXv37sHNza3U8/b+jAGoDL/99hs8PDzkLoOIiIiq4Pr162jcuHG5fRiAylByK//r16/D3t5e5mqIiIioInJzc+Hh4SEdx8vDAFSGktNe9vb2DEBEREQ1TEWmr3ASNBEREVkcBiAiIiKyOAxAREREZHEYgIiIiMjiMAARERGRxWEAIiIiIovDAEREREQWhwGIiIiILA4DEBEREVkcBiAiIiKyOLIGoIMHD6Jfv35wc3ODQqHArl27/vIz+/fvR4cOHaBSqdC8eXOsW7euVJ8VK1bA09MTarUaAQEBSExMNH7xREREVGPJGoDy8/Ph5+eHFStWVKj/lStX0LdvXzzzzDNITk7G1KlT8frrr2Pv3r1Sny1btiA8PBzz58/H8ePH4efnh+DgYGRlZVXXZhAREVENoxBCCLmLAB49uGznzp148cUXH9tn5syZ2LNnD06fPi21DR06FNnZ2YiJiQEABAQEoFOnTli+fDkAQK/Xw8PDA5MmTcKsWbMqVEtubi4cHByQk5PDh6H+gU4vkJ7zAHVsrVGk0+OhTi93SUREVENpbJRooFUZdZ2VOX7XqKfBx8fHIygoyKAtODgYU6dOBQA8fPgQSUlJiIiIkJZbWVkhKCgI8fHxj11vYWEhCgsLpfe5ubnGLbyWGP6fIzhy+Y7cZRARUS3wDz83fDSsvWzfX6MCUEZGBlxcXAzaXFxckJubiwcPHuDu3bvQ6XRl9jl79uxj1xsZGYm33nqrWmquTZKu3TV4b22lgNJKIVM1RERUk1kr5T1+1KgAVF0iIiIQHh4uvc/NzYWHh4eMFZkfnV6gSGd4tjRqaHv0bdtIpoqIiIiqrkYFIFdXV2RmZhq0ZWZmwt7eHhqNBkqlEkqlssw+rq6uj12vSqWCSmXc85C1TUGRrlSb2oZ3USAiopqpRh3BAgMDERcXZ9AWGxuLwMBAAICtrS06duxo0Eev1yMuLk7qQ1VTdgBSylAJERHRk5M1AOXl5SE5ORnJyckAHl3mnpycjNTUVACPTk2NGDFC6j927FhcvnwZM2bMwNmzZ/Hxxx9j69atmDZtmtQnPDwca9aswfr163HmzBmMGzcO+fn5CAsLM+m21TYFxaWv+OIIEBER1VSyngI7duwYnnnmGel9yTyc0NBQrFu3Dunp6VIYAgAvLy/s2bMH06ZNQ1RUFBo3boz//Oc/CA4OlvoMGTIEN2/exLx585CRkYF27dohJiam1MRoqpwHDzkCREREtYfZ3AfInPA+QKWdTsvBC9GHDNri/t0T3s5amSoiIiIyVJnjN89hUIUUFnMEiIiIag8GIKqQgqIy5gBZ88+HiIhqJh7BqEI4B4iIiGoTBiCqkAKeAiMiolqkRt0IkSru6+Q0nMu4Z7T1nc8svS4+BoOIiGoqBqBa6Mbd+5iyObla1u3rWhdnjRisiIiI5MAAVAvdyX8IANCqrDHY33jPNLOxVmBYpyY4evUO3Bw1RlsvERGRqTEA1UIlV2w1rKvCvH6tjL5+T6c6Rl8nERGRKXESdC304H/P7VJxkjIREVGZGIBqoZIHl/JZXURERGXjEbIWkgKQNUeAiIiIysIAVAsV/m8OkMaWAYiIiKgsDEC1UMlNC3kKjIiIqGw8QtZCPAVGRERUPgagWqjkMnheBUZERFQ2BqBaqOQyeA0DEBERUZkYgGohXgZPRERUPt4JuoY7eP4mZm7/RRr1AYD7D0sCEEeAiIiIysIAVMN9fzoD6TkFZS572s3exNUQERHVDAxANVzJ6a5/9WiGQX948Km92hoN7dVylUVERGTWGIBquJIA5F5Pg+YNtTJXQ0REVDNwlmwNx3v+EBERVR4DUA1Xcs8fNR97QUREVGEMQDWc9NgLa/4qiYiIKopHzRruAS95JyIiqjQGoBqusPh/p8AYgIiIiCqMAaiG412fiYiIKo9HzRru9wDEESAiIqKKYgCq4aSrwHgZPBERUYUxANVgGTkF0jPA1Lb8VRIREVUUj5o12LA1R6Sf7Wx5U28iIqKKYgCqwX7LfgAAGOzfGFoVAxAREVFFMQDVUHq9kC6Bn9HbV+ZqiIiIahYGoBqqJPwAvAKMiIioshiAaqiSy98BPgaDiIiosnjkrKFKngFmo1TAWslfIxERUWXwyFlDSc8A4/1/iIiIKo0BqIYquQGiivN/iIiIKo0BqIYqOQXGZ4ARERFVHo+eNVTJJGgNR4CIiIgqTfYAtGLFCnh6ekKtViMgIACJiYmP7VtUVISFCxfC29sbarUafn5+iImJMehz7949TJ06FU2bNoVGo0GXLl1w9OjR6t4Mk+NDUImIiKpO1gC0ZcsWhIeHY/78+Th+/Dj8/PwQHByMrKysMvvPmTMHq1evRnR0NFJSUjB27FgMGDAAJ06ckPq8/vrriI2NxYYNG3Dq1Cn8/e9/R1BQENLS0ky1WSYhPQSVp8CIiIgqTSGEEHJ9eUBAADp16oTly5cDAPR6PTw8PDBp0iTMmjWrVH83NzfMnj0bEyZMkNoGDhwIjUaDL774Ag8ePEDdunXx9ddfo2/fvlKfjh07ok+fPnj77bcrVFdubi4cHByQk5MDe3v7J9zKyvs6OQ1fHbsBgcf/am7eK8T5zDx093HChtcCTFgdERGRearM8Vu2B0g9fPgQSUlJiIiIkNqsrKwQFBSE+Pj4Mj9TWFgItVpt0KbRaHDo0CEAQHFxMXQ6Xbl9HrfewsJC6X1ubm6lt8eYlsaex7Xb9yvU191RU83VEBER1T6yBaBbt25Bp9PBxcXFoN3FxQVnz54t8zPBwcFYunQpevToAW9vb8TFxWHHjh3Q6R7Nh6lbty4CAwOxaNEitGzZEi4uLti0aRPi4+PRvHnzx9YSGRmJt956y3gb94TyC4sBADN7+8LNUf3YfjZKK3T3cTJVWURERLVGjXqEeFRUFEaPHg1fX18oFAp4e3sjLCwMa9eulfps2LABo0aNgru7O5RKJTp06IBhw4YhKSnpseuNiIhAeHi49D43NxceHh7Vui3lKZnf06e1Kzyd6shWBxERUW0l2wxaJycnKJVKZGZmGrRnZmbC1dW1zM84Oztj165dyM/Px7Vr13D27FlotVo0a9ZM6uPt7Y0DBw4gLy8P169fR2JiIoqKigz6/JlKpYK9vb3BS04PeIUXERFRtZItANna2qJjx46Ii4uT2vR6PeLi4hAYGFjuZ9VqNdzd3VFcXIzt27ejf//+pfrUqVMHjRo1wt27d7F3794y+5ijIp0eOv2jyc+8wouIiKh6yHoKLDw8HKGhofD390fnzp2xbNky5OfnIywsDAAwYsQIuLu7IzIyEgCQkJCAtLQ0tGvXDmlpaViwYAH0ej1mzJghrXPv3r0QQqBFixa4ePEi3njjDfj6+krrNHcGT3nnCBAREVG1kDUADRkyBDdv3sS8efOQkZGBdu3aISYmRpoYnZqaCiur30dBCgoKMGfOHFy+fBlarRYhISHYsGEDHB0dpT45OTmIiIjAjRs3UL9+fQwcOBDvvPMObGxsTL15VVIy/wcAVNYcASIiIqoOst4HyFzJeR+g63fuo/v7P0JtY4Wzi/qY9LuJiIhqssocvznEYGb4iAsiIqLqxwBkZqRHXFgzABEREVUXBiAzU1D8v6e82zIAERERVZcadSPE2iTrXgEePNSVai95BAYnQBMREVUfBiAZfJ2chimbk8vtwzlARERE1YcBSAa/3MgBANgoFVCVMdfHSgH8w8/N1GURERFZDAYgGZTc6flfPbwxPbiFzNUQERFZHk40kUGR7tGVXkorhcyVEBERWSYGIBmUjADZKBmAiIiI5MAAJIMi3aMAZK3k7iciIpIDj8Ay0OkfnQKz5ikwIiIiWTAAyaDof6fAGICIiIjkwQAkg+KSSdA8BUZERCQLHoFlIE2C5ggQERGRLBiAZFAyCZqXwRMREcmDAUgGv18Gz91PREQkBx6BZVByI0Rr3geIiIhIFgxAMtDxKjAiIiJZMQDJ4PfL4Ln7iYiI5MAjsAxKboSo5CkwIiIiWTAAyaBYV3IZPHc/ERGRHHgElgEnQRMREcmLAUgGnARNREQkLwYgGfBp8ERERPLiEVgGHAEiIiKSFwOQDIr1nANEREQkJwYgGRTzPkBERESy4hFYBiWXwfMUGBERkTwYgGTAy+CJiIjkxQBkYpHfn0Fh8f8CEE+BERERyYJHYBPbnpQm/Vy/jq2MlRAREVkuBiATKyjSAQD2Tu0BW2vufiIiIjnwCGxiJQHIQWMjcyVERESWiwHIhIp0eukSeLUNdz0REZFceBQ2oZLRHwBQ2yhlrISIiMiyMQCZUEGRXvpZxfk/REREsuFR2IRKRoBU1lZQKHgPICIiIrkwAJlQYfGjAKSx5ekvIiIiOTEAmVDJKTC1NQMQERGRnBiATKjkFBivACMiIpIXj8Qm9EAKQBwBIiIikpPsAWjFihXw9PSEWq1GQEAAEhMTH9u3qKgICxcuhLe3N9RqNfz8/BATE2PQR6fTYe7cufDy8oJGo4G3tzcWLVoEIUR1b8pfKjkFpmIAIiIikpWsAWjLli0IDw/H/Pnzcfz4cfj5+SE4OBhZWVll9p8zZw5Wr16N6OhopKSkYOzYsRgwYABOnDgh9XnvvfewcuVKLF++HGfOnMF7772H999/H9HR0abarMeSToHxEngiIiJZKYSMQyMBAQHo1KkTli9fDgDQ6/Xw8PDApEmTMGvWrFL93dzcMHv2bEyYMEFqGzhwIDQaDb744gsAwAsvvAAXFxd8+umnj+3zV3Jzc+Hg4ICcnBzY29s/ySYaOHzxFlbuv4SWjepidt9WRlsvERERVe74LdtQxMOHD5GUlISgoKDfi7GyQlBQEOLj48v8TGFhIdRqtUGbRqPBoUOHpPddunRBXFwczp8/DwA4efIkDh06hD59+jy2lsLCQuTm5hq8qkPX5k744vUAhh8iIiKZWcv1xbdu3YJOp4OLi4tBu4uLC86ePVvmZ4KDg7F06VL06NED3t7eiIuLw44dO6DT/f6IiVmzZiE3Nxe+vr5QKpXQ6XR45513MHz48MfWEhkZibfeess4G0ZERERmr0ZNRomKioKPjw98fX1ha2uLiRMnIiwsDFZWv2/G1q1bsXHjRnz55Zc4fvw41q9fjw8//BDr169/7HojIiKQk5Mjva5fv26KzSEiIiKZyDYC5OTkBKVSiczMTIP2zMxMuLq6lvkZZ2dn7Nq1CwUFBbh9+zbc3Nwwa9YsNGvWTOrzxhtvYNasWRg6dCgAoE2bNrh27RoiIyMRGhpa5npVKhVUKpWRtoyIiIjMnWwjQLa2tujYsSPi4uKkNr1ej7i4OAQGBpb7WbVaDXd3dxQXF2P79u3o37+/tOz+/fsGI0IAoFQqodfr/7waIiIislCyjQABQHh4OEJDQ+Hv74/OnTtj2bJlyM/PR1hYGABgxIgRcHd3R2RkJAAgISEBaWlpaNeuHdLS0rBgwQLo9XrMmDFDWme/fv3wzjvvoEmTJnj66adx4sQJLF26FKNGjZJlG4mIiMj8yBqAhgwZgps3b2LevHnIyMhAu3btEBMTI02MTk1NNRjNKSgowJw5c3D58mVotVqEhIRgw4YNcHR0lPpER0dj7ty5GD9+PLKysuDm5oZ//etfmDdvnqk3j4iIiMyUrPcBMlfVdR8gIiIiqj414j5ARERERHJhACIiIiKLwwBEREREFocBiIiIiCwOAxARERFZHAYgIiIisjgMQERERGRxGICIiIjI4jAAERERkcVhACIiIiKLwwBEREREFocBiIiIiCwOAxARERFZHAYgIiIisjgMQERERGRxGICIiIjI4jAAERERkcVhACIiIiKLwwBEREREFocBiIiIiCwOAxARERFZHAYgIiIisjgMQERERGRxGICIiIjI4jAAERERkcVhACIiIiKLwwBEREREFocBiIiIiCwOAxARERFZnCoFoB9//NHYdRARERGZTJUCUO/eveHt7Y23334b169fN3ZNRERERNWqSgEoLS0NEydOxLZt29CsWTMEBwdj69atePjwobHrIyIiIjK6KgUgJycnTJs2DcnJyUhISMBTTz2F8ePHw83NDZMnT8bJkyeNXScRERGR0TzxJOgOHTogIiICEydORF5eHtauXYuOHTuie/fu+PXXX41RIxEREZFRVTkAFRUVYdu2bQgJCUHTpk2xd+9eLF++HJmZmbh48SKaNm2KQYMGGbNWIiIiIqNQCCFEZT80adIkbNq0CUIIvPrqq3j99dfRunVrgz4ZGRlwc3ODXq83WrGmkpubCwcHB+Tk5MDe3l7ucoiIiKgCKnP8tq7KF6SkpCA6OhovvfQSVCpVmX2cnJx4uTwRERGZpSqNANV2HAEiIiKqeSpz/K7SHKDIyEisXbu2VPvatWvx3nvvVWWVRERERCZTpQC0evVq+Pr6lmp/+umnsWrVqicuioiIiKg6VSkAZWRkoFGjRqXanZ2dkZ6eXun1rVixAp6enlCr1QgICEBiYuJj+xYVFWHhwoXw9vaGWq2Gn58fYmJiDPp4enpCoVCUek2YMKHStREREVHtU6UA5OHhgcOHD5dqP3z4MNzc3Cq1ri1btiA8PBzz58/H8ePH4efnh+DgYGRlZZXZf86cOVi9ejWio6ORkpKCsWPHYsCAAThx4oTU5+jRo0hPT5desbGxAMDL8omIiAhAFSdBv//++3j//ffxwQcf4NlnnwUAxMXFYcaMGfj3v/+NiIiICq8rICAAnTp1wvLlywEAer0eHh4emDRpEmbNmlWqv5ubG2bPnm0wmjNw4EBoNBp88cUXZX7H1KlT8e233+LChQtQKBR/WRMnQRMREdU81X4Z/BtvvIHbt29j/Pjx0vO/1Go1Zs6cWanw8/DhQyQlJRl8xsrKCkFBQYiPjy/zM4WFhVCr1QZtGo0Ghw4deux3fPHFFwgPD39s+CksLERhYaH0Pjc3t8LbQERERDVPlU6BKRQKvPfee7h58yaOHDmCkydP4s6dO5g3b16l1nPr1i3odDq4uLgYtLu4uCAjI6PMzwQHB2Pp0qW4cOEC9Ho9YmNjsWPHjsfOPdq1axeys7MxcuTIx9YRGRkJBwcH6eXh4VGp7SAiIqKa5YmeBabVatGpUye0bt36sTdENLaoqCj4+PjA19cXtra2mDhxIsLCwmBlVfamfPrpp+jTp0+5c5MiIiKQk5Mjva5fv15d5RMREZEZqNIpMAA4duwYtm7ditTUVOk0WIkdO3ZUaB1OTk5QKpXIzMw0aM/MzISrq2uZn3F2dsauXbtQUFCA27dvw83NDbNmzUKzZs1K9b127Rr27dv3l/WoVCqTBTgiIiKSX5VGgDZv3owuXbrgzJkz2LlzJ4qKivDrr7/ihx9+gIODQ4XXY2tri44dOyIuLk5q0+v1iIuLQ2BgYLmfVavVcHd3R3FxMbZv347+/fuX6vPZZ5+hYcOG6Nu3b8U3joiIiGq9KgWgd999F//3f/+Hb775Bra2toiKisLZs2cxePBgNGnSpFLrCg8Px5o1a7B+/XqcOXMG48aNQ35+PsLCwgAAI0aMMJgknZCQgB07duDy5cv46aef0Lt3b+j1esyYMcNgvXq9Hp999hlCQ0NhbV3lgS4iIiKqhaqUDC5duiSNqtja2iI/Px8KhQLTpk3Ds88+i7feeqvC6xoyZAhu3ryJefPmISMjA+3atUNMTIw0MTo1NdVgfk9BQQHmzJmDy5cvQ6vVIiQkBBs2bICjo6PBevft24fU1FSMGjWqKptIREREtViVAlC9evVw7949AIC7uztOnz6NNm3aIDs7G/fv36/0+iZOnIiJEyeWuWz//v0G73v27ImUlJS/XOff//538DmvREREVJYqBaAePXogNjYWbdq0waBBgzBlyhT88MMPiI2NxXPPPWfsGomIiIiMqkoBaPny5SgoKAAAzJ49GzY2Nvj5558xcOBAzJkzx6gFEhERERlbpQNQcXExvv32WwQHBwN4dOfmsh5ZQURERGSuKn0VmLW1NcaOHSuNABERERHVNFW6DL5z585ITk42cilEREREplGlOUDjx49HeHg4rl+/jo4dO6JOnToGy9u2bWuU4oiIiIiqg0JU4Vrxsp67pVAoIISAQqGATqczSnFyyc3NhYODA3JycmBvby93OURERFQBlTl+V2kE6MqVK1UqjIiIiMgcVCkANW3a1Nh1EBEREZlMlQLQ559/Xu7yESNGVKkYIiIiIlOo0hygevXqGbwvKirC/fv3YWtrCzs7O9y5c8doBcqBc4CIiIhqnsocv6t0Gfzdu3cNXnl5eTh37hy6deuGTZs2ValoIiIiIlOpUgAqi4+PDxYvXowpU6YYa5VERERE1cJoAQh4dJfo3377zZirJCIiIjK6Kk2C3r17t8F7IQTS09OxfPlydO3a1SiFEREREVWXKgWgF1980eC9QqGAs7Mznn32WSxZssQYdRERERFVmyoFIL1eb+w6iIiIiEzGqHOAiIiIiGqCKgWggQMH4r333ivV/v7772PQoEFPXBQRERFRdapSADp48CBCQkJKtffp0wcHDx584qKIiIiIqlOVAlBeXh5sbW1LtdvY2CA3N/eJiyIiIiKqTlUKQG3atMGWLVtKtW/evBmtWrV64qKIiIiIqlOVrgKbO3cuXnrpJVy6dAnPPvssACAuLg6bNm3CV199ZdQCiYiIiIytSgGoX79+2LVrF959911s27YNGo0Gbdu2xb59+9CzZ09j10hERERkVFV6Gnxtx6fBExER1TzV/jT4o0ePIiEhoVR7QkICjh07VpVVEhEREZlMlQLQhAkTcP369VLtaWlpmDBhwhMXRURERFSdqhSAUlJS0KFDh1Lt7du3R0pKyhMXRURERFSdqhSAVCoVMjMzS7Wnp6fD2rpK86qJiIiITKZKAejvf/87IiIikJOTI7VlZ2fjzTffxPPPP2+04oiIiIiqQ5WGaz788EP06NEDTZs2Rfv27QEAycnJcHFxwYYNG4xaIBEREZGxVSkAubu745dffsHGjRtx8uRJaDQahIWFYdiwYbCxsTF2jURERERGVeUJO3Xq1EG3bt3QpEkTPHz4EADw/fffAwD+8Y9/GKc6IiIiompQpQB0+fJlDBgwAKdOnYJCoYAQAgqFQlqu0+mMViARERGRsVVpEvSUKVPg5eWFrKws2NnZ4fTp0zhw4AD8/f2xf/9+I5dIREREZFxVGgGKj4/HDz/8ACcnJ1hZWUGpVKJbt26IjIzE5MmTceLECWPXSURERGQ0VRoB0ul0qFu3LgDAyckJv/32GwCgadOmOHfunPGqIyIiIqoGVRoBat26NU6ePAkvLy8EBATg/fffh62tLT755BM0a9bM2DUSERERGVWVAtCcOXOQn58PAFi4cCFeeOEFdO/eHQ0aNMCWLVuMWiARERGRsSmEEMIYK7pz5w7q1atncDVYTZWbmwsHBwfk5OTA3t5e7nKIiIioAipz/Dbag7vq169vrFURERERVasqTYI2phUrVsDT0xNqtRoBAQFITEx8bN+ioiIsXLgQ3t7eUKvV8PPzQ0xMTKl+aWlpeOWVV9CgQQNoNBq0adMGx44dq87NICIiohpE1gC0ZcsWhIeHY/78+Th+/Dj8/PwQHByMrKysMvvPmTMHq1evRnR0NFJSUjB27FgMGDDA4LL7u3fvomvXrrCxscH333+PlJQULFmyBPXq1TPVZhEREZGZM9ocoKoICAhAp06dsHz5cgCAXq+Hh4cHJk2ahFmzZpXq7+bmhtmzZ2PChAlS28CBA6HRaPDFF18AAGbNmoXDhw/jp59+qnJdnANERERU81Tm+C3bCNDDhw+RlJSEoKCg34uxskJQUBDi4+PL/ExhYSHUarVBm0ajwaFDh6T3u3fvhr+/PwYNGoSGDRuiffv2WLNmTbm1FBYWIjc31+BFREREtZdsAejWrVvQ6XRwcXExaHdxcUFGRkaZnwkODsbSpUtx4cIF6PV6xMbGYseOHUhPT5f6XL58GStXroSPjw/27t2LcePGYfLkyVi/fv1ja4mMjISDg4P08vDwMM5GEhERkVmSfRJ0ZURFRcHHxwe+vr6wtbXFxIkTERYWBiur3zdDr9ejQ4cOePfdd9G+fXuMGTMGo0ePxqpVqx673oiICOTk5Eiv69evm2JziIiISCayBSAnJycolUpkZmYatGdmZsLV1bXMzzg7O2PXrl3Iz8/HtWvXcPbsWWi1WoO7Tzdq1AitWrUy+FzLli2Rmpr62FpUKhXs7e0NXkRERFR7yRaAbG1t0bFjR8TFxUlter0ecXFxCAwMLPezarUa7u7uKC4uxvbt29G/f39pWdeuXUs9j+z8+fNo2rSpcTeAiIiIaiyj3QixKsLDwxEaGgp/f3907twZy5YtQ35+PsLCwgAAI0aMgLu7OyIjIwEACQkJSEtLQ7t27ZCWloYFCxZAr9djxowZ0jqnTZuGLl264N1338XgwYORmJiITz75BJ988oks20hERETmR9YANGTIENy8eRPz5s1DRkYG2rVrh5iYGGlidGpqqsH8noKCAsyZMweXL1+GVqtFSEgINmzYAEdHR6lPp06dsHPnTkRERGDhwoXw8vLCsmXLMHz4cFNvHhEREZkpWe8DZK54HyAiIqKap0bcB4iIiIhILgxAREREZHEYgIiIiMjiMAARERGRxWEAIiIiIovDAEREREQWhwGIiIiILA4DEBEREVkcBiAiIiKyOLI+CsPiPMwH7t8ue5m1GtA2BO5lAHodoKkHFD0AivJNWyMREZEp2NgBdZxk+3oGIFM69z2w/bXHL3dsCmRfM109REREcmn9MvDyp7J9PQOQKVkpH430/JmuCBC6ssOPwgpQ2lZ/bURERKaktJH16xmATOnpAY9ef/bTEiBuYdmf6TwG6PNe9dZFRERkYTgJ2iwoqriMiIiIqoIByBwoygk55S0jIiKiKmEAMgscASIiIjIlBiBzwBEgIiIik2IAMgsMOURERKbEAGQOOAJERERkUgxAZoFzgIiIiEyJAcgccASIiIjIpBiAzAJHgIiIiEyJAcgccASIiIjIpBiAzAJHgIiIiEyJAcgccASIiIjIpBiAzAJHgIiIiEyJAcgccASIiIjIpBiAzB4DEBERkbExAJkDjgARERGZFAOQWeAcICIiIlNiADIHHAEiIiIyKQYgs8ARICIiIlNiADIHHAEiIiIyKQYgs8ARICIiIlNiADIH5Y4Ama4MIiIiS8EAZBY4AkRERGRKDEDmgHOAiIiITIoByCxwBIiIiMiUGIDMgaKcX0N5y4iIiKhKeHQ1BzwFRkREZFJmEYBWrFgBT09PqNVqBAQEIDEx8bF9i4qKsHDhQnh7e0OtVsPPzw8xMTEGfRYsWACFQmHw8vX1re7NeAI8BUZERGRKsgegLVu2IDw8HPPnz8fx48fh5+eH4OBgZGVlldl/zpw5WL16NaKjo5GSkoKxY8diwIABOHHihEG/p59+Gunp6dLr0KFDpticquEIEBERkUnJHoCWLl2K0aNHIywsDK1atcKqVatgZ2eHtWvXltl/w4YNePPNNxESEoJmzZph3LhxCAkJwZIlSwz6WVtbw9XVVXo5OTmZYnOqiCNAREREpiRrAHr48CGSkpIQFBQktVlZWSEoKAjx8fFlfqawsBBqtdqgTaPRlBrhuXDhAtzc3NCsWTMMHz4cqampxt8AY+EIEBERkUnJGoBu3boFnU4HFxcXg3YXFxdkZGSU+Zng4GAsXboUFy5cgF6vR2xsLHbs2IH09HSpT0BAANatW4eYmBisXLkSV65cQffu3XHv3r0y11lYWIjc3FyDl/lgACIiIjI22U+BVVZUVBR8fHzg6+sLW1tbTJw4EWFhYbCy+n1T+vTpg0GDBqFt27YIDg7Gd999h+zsbGzdurXMdUZGRsLBwUF6eXh4mGpzHuEIEBERkUnJGoCcnJygVCqRmZlp0J6ZmQlXV9cyP+Ps7Ixdu3YhPz8f165dw9mzZ6HVatGsWbPHfo+joyOeeuopXLx4sczlERERyMnJkV7Xr1+v+kZVCecAERERmZKsAcjW1hYdO3ZEXFyc1KbX6xEXF4fAwMByP6tWq+Hu7o7i4mJs374d/fv3f2zfvLw8XLp0CY0aNSpzuUqlgr29vcHLpDgCREREZFKynwILDw/HmjVrsH79epw5cwbjxo1Dfn4+wsLCAAAjRoxARESE1D8hIQE7duzA5cuX8dNPP6F3797Q6/WYMWOG1Gf69Ok4cOAArl69ip9//hkDBgyAUqnEsGHDTL59FcMRICIiIlOylruAIUOG4ObNm5g3bx4yMjLQrl07xMTESBOjU1NTDeb3FBQUYM6cObh8+TK0Wi1CQkKwYcMGODo6Sn1u3LiBYcOG4fbt23B2dka3bt1w5MgRODs7m3rzKoYjQERERCalEEIIuYswN7m5uXBwcEBOTo5pToel7Aa2vlr2spAPgc6jq78GIiKiGq4yx2/ZT4EROAJERERkYgxAZoFzgIiIiEyJAcgccASIiIjIpBiAzAJHgIiIiEyJAcgccASIiIjIpBiAzAJHgIiIiEyJAcgccASIiIjIpBiAzAJHgIiIiEyJAcgccASIiIjIpBiAzAJHgIiIiEyJAcgclJt/GICIiIiMjQHILHAEiIiIyJQYgMwB5wARERGZFAOQWeAIEBERkSkxAJkDRTm/hvKWERERUZXw6GoOeAqMiIjIpBiAzAJDDhERkSkxAJkDjgARERGZFAOQWeAkaCIiIlNiADIHHAEiIiIyKQYgs8ARICIiIlNiADIHHAEiIiIyKQYgs8ARICIiIlNiADIHHAEiIiIyKQYgs8ARICIiIlNiADIHHAEiIiIyKQYgs8ARICIiIlNiADIH5eYfBiAiIiJjYwAyCxwBIiIiMiUGIHPAOUBEREQmxQBkFjgCREREZEoMQOaAI0BEREQmxQBkFjgCREREZEoMQOag3BEg05VBRERkKRiAzAJHgIiIiEzJWu4CCJwDRES1ik6nQ1FRkdxlUC1kY2MDpVJplHUxAJkFjgARUc0nhEBGRgays7PlLoVqMUdHR7i6ukLxhAMEDEDmgCNARFQLlISfhg0bws7O7okPUER/JITA/fv3kZWVBQBo1KjRE62PAcgscASIiGo2nU4nhZ8GDRrIXQ7VUhqNBgCQlZWFhg0bPtHpME6CNgccASKiGq5kzo+dnZ3MlVBtV/I39qTzzBiAzAJHgIioduBpL6puxvobM4sAtGLFCnh6ekKtViMgIACJiYmP7VtUVISFCxfC29sbarUafn5+iImJeWz/xYsXQ6FQYOrUqdVQuZFwBIiIqNbw9PTEsmXLKtx///79UCgUskweX7duHRwdHU3+veZA9gC0ZcsWhIeHY/78+Th+/Dj8/PwQHBwsTXL6szlz5mD16tWIjo5GSkoKxo4diwEDBuDEiROl+h49ehSrV69G27Ztq3sznoyivF8DAxARUXXq1auXUf9P8tGjRzFmzJgK9+/SpQvS09Ph4OBgtBqqU2UDnrmSPQAtXboUo0ePRlhYGFq1aoVVq1bBzs4Oa9euLbP/hg0b8OabbyIkJATNmjXDuHHjEBISgiVLlhj0y8vLw/Dhw7FmzRrUq1fPFJtSPTgCREQkOyEEiouLK9TX2dm5UnOhbG1tjXJZN1WOrAHo4cOHSEpKQlBQkNRmZWWFoKAgxMfHl/mZwsJCqNVqgzaNRoNDhw4ZtE2YMAF9+/Y1WPfjFBYWIjc31+BlUvyjJyKSxciRI3HgwAFERUVBoVBAoVDg6tWr0mmp77//Hh07doRKpcKhQ4dw6dIl9O/fHy4uLtBqtejUqRP27dtnsM4/j5AoFAr85z//wYABA2BnZwcfHx/s3r1bWv7nU2Alp6X27t2Lli1bQqvVonfv3khPT5c+U1xcjMmTJ8PR0RENGjTAzJkzERoaihdffLHc7V23bh2aNGkCOzs7DBgwALdv3zZY/lfb16tXL1y7dg3Tpk2T9hcA3L59G8OGDYO7uzvs7OzQpk0bbNq0qTK/CpOTNQDdunULOp0OLi4uBu0uLi7IyMgo8zPBwcFYunQpLly4AL1ej9jYWOzYscPgD2Pz5s04fvw4IiMjK1RHZGQkHBwcpJeHh0fVN6pKGICIqPYRQuD+w2JZXkKICtUYFRWFwMBAjB49Gunp6UhPTzc4BsyaNQuLFy/GmTNn0LZtW+Tl5SEkJARxcXE4ceIEevfujX79+iE1NbXc73nrrbcwePBg/PLLLwgJCcHw4cNx586dx/a/f/8+PvzwQ2zYsAEHDx5Eamoqpk+fLi1/7733sHHjRnz22Wc4fPgwcnNzsWvXrnJrSEhIwGuvvYaJEyciOTkZzzzzDN5++22DPn+1fTt27EDjxo2xcOFCaX8BQEFBATp27Ig9e/bg9OnTGDNmDF599dVy5/TKrcbdBygqKgqjR4+Gr68vFAoFvL29ERYWJp0yu379OqZMmYLY2NhSI0WPExERgfDwcOl9bm6uaUMQR4CIqBZ6UKRDq3l7ZfnulIXBsLP960Ocg4MDbG1tYWdnB1dX11LLFy5ciOeff156X79+ffj5+UnvFy1ahJ07d2L37t2YOHHiY79n5MiRGDZsGADg3XffxUcffYTExET07t27zP5FRUVYtWoVvL29AQATJ07EwoULpeXR0dGIiIjAgAEDAADLly/Hd999V+62RkVFoXfv3pgxYwYA4KmnnsLPP/9scCGRn59fudtXv359KJVK1K1b12B/ubu7GwS0SZMmYe/evdi6dSs6d+5cbl1ykXUEyMnJCUqlEpmZmQbtmZmZZf4hAo/Ore7atQv5+fm4du0azp49C61Wi2bNmgEAkpKSkJWVhQ4dOsDa2hrW1tY4cOAAPvroI1hbW0On05Vap0qlgr29vcHLtBiAiIjMkb+/v8H7vLw8TJ8+HS1btoSjoyO0Wi3OnDnzlyNAf7wYp06dOrC3t3/sxT7Ao3vdlIQf4NFdj0v65+TkIDMz0yBYKJVKdOzYsdwazpw5g4CAAIO2wMBAo2yfTqfDokWL0KZNG9SvXx9arRZ79+79y8/JSdYRIFtbW3Ts2BFxcXHSeUu9Xo+4uLhykzQAqNVquLu7o6ioCNu3b8fgwYMBAM899xxOnTpl0DcsLAy+vr6YOXOm0R6iZlQcASKiWkhjo0TKwmDZvtsY6tSpY/B++vTpiI2NxYcffojmzZtDo9Hg5ZdfxsOHD8tdj42NjcF7hUIBvV5fqf4VPa33JKq6fR988AGioqKwbNkytGnTBnXq1MHUqVP/8nNykv0UWHh4OEJDQ+Hv74/OnTtj2bJlyM/PR1hYGABgxIgRcHd3l+bzJCQkIC0tDe3atUNaWhoWLFgAvV4vDenVrVsXrVu3NviOOnXqoEGDBqXazQcDEBHVPgqFokKnoeRma2tb5tmBshw+fBgjR46UTj3l5eXh6tWr1VhdaQ4ODnBxccHRo0fRo0cPAI9GYI4fP4527do99nMtW7ZEQkKCQduRI0cM3ldk+8raX4cPH0b//v3xyiuvAHg0mHH+/Hm0atWqKptoErL/ZQ4ZMgQ3b97EvHnzkJGRgXbt2iEmJkaaGJ2amgorq9/P1BUUFGDOnDm4fPkytFotQkJCsGHDhpp9IyeOABERycbT0xMJCQm4evUqtFot6tev/9i+Pj4+2LFjB/r16weFQoG5c+eWO5JTXSZNmoTIyEg0b94cvr6+iI6Oxt27d8u9lH7y5Mno2rUrPvzwQ/Tv3x979+4tdSPhimyfp6cnDh48iKFDh0KlUsHJyQk+Pj7Ytm0bfv75Z9SrVw9Lly5FZmamWQcg2e8DBDya3HXt2jUUFhYiISHB4Bzl/v37sW7dOul9z549kZKSgoKCAty6dQuff/453Nzcyl3//v37zfymTQxARERymT59OpRKJVq1agVnZ+dy560sXboU9erVQ5cuXdCvXz8EBwejQ4cOJqz2kZkzZ2LYsGEYMWIEAgMDodVqERwcXO7FP3/729+wZs0aREVFwc/PD//9738xZ84cgz4V2b6FCxfi6tWr8Pb2hrOzM4BHNynu0KEDgoOD0atXL7i6uv7lJflyUwhTnFSsYXJzc+Hg4ICcnBzTTIjO/Q1Y2rLsZWHfA027VH8NRERPoKCgAFeuXIGXl1eFr8Al49Hr9WjZsiUGDx6MRYsWyV1OtSrvb60yx2/ZT4ERwBEgIiKqjGvXruG///0vevbsicLCQixfvhxXrlzBP//5T7lLqzHM4hSYxeMcICIiqgQrKyusW7cOnTp1QteuXXHq1Cns27cPLVs+5mwClcIRILPAAERERBXn4eGBw4cPy11GjcYRIHPAESAiIiKTYgAyCwxAREREpsQAZA44AkRERGRSDEBmgQGIiIjIlBiAzAFHgIiIiEyKAYiIiIgsDgOQOeAIEBFRjebp6WnwyCWFQoFdu3Y9tv/Vq1ehUCiQnJz8RN9rrPVUxciRI83+cRflYQAyCwxARES1SXp6Ovr06WPUdZYVODw8PJCeno7WrVsb9buqg5xhrSy8EaI54AgQEVGt4urqapLvUSqVJvuu2oYjQGaBAYiISA6ffPIJ3NzcoNfrDdr79++PUaNGAQAuXbqE/v37w8XFBVqtFp06dcK+ffvKXe+fT4ElJiaiffv2UKvV8Pf3x4kTJwz663Q6vPbaa/Dy8oJGo0GLFi0QFRUlLV+wYAHWr1+Pr7/+GgqFAgqFAvv37y9zVOXAgQPo3LkzVCoVGjVqhFmzZqG4uFha3qtXL0yePBkzZsxA/fr14erqigULFpS7PTqdDuHh4XB0dESDBg0wY8YM/PlZ6jExMejWrZvU54UXXsClS5ek5V5eXgCA9u3bQ6FQoFevXgCAo0eP4vnnn4eTkxMcHBzQs2dPHD9+vNx6jIEByBxwBIiIaiMhgIf58rz+dHB+nEGDBuH27dv48ccfpbY7d+4gJiYGw4cPBwDk5eUhJCQEcXFxOHHiBHr37o1+/fohNTW1Qt+Rl5eHF154Aa1atUJSUhIWLFiA6dOnG/TR6/Vo3LgxvvrqK6SkpGDevHl48803sXXrVgDA9OnTMXjwYPTu3Rvp6elIT09Hly5dSn1XWloaQkJC0KlTJ5w8eRIrV67Ep59+irffftug3/r161GnTh0kJCTg/fffx8KFCxEbG/vYbViyZAnWrVuHtWvX4tChQ7hz5w527txp0Cc/Px/h4eE4duwY4uLiYGVlhQEDBkjhMjExEQCwb98+pKenY8eOHQCAe/fuITQ0FIcOHcKRI0fg4+ODkJAQ3Lt3r0L7t6p4CswsMAARUS1UdB94102e737zN8C2zl92q1evHvr06YMvv/wSzz33HABg27ZtcHJywjPPPAMA8PPzg5+fn/SZRYsWYefOndi9ezcmTpz4l9/x5ZdfQq/X49NPP4VarcbTTz+NGzduYNy4cVIfGxsbvPXWW9J7Ly8vxMfHY+vWrRg8eDC0Wi00Gg0KCwvLPeX18ccfw8PDA8uXL4dCoYCvry9+++03zJw5E/PmzYOV1aNxj7Zt22L+/PkAAB8fHyxfvhxxcXF4/vnny1zvsmXLEBERgZdeegkAsGrVKuzdu9egz8CBAw3er127Fs7OzkhJSUHr1q3h7OwMAGjQoIHBNjz77LMGn/vkk0/g6OiIAwcO4IUXXnjstj4pjgCZA44AERHJZvjw4di+fTsKCwsBABs3bsTQoUOlsJCXl4fp06ejZcuWcHR0hFarxZkzZyo8AnTmzBm0bdsWarVaagsMDCzVb8WKFejYsSOcnZ2h1WrxySefVPg7/vhdgYGBUPzhuNK1a1fk5eXhxo0bUlvbtm0NPteoUSNkZWWVuc6cnBykp6cjICBAarO2toa/v79BvwsXLmDYsGFo1qwZ7O3t4enpCQB/uQ2ZmZkYPXo0fHx84ODgAHt7e+Tl5VV62yuLI0DmQMEcSkS1kI3do5EYub67gvr16wchBPbs2YNOnTrhp59+wv/93/9Jy6dPn47Y2Fh8+OGHaN68OTQaDV5++WU8fPjQaOVu3rwZ06dPx5IlSxAYGIi6devigw8+QEJCgtG+449sbGwM3isUilLzoCqrX79+aNq0KdasWSPNq2rduvVf7qfQ0FDcvn0bUVFRaNq0KVQqFQIDA426f8vCAGQWOAJERLWQQlGh01ByU6vVeOmll7Bx40ZcvHgRLVq0QIcOHaTlhw8fxsiRIzFgwAAAj0aErl69WuH1t2zZEhs2bEBBQYE0CnTkyBGDPocPH0aXLl0wfvx4qe2PE4gBwNbWFjqd7i+/a/v27RBCSKNAhw8fRt26ddG4ceMK1/xHDg4OaNSoERISEtCjRw8AQHFxMZKSkqT9dPv2bZw7dw5r1qxB9+7dAQCHDh0qVT+AUttw+PBhfPzxxwgJCQEAXL9+Hbdu3apSrZXBoQdzUN4pMI4OERFVu+HDh2PPnj1Yu3atNPm5hI+PD3bs2IHk5GScPHkS//znPys1WvLPf/4TCoUCo0ePRkpKCr777jt8+OGHpb7j2LFj2Lt3L86fP4+5c+fi6NGjBn08PT3xyy+/4Ny5c7h16xaKiopKfdf48eNx/fp1TJo0CWfPnsXXX3+N+fPnIzw8XDqlVxVTpkzB4sWLsWvXLpw9exbjx49Hdna2tLxevXpo0KABPvnkE1y8eBE//PADwsPDDdbRsGFDaDQaxMTEIDMzEzk5OdK2b9iwAWfOnEFCQgKGDx8OjUZT5VorikdXc2CtAlr2A6zVQPtXgG7THrU3agc07iRraUREluDZZ59F/fr1ce7cOfzzn/80WLZ06VLUq1cPXbp0Qb9+/RAcHGwwQvRXtFotvvnmG5w6dQrt27fH7Nmz8d577xn0+de//oWXXnoJQ4YMQUBAAG7fvm0wGgQAo0ePRosWLeDv7w9nZ2ccPny41He5u7vju+++Q2JiIvz8/DB27Fi89tprmDNnTiX2Rmn//ve/8eqrryI0NFQ6RVcyIgYAVlZW2Lx5M5KSktC6dWtMmzYNH3zwgcE6rK2t8dFHH2H16tVwc3ND//79AQCffvop7t69iw4dOuDVV1/F5MmT0bBhwyeqtyIU4s8X8hNyc3Ph4OCAnJwc2Nvby10OEZHZKygowJUrV+Dl5WUw2ZfI2Mr7W6vM8ZsjQERERGRxGICIiIjI4jAAERERkcVhACIiIiKLwwBEREREFocBiIiIjIYXFlN1M9bfGAMQERE9sZJHK9y/f1/mSqi2K/kb+/PjPCqLj8IgIqInplQq4ejoKD1Q087OzuCBnERPSgiB+/fvIysrC46OjlAqlU+0PgYgIiIyCldXVwB47FPFiYzB0dFR+lt7EgxARERkFAqFAo0aNULDhg3LfE4V0ZOysbF54pGfEgxARERkVEql0mgHKaLqwknQREREZHEYgIiIiMjiMAARERGRxeEcoDKU3GQpNzdX5kqIiIiookqO2xW5WSIDUBnu3bsHAPDw8JC5EiIiIqqse/fuwcHBodw+CsH7lpei1+vx22+/oW7duka/kVdubi48PDxw/fp12NvbG3Xd9DvuZ9PgfjYd7mvT4H42jeraz0II3Lt3D25ubrCyKn+WD0eAymBlZYXGjRtX63fY29vzPy4T4H42De5n0+G+Ng3uZ9Oojv38VyM/JTgJmoiIiCwOAxARERFZHAYgE1OpVJg/fz5UKpXcpdRq3M+mwf1sOtzXpsH9bBrmsJ85CZqIiIgsDkeAiIiIyOIwABEREZHFYQAiIiIii8MARERERBaHAciEVqxYAU9PT6jVagQEBCAxMVHukmqUyMhIdOrUCXXr1kXDhg3x4osv4ty5cwZ9CgoKMGHCBDRo0ABarRYDBw5EZmamQZ/U1FT07dsXdnZ2aNiwId544w0UFxebclNqlMWLF0OhUGDq1KlSG/ezcaSlpeGVV15BgwYNoNFo0KZNGxw7dkxaLoTAvHnz0KhRI2g0GgQFBeHChQsG67hz5w6GDx8Oe3t7ODo64rXXXkNeXp6pN8Ws6XQ6zJ07F15eXtBoNPD29saiRYsMnhfFfV15Bw8eRL9+/eDm5gaFQoFdu3YZLDfWPv3ll1/QvXt3qNVqeHh44P333zfOBggyic2bNwtbW1uxdu1a8euvv4rRo0cLR0dHkZmZKXdpNUZwcLD47LPPxOnTp0VycrIICQkRTZo0EXl5eVKfsWPHCg8PDxEXFyeOHTsm/va3v4kuXbpIy4uLi0Xr1q1FUFCQOHHihPjuu++Ek5OTiIiIkGOTzF5iYqLw9PQUbdu2FVOmTJHauZ+f3J07d0TTpk3FyJEjRUJCgrh8+bLYu3evuHjxotRn8eLFwsHBQezatUucPHlS/OMf/xBeXl7iwYMHUp/evXsLPz8/ceTIEfHTTz+J5s2bi2HDhsmxSWbrnXfeEQ0aNBDffvutuHLlivjqq6+EVqsVUVFRUh/u68r77rvvxOzZs8WOHTsEALFz506D5cbYpzk5OcLFxUUMHz5cnD59WmzatEloNBqxevXqJ66fAchEOnfuLCZMmCC91+l0ws3NTURGRspYVc2WlZUlAIgDBw4IIYTIzs4WNjY24quvvpL6nDlzRgAQ8fHxQohH/8FaWVmJjIwMqc/KlSuFvb29KCwsNO0GmLl79+4JHx8fERsbK3r27CkFIO5n45g5c6bo1q3bY5fr9Xrh6uoqPvjgA6ktOztbqFQqsWnTJiGEECkpKQKAOHr0qNTn+++/FwqFQqSlpVVf8TVM3759xahRowzaXnrpJTF8+HAhBPe1Mfw5ABlrn3788ceiXr16Bv9uzJw5U7Ro0eKJa+YpMBN4+PAhkpKSEBQUJLVZWVkhKCgI8fHxMlZWs+Xk5AAA6tevDwBISkpCUVGRwX729fVFkyZNpP0cHx+PNm3awMXFReoTHByM3Nxc/Prrryas3vxNmDABffv2NdifAPezsezevRv+/v4YNGgQGjZsiPbt22PNmjXS8itXriAjI8NgPzs4OCAgIMBgPzs6OsLf31/qExQUBCsrKyQkJJhuY8xcly5dEBcXh/PnzwMATp48iUOHDqFPnz4AuK+rg7H2aXx8PHr06AFbW1upT3BwMM6dO4e7d+8+UY18GKoJ3Lp1CzqdzuBgAAAuLi44e/asTFXVbHq9HlOnTkXXrl3RunVrAEBGRgZsbW3h6Oho0NfFxQUZGRlSn7J+DyXL6JHNmzfj+PHjOHr0aKll3M/GcfnyZaxcuRLh4eF48803cfToUUyePBm2trYIDQ2V9lNZ+/GP+7lhw4YGy62trVG/fn3u5z+YNWsWcnNz4evrC6VSCZ1Oh3feeQfDhw8HAO7ramCsfZqRkQEvL69S6yhZVq9evSrXyABENdKECRNw+vRpHDp0SO5Sap3r169jypQpiI2NhVqtlrucWkuv18Pf3x/vvvsuAKB9+/Y4ffo0Vq1ahdDQUJmrq122bt2KjRs34ssvv8TTTz+N5ORkTJ06FW5ubtzXFoynwEzAyckJSqWy1FUymZmZcHV1lamqmmvixIn49ttv8eOPP6Jx48ZSu6urKx4+fIjs7GyD/n/cz66urmX+HkqW0aNTXFlZWejQoQOsra1hbW2NAwcO4KOPPoK1tTVcXFy4n42gUaNGaNWqlUFby5YtkZqaCuD3/VTevxuurq7IysoyWF5cXIw7d+5wP//BG2+8gVmzZmHo0KFo06YNXn31VUybNg2RkZEAuK+rg7H2aXX+W8IAZAK2trbo2LEj4uLipDa9Xo+4uDgEBgbKWFnNIoTAxIkTsXPnTvzwww+lhkU7duwIGxsbg/187tw5pKamSvs5MDAQp06dMviPLjY2Fvb29qUORpbqueeew6lTp5CcnCy9/P39MXz4cOln7ucn17Vr11K3cTh//jyaNm0KAPDy8oKrq6vBfs7NzUVCQoLBfs7OzkZSUpLU54cffoBer0dAQIAJtqJmuH//PqysDA93SqUSer0eAPd1dTDWPg0MDMTBgwdRVFQk9YmNjUWLFi2e6PQXAF4GbyqbN28WKpVKrFu3TqSkpIgxY8YIR0dHg6tkqHzjxo0TDg4OYv/+/SI9PV163b9/X+ozduxY0aRJE/HDDz+IY8eOicDAQBEYGCgtL7k8++9//7tITk4WMTExwtnZmZdn/4U/XgUmBPezMSQmJgpra2vxzjvviAsXLoiNGzcKOzs78cUXX0h9Fi9eLBwdHcXXX38tfvnlF9G/f/8yLyNu3769SEhIEIcOHRI+Pj4WfWl2WUJDQ4W7u7t0GfyOHTuEk5OTmDFjhtSH+7ry7t27J06cOCFOnDghAIilS5eKEydOiGvXrgkhjLNPs7OzhYuLi3j11VfF6dOnxebNm4WdnR0vg69poqOjRZMmTYStra3o3LmzOHLkiNwl1SgAynx99tlnUp8HDx6I8ePHi3r16gk7OzsxYMAAkZ6ebrCeq1evij59+giNRiOcnJzEv//9b1FUVGTiralZ/hyAuJ+N45tvvhGtW7cWKpVK+Pr6ik8++cRguV6vF3PnzhUuLi5CpVKJ5557Tpw7d86gz+3bt8WwYcOEVqsV9vb2IiwsTNy7d8+Um2H2cnNzxZQpU0STJk2EWq0WzZo1E7Nnzza4tJr7uvJ+/PHHMv9NDg0NFUIYb5+ePHlSdOvWTahUKuHu7i4WL15slPoVQvzhVphEREREFoBzgIiIiMjiMAARERGRxWEAIiIiIovDAEREREQWhwGIiIiILA4DEBEREVkcBiAiIiKyOAxAREQVsH//figUilLPQCOimokBiIiIiCwOAxARERFZHAYgIqoR9Ho9IiMj4eXlBY1GAz8/P2zbtg3A76en9uzZg7Zt20KtVuNvf/sbTp8+bbCO7du34+mnn4ZKpYKnpyeWLFlisLywsBAzZ86Eh4cHVCoVmjdvjk8//dSgT1JSEvz9/WFnZ4cuXbqUeqI7EdUMDEBEVCNERkbi888/x6pVq/Drr79i2rRpeOWVV3DgwAGpzxtvvIElS5bg6NGjcHZ2Rr9+/VBUVATgUXAZPHgwhg4dilOnTmHBggWYO3cu1q1bJ31+xIgR2LRpEz766COcOXMGq1evhlarNahj9uzZWLJkCY4dOwZra2uMGjXKJNtPRMbFh6ESkdkrLCxE/fr1sW/fPgQGBkrtr7/+Ou7fv48xY8bgmWeewebNmzFkyBAAwJ07d9C4cWOsW7cOgwcPxvDhw3Hz5k3897//lT4/Y8YM7NmzB7/++ivOnz+PFi1aIDY2FkFBQaVq2L9/P5555hns27cPzz33HADgu+++Q9++ffHgwQOo1epq3gtEZEwcASIis3fx4kXcv38fzz//PLRarfT6/PPPcenSJanfH8NR/fr10aJFC5w5cwYAcObMGXTt2tVgvV27dsWFCxeg0+mQnJwMpVKJnj17lltL27ZtpZ8bNWoEAMjKynribSQi07KWuwAior+Sl5cHANizZw/c3d0NlqlUKoMQVFUajaZC/WxsbKSfFQoFgEfzk4ioZuEIEBGZvVatWkGlUiE1NRXNmzc3eHl4eEj9jhw5Iv189+5dnD9/Hi1btgQAtGzZEocPHzZY7+HDh/HUU09BqVSiTZs20Ov1BnOKiKj24ggQEZm9unXrYvr06Zg2bRr0ej26deuGnJwcHD58GPb29mjatCkAYOHChWjQoAFcXFwwe/ZsODk54cUXXwQA/Pvf/0anTp2waNEiDBkyBPHx8Vi+fDk+/vhjAICnpydCQ0MxatQofPTRR/Dz88O1a9eQlZWFwYMHy7XpRFRNGICIqEZYtGgRnJ2dERkZicuXL8PR0REdOnTAm2++KZ2CWrx4MaZMmYILFy6gXbt2+Oabb2BrawsA6NChA7Zu3Yp58+Zh0aJFaNSoERYuXIiRI0dK37Fy5Uq8+eabGD9+PG7fvo0mTZrgzTfflGNziaia8SowIqrxSq7Qunv3LhwdHeUuh4hqAM4BIiIiIovDAEREREQWh6fAiIiIyOJwBIiIiIgsDgMQERERWRwGICIiIrI4DEBERERkcRiAiIiIyOIwABEREZHFYQAiIiIii8MARERERBaHAYiIiIgszv8DpDOFWY7wFmEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.legend(['training data', 'validation data'], loc = 'lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "676443bb-983f-4d7e-ad00-f27b6fb5f7b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x14724b3e9a0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABiq0lEQVR4nO3dd3gU5d7G8e+mJ4Q0AgmBQEKRIr3FAPZoEEVQlCJKUeE9do2ooFIEj6CiBxAE5YjYELBhAUEIxQOGDtKrIC0JNQkhkLbz/rGyYUmAkDYp9+e69srOM8/O/GaA7M3MMzMWwzAMRERERCoQJ7MLEBERESlpCkAiIiJS4SgAiYiISIWjACQiIiIVjgKQiIiIVDgKQCIiIlLhKACJiIhIhaMAJCIiIhWOApCIiIhUOApAIlLmHThwAIvFwowZM675s8uWLcNisbBs2bIr9psxYwYWi4UDBw4UqEYRKV0UgERERKTCUQASERGRCkcBSERERCocBSARKbSRI0disVjYvXs3Dz/8ML6+vlStWpVhw4ZhGAaHDh2ia9eu+Pj4EBwczHvvvZdrGceOHeOxxx4jKCgIDw8PmjdvzmeffZarX1JSEv3798fX1xc/Pz/69etHUlJSnnXt3LmTBx54gICAADw8PGjTpg0//fRTkW77hx9+yPXXX4+7uzshISE89dRTuerZs2cP3bt3Jzg4GA8PD2rWrEmvXr1ITk6291m0aBEdO3bEz88Pb29vGjRowKuvvlqktYpIDhezCxCR8qNnz540atSIsWPHMm/ePN58800CAgL46KOPuO2223j77bf56quvGDx4MG3btuWmm24C4Ny5c9xyyy3s3buXp59+mvDwcL755hv69+9PUlISzz33HACGYdC1a1dWrFjBv/71Lxo1asQPP/xAv379ctWybds2OnToQI0aNRgyZAiVKlVizpw5dOvWje+++4777ruv0Ns7cuRI3njjDaKionjiiSfYtWsXU6ZMYe3ataxcuRJXV1cyMjKIjo4mPT2dZ555huDgYI4cOcIvv/xCUlISvr6+bNu2jXvuuYdmzZoxatQo3N3d2bt3LytXrix0jSJyGYaISCGNGDHCAIxBgwbZ27KysoyaNWsaFovFGDt2rL399OnThqenp9GvXz972/jx4w3A+PLLL+1tGRkZRmRkpOHt7W2kpKQYhmEYc+fONQDjnXfecVjPjTfeaADGp59+am+//fbbjaZNmxrnz5+3t1mtVqN9+/ZG/fr17W1Lly41AGPp0qVX3MZPP/3UAIz9+/cbhmEYx44dM9zc3Iw777zTyM7OtvebNGmSARjTp083DMMwNm7caADGN998c9ll/+c//zEA4/jx41esQUSKjk6BiUiRefzxx+3vnZ2dadOmDYZh8Nhjj9nb/fz8aNCgAX/99Ze9bf78+QQHB9O7d297m6urK88++yypqaksX77c3s/FxYUnnnjCYT3PPPOMQx2nTp1iyZIl9OjRgzNnznDixAlOnDjByZMniY6OZs+ePRw5cqRQ27p48WIyMjJ4/vnncXLK+VU6cOBAfHx8mDdvHgC+vr4ALFy4kLS0tDyX5efnB8CPP/6I1WotVF0ikj8KQCJSZGrVquUw7evri4eHB4GBgbnaT58+bZ/++++/qV+/vkOQAGjUqJF9/oWf1atXx9vb26FfgwYNHKb37t2LYRgMGzaMqlWrOrxGjBgB2MYcFcaFmi5dt5ubG3Xq1LHPDw8PJyYmhv/+978EBgYSHR3N5MmTHcb/9OzZkw4dOvD4448TFBREr169mDNnjsKQSDHSGCARKTLOzs75agPbeJ7iciE4DB48mOjo6Dz71KtXr9jWf6n33nuP/v378+OPP/Lbb7/x7LPPMmbMGFatWkXNmjXx9PTk999/Z+nSpcybN48FCxYwe/ZsbrvtNn777bfL7kMRKTgdARIR09WuXZs9e/bkOuKxc+dO+/wLP+Pj40lNTXXot2vXLofpOnXqALbTaFFRUXm+KleuXOia81p3RkYG+/fvt8+/oGnTprz++uv8/vvv/O9//+PIkSNMnTrVPt/JyYnbb7+d999/n+3bt/Pvf/+bJUuWsHTp0kLVKSJ5UwASEdN17tyZhIQEZs+ebW/Lysrigw8+wNvbm5tvvtneLysriylTptj7ZWdn88EHHzgsr1q1atxyyy189NFHxMfH51rf8ePHC11zVFQUbm5uTJw40eFo1ieffEJycjJ33303ACkpKWRlZTl8tmnTpjg5OZGeng7YxixdqkWLFgD2PiJStHQKTERMN2jQID766CP69+/P+vXrCQsL49tvv2XlypWMHz/efrSmS5cudOjQgSFDhnDgwAEaN27M999/7zCe5oLJkyfTsWNHmjZtysCBA6lTpw6JiYnExcVx+PBh/vzzz0LVXLVqVYYOHcobb7xBp06duPfee9m1axcffvghbdu25eGHHwZgyZIlPP300zz44INcd911ZGVl8cUXX+Ds7Ez37t0BGDVqFL///jt33303tWvX5tixY3z44YfUrFmTjh07FqpOEcmbApCImM7T05Nly5YxZMgQPvvsM1JSUmjQoAGffvop/fv3t/dzcnLip59+4vnnn+fLL7/EYrFw77338t5779GyZUuHZTZu3Jh169bxxhtvMGPGDE6ePEm1atVo2bIlw4cPL5K6R44cSdWqVZk0aRIvvPACAQEBDBo0iLfeegtXV1cAmjdvTnR0ND///DNHjhzBy8uL5s2b8+uvv3LDDTcAcO+993LgwAGmT5/OiRMnCAwM5Oabb+aNN96wX0UmIkXLYhTnSEQRERGRUkhjgERERKTCUQASERGRCkcBSERERCocBSARERGpcBSAREREpMJRABIREZEKR/cByoPVauXo0aNUrlwZi8VidjkiIiKSD4ZhcObMGUJCQnI9XPlSCkB5OHr0KKGhoWaXISIiIgVw6NAhatasecU+CkB5uHDb/UOHDuHj42NyNSIiIpIfKSkphIaG5uthxwpAebhw2svHx0cBSEREpIzJz/AVDYIWERGRCkcBSERERCocBSARERGpcDQGSEREilR2djaZmZlmlyHlkKurK87OzkWyLAUgEREpEoZhkJCQQFJSktmlSDnm5+dHcHBwoe/TpwAkIiJF4kL4qVatGl5eXrqRrBQpwzBIS0vj2LFjAFSvXr1Qy1MAEhGRQsvOzraHnypVqphdjpRTnp6eABw7doxq1aoV6nSYBkGLiEihXRjz4+XlZXIlUt5d+DtW2HFmCkAiIlJkdNpLiltR/R1TABIREZEKRwFIRESkCIWFhTF+/Ph891+2bBkWi8WUq+dmzJiBn59fia+3NFAAEhGRCu2WW27h+eefL7LlrV27lkGDBuW7f/v27YmPj8fX17fIaihO1xrwSitdBSYiInIVhmGQnZ2Ni8vVvzarVq16Tct2c3MjODi4oKWVPdmZtpebuQPmdQRIREQqrP79+7N8+XImTJiAxWLBYrFw4MAB+2mpX3/9ldatW+Pu7s6KFSvYt28fXbt2JSgoCG9vb9q2bcvixYsdlnnpERKLxcJ///tf7rvvPry8vKhfvz4//fSTff6lp8AunJZauHAhjRo1wtvbm06dOhEfH2//TFZWFs8++yx+fn5UqVKFV155hX79+tGtW7crbu+MGTOoVasWXl5e3HfffZw8edJh/tW275ZbbuHvv//mhRdesO8vgJMnT9K7d29q1KiBl5cXTZs25euvv867iLSTcGIXJB28Yq3FTQFIRESKhWEYpGVkmfIyDCNfNU6YMIHIyEgGDhxIfHw88fHxhIaG2ucPGTKEsWPHsmPHDpo1a0ZqaiqdO3cmNjaWjRs30qlTJ7p06cLBg1f+Mn/jjTfo0aMHmzdvpnPnzvTp04dTp05dtn9aWhrjxo3jiy++4Pfff+fgwYMMHjzYPv/tt9/mq6++4tNPP2XlypWkpKQwd+7cK9awevVqHnvsMZ5++mk2bdrErbfeyptvvunQ52rb9/3331OzZk1GjRpl318A58+fp3Xr1sybN4+tW7cyaNAgHnnkEdasWZOzcKsVUo/DmX+CnFulK9Zb3ErFKbDJkyfz7rvvkpCQQPPmzfnggw9o165dnn2///573nrrLfbu3UtmZib169fnxRdf5JFHHrH3MQyDESNGMG3aNJKSkujQoQNTpkyhfv36JbVJIiIV3rnMbBoPX2jKurePisbL7epfcb6+vri5ueHl5ZXnaahRo0Zxxx132KcDAgJo3ry5fXr06NH88MMP/PTTTzz99NOXXU///v3p3bs3AG+99RYTJ05kzZo1dOrUKc/+mZmZTJ06lbp16wLw9NNPM2rUKPv8Dz74gKFDh3LfffcBMGnSJObPn3/FbZ0wYQKdOnXi5ZdfBuC6667jjz/+YMGCBfY+zZs3v+L2BQQE4OzsTOXKlR32V40aNRwC2jPPPMPChQuZM2eO7fs887ztqI9htXWwOIGH3xXrLW6mHwGaPXs2MTExjBgxgg0bNtC8eXOio6Ptt7q+VEBAAK+99hpxcXFs3ryZAQMGMGDAABYuzPlH9s477zBx4kSmTp3K6tWrqVSpEtHR0Zw/f76kNktERMqBNm3aOEynpqYyePBgGjVqhJ+fH97e3uzYseOqR4CaNWtmf1+pUiV8fHwu+z0Htpv9XQg/YHvsw4X+ycnJJCYmOhwocHZ2pnXr1lesYceOHURERDi0RUZGFsn2ZWdnM3r0aJo2bUpAQADe3t4sXLiQg/v3QsJWOL4jJ/wAePqBU9E81LSgTD8C9P777zNw4EAGDBgAwNSpU5k3bx7Tp09nyJAhufrfcsstDtPPPfccn332GStWrCA6OhrDMBg/fjyvv/46Xbt2BeDzzz8nKCiIuXPn0qtXr2LfJhERAU9XZ7aPijZt3UWhUiXH0zSDBw9m0aJFjBs3jnr16uHp6ckDDzxARkbGFZfj6urqMG2xWLBarZfpnXf//J7WK4yCbt+7777LhAkTGD9+PE2vb0wlDzeeH/wyGWeTwXrRHZs9fMHFE7yrFfOWXJ2pASgjI4P169czdOhQe5uTkxNRUVHExcVd9fOGYbBkyRJ27drF22+/DcD+/ftJSEggKirK3s/X15eIiAji4uIUgERESojFYsnXaSizubm5kZ2dna++K1eupH///vZTT6mpqRw4cKAYq8vN19eXoKAg1q5dy0033QTYjsBs2LCBFi1aXPZzjRo1YvXq1Q5tq1atcpjOz/bltb9WrlxJ165debh3T0jcitWazu4d22h8XR1bB/9wcPEAV48CbHHxMPVv5okTJ8jOziYoKMihPSgoiJ07d172c8nJydSoUYP09HScnZ358MMP7edoExIS7Mu4dJkX5l0qPT2d9PR0+3RKSkqBtkdERMqesLAwVq9ezYEDB/D29iYgIOCyfevXr8/3339Ply5dsFgsDBs27IpHcorLM888w5gxY6hXrx4NGzbkgw8+4PTp01d8TMSzzz5Lhw4dGDduHF27dmXhwoUO438gf9sXFhbG77//Tq9evXB3dycwMJD6devy7fff88dvc/H3cuL9j78i8cQpWwDyq2075VXKmD4GqCAqV67Mpk2bWLt2Lf/+97+JiYlh2bJlBV7emDFj8PX1tb8uvgJARETKt8GDB+Ps7Ezjxo2pWrXqFce7vP/++/j7+9O+fXu6dOlCdHQ0rVq1KsFqbV555RV69+5N3759iYyMxNvbm+joaDw8Ln+E5YYbbmDatGlMmDCB5s2b89tvv/H666879MnP9o0aNYoDBw5Qt25d2z2Pzifz+sD7aNW4LtEP9ueWBwYRXLUK3aJvAYtzqQw/ABajJE4qXkZGRgZeXl58++23Dvcu6NevH0lJSfz444/5Ws7jjz/OoUOHWLhwIX/99Rd169Zl48aNDocCb775Zlq0aMGECRNyfT6vI0ChoaEkJyfj4+NT4O0TEakozp8/z/79+wkPD7/il7AUD6vVSqNGjejRowejR48umZVmZ8K505ByxLHdyQWq1AdnF9v7Inalv2spKSn4+vrm6/vb1CNAbm5utG7dmtjYWHub1WolNjY218j0K7FarfYAEx4eTnBwsMMyU1JSWL169WWX6e7ujo+Pj8NLRESktPr777+ZNm0au3fvZsuWLTzxxBPs37+fhx56qGQKsGZD4tbc4cfiDIENbGN9iiH8FCXTq4uJiaFfv360adOGdu3aMX78eM6ePWu/Kqxv377UqFGDMWPGALbTVW3atKFu3bqkp6czf/58vvjiC6ZMmQLYBt09//zzvPnmm9SvX5/w8HCGDRtGSEjIVe+QKSIiUhY4OTkxY8YMBg8ejGEYNGnShMWLF9OoUaPiXbE1y3YH5/PJju0BdW2DnJ1d4QrjkEoT0wNQz549OX78OMOHDychIYEWLVqwYMEC+yDmgwcP4uSUc6Dq7NmzPPnkkxw+fBhPT08aNmzIl19+Sc+ePe19Xn75Zc6ePcugQYNISkqiY8eOLFiwQIdlRUSkXAgNDWXlypUlu9L0VNtdnDNSc9p8apSKS9oLwtQxQKXVtZxDFBERjQEqt1KOQmpi3vO8q9kCUAkrqjFAph8BEhERkVIoKz3v8OMfZnuMRRk51XU5CkAiIiKSwzBsd28+tj33PP8w8PQv8ZKKgwKQiIiI2J7UnnYCsi55bqZ3kO1l8rO7ipoCkIiISEVmzYIzCXD2eO55bpWhcvUyf7orLwpAIiIiFVHmeTi1D7IvedCpxRmc3cC3Brh5l8vwA2X0URgiIiKlSVhYGOPHj7dPWywW5s6de9n+Bw4cwGKxsGnTpkKtt8DLMQxIOewYfpzdbA8trd4MqjUE98pXDD/9+/cv0/fX0xEgERGRIhYfH4+/f9EOFu7fvz9JSUkOwSo0NJT4+HgCAwOvvgDDsN3Dx9kNkg5BxpmceX61wevyD4EtCgcOHCA8PDzXo6rMogAkIiJSxIKDg0tkPc7OzvlbV/oZOLkPuOTWf5Wq2U51VUA6BSYiIhXWxx9/TEhICFar1aG9a9euPProowDs27ePrl27EhQUhLe3N23btmXx4sVXXO6lp8DWrFlDy5Yt8fDwoE2bNmzcuNGhf3Z2No899hjh4eF4enrSoEEDh4d3jxw5ks8++4wff/wRi8WCxWJh2bJleZ4CW758Oe3atcPd3Z3q1asz5KUXyUrcyYXwc8sDA3l22Du8/M4nBIQ3JTg4mJEjR15xe7Kzs4mJicHPz48qVarw8ssvc+l9lBcsWEDHjh3tfe655x727dtnnx8eHg5Ay5YtsVgs3HLLLQCsXbuWO+64g8DAQHx9fbn55pvZsGHDFespCgpAIiJSPAwDMs6a88rnQw4efPBBTp48ydKlS+1tp06dYsGCBfTp0weA1NRUOnfuTGxsLBs3bqRTp0506dKFgwcP5msdqamp3HPPPTRu3Jj169czcuRIBg8e7NDHarVSs2ZNvvnmG7Zv387w4cN59dVXmTNnDgCDBw+mR48edOrUifj4eOLj42nfvn2udR05coTOnTvTtm1b/ty4gSn/fplPpk/nzQn/zenk5Mpn386nkn9VVq9ezTvvvMOoUaNYtGjRZbfhvffeY8aMGUyfPp0VK1Zw6tQpfvjhB4c+Z8+eJSYmhnXr1hEbG4uTkxP33XefPVyuWbMGgMWLFxMfH8/3338PwJkzZ+jXrx8rVqxg1apV1K9fn86dO3PmzBmKk06BiYhI8chMg7dCzFn3q0fBrdJVu/n7+3PXXXcxc+ZMbr/9dgC+/fZbAgMDufXWWwFo3rw5zZs3t39m9OjR/PDDD/z00088/fTTV13HzJkzsVqtfPLJJ3h4eHD99ddz+PBhnnjiCXsfV1dX3njjDft0eHg4cXFxzJkzhx49euDt7Y2npyfp6elXPOX14YcfEhoayqRJk7CcO0VDv1s4mnCMV96ayPBXYnAKrAcu7jRr1owRI0YAUL9+fSZNmkRsbCx33HFHnssdP348Q4cO5f777wdg6tSpLFy40KFP9+7dHaanT59O1apV2b59O02aNKFq1aoAVKlSxWEbbrvtNofPffzxx/j5+bF8+XLuueeey25rYekIkIiIVGh9+vThu+++Iz09HYCvvvqKXr162R/EnZqayuDBg2nUqBF+fn54e3uzY8eOfB8B2rFjB82aNXN4blVkZGSufpMnT6Z169ZUrVoVb29vPv7443yvAwBrNju2bSGyVRMsJ3bZntoOdIhoQ+rZNA6f97TfzLBZs2YOH61evTrHjh3Lc7HJycnEx8cTERFhb3NxcaFNmzYO/fbs2UPv3r2pU6cOPj4+hIWFAVx1GxITExk4cCD169fH19cXHx8fUlNTr23bC0BHgEREpHi4etmOxJi17nzq0qULhmEwb9482rZty//+9z/+85//2OcPHjyYRYsWMW7cOOrVq4enpycPPPAAGRkZV1jqtZk1axaDBw/mvffeIzIyksqVK/Puu++yevXq/C3g/BlI2Gy7ysvdGzLP2dqd3SAgLFd3V1dXh2mLxZJrHNS16tKlC7Vr12batGn2cVVNmjS56n7q168fJ0+eZMKECdSuXRt3d3ciIyOLdP/mRQFIRESKh8WSr9NQZvPw8OD+++/nq6++Yu/evTRo0IBWrVrZ569cuZL+/ftz3333AbYjQgcOHMj38hs1asQXX3zB+fPn7UeBVq1a5dBn5cqVtG/fnieffNLedvEAYgA3Nzeys7MdF57+zziZlCNAAxrVC+e7+Usw3H2xuHqCVwArv/uEypUrU7NmzXzXfDFfX1+qV6/O6tWruemmmwDIyspi/fr19v108uRJdu3axbRp07jxxhsBWLFiRa76gVzbsHLlSj788EM6d+4MwKFDhzhx4kSBar0WOgUmIiIVXp8+fZg3bx7Tp0+3D36+oH79+nz//fds2rSJP//8k4ceeuiajpY89NBDWCwWBg4cyPbt25k/fz7jxo3LtY5169axcOFCdu/ezbBhw1i7dq1Dn7CwMDZv3syuXbs4ceIEmamn7ae5LniyXw8OxR/jmRHvs/NoMj/OW8CIESOIiYmxn9IriOeee46xY8cyd+5cdu7cyZNPPklSUpJ9vr+/P1WqVOHjjz9m7969LFmyhJiYGIdlVKtWDU9PTxYsWEBiYiLJycn2bf/iiy/YsWMHq1evpk+fPnh6eha41vxSABIRkQrvtttuIyAggF27dvHQQw85zHv//ffx9/enffv2dOnShejoaIcjRFfj7e3Nzz//zJYtW2jZsiWvvfYab7/9tkOf//u//+P++++nZ8+eREREcPLkSYejQQADH3+cBnVr06aNbZzQysW/OK7IK5Aa10cyf/581qxZQ/PmzfnXv/7FY489xuuvv35tO+QSL774Io888gj9+vWzn6K7cEQMwMnJiVmzZrF+/XqaNGnCCy+8wLvvvuuwDBcXFyZOnMhHH31ESEgIXbt2BeCTTz7h9OnTtGrVikceeYRnn32WatWqFare/LAYl17IL6SkpODr60tycjI+Pj5mlyMiUuqdP3+e/fv3Ex4e7jDYV4rQudNw+sA/ExbsNzWsVNX2wNJy9rT2y7nS37Vr+f7WGCAREZHSzpp9yemuf8KPfzh4+plRUZmnACQiIlLaGAaciYfsTNtAZ2um43xnd/CtCR46S1FQCkAiIiKlTfoZSE3MY4aT7WntV3hKu+SPApCIiEhpkZ0BZxIg7eQlMywQEA5ulRV+iogCkIiIFBldV1NIpw5A5lnHNoszVGsEzq55fqSiKaq/YwpAIiJSaBfuLJyWllYi93ApVzLTIOkQZKWDcdFNAv3DbVd2ubgr/FwkLS0NyH0362ulACQiIoXm7OyMn5+f/XlSXl5eWHSq5vIMA9JO2B5hkX3+kplOEFAHLG62i70yrZB5aZ+KxzAM0tLSOHbsGH5+fjg7F+6yfwUgEREpEhee8H25h2rKRc4lQXpK7nZnV3D3gbNHSrykssLPz8/hafIFpQAkIiJFwmKxUL16dapVq0ZmZubVP1DRZGfC/t/h5F5YOy2nPaA+dPsQvPzNq62McHV1LfSRnwsUgEREpEg5OzsX2ZdUuZGwBT662XGMD0DTB6HLRHDL/9PrpWgoAImIiBSnnfNg7hO5w8+ABVA70pyaRAFIRESkWFitsPa/8OtLOW33fQRV6kNwU3BxM682UQASEREpUvGb4c9ZsO172+MsLmjcDZr3Mq0scaQAJCIiUlRSj8OnnSHjTE5b6A1QoxXc+pp5dUkuCkAiIiJFYccvMOcRMKw5bT0+h8ZdzatJLksBSEREpKDOJ8NfyyFuEhxandPuHwbX3QUN7jatNLkyBSAREZGCsFphZi84+EdOW9Me0GksVKpiXl2SLwpAIiIi1yorA2LfcAw/XSZA6/6mlSTXRgFIREQkP7Iy4PhO+OMD2DInp71ZT6hSD1o+Yl5tcs0UgERERK7mj0nwWx5Xcd0+Am6MKfl6pNAUgERERK5k3ae5w8+9H9iu7vLwNacmKTQFIBERkUsd2wlrPoJzp2HbDznt/mHQ51sIrG9aaVI0FIBEREQuyEiDddNhyZuQdS6nvd0guOsdsFjMq02KlAKQiIgIgGHAj086HvFp8gDUux2a9VL4KWcUgEREpGJLPgzulWHRcMfw06qvbayPlEsKQCIiUnH9OQt++D/HtsohUCsC2j9nTk1SIhSARESk4jmTACf3wYYvcs/r8w0ENyn5mqREKQCJiEjFcfpvmD8Y9vzm2N55HLh6Qc02ULWBObVJiXIyuwCAyZMnExYWhoeHBxEREaxZs+ayfadNm8aNN96Iv78//v7+REVF5erfv39/LBaLw6tTp07FvRkiIlKaJWyFCc1yh5+G90Cbx6BlH4WfCsT0ADR79mxiYmIYMWIEGzZsoHnz5kRHR3Ps2LE8+y9btozevXuzdOlS4uLiCA0N5c477+TIkSMO/Tp16kR8fLz99fXXX5fE5oiISGn0dxxM7eDY5hUI0W9Bj8/ByfSvQylhFsMwDDMLiIiIoG3btkyaNAkAq9VKaGgozzzzDEOGDLnq57Ozs/H392fSpEn07dsXsB0BSkpKYu7cuQWqKSUlBV9fX5KTk/Hx8SnQMkREpBQ4d9r2xPZDq3LabhkKN72s0FMOXcv3t6l/+hkZGaxfv56oqCh7m5OTE1FRUcTFxeVrGWlpaWRmZhIQEODQvmzZMqpVq0aDBg144oknOHny5GWXkZ6eTkpKisNLRETKgeXv5IQf72B4eh3c/IrCj5g7CPrEiRNkZ2cTFBTk0B4UFMTOnTvztYxXXnmFkJAQhxDVqVMn7r//fsLDw9m3bx+vvvoqd911F3FxcTg7O+daxpgxY3jjjTcKtzEiImK+M4kwu4/t9FZGKhz4n6292vXQZYIeYSF2ZfoqsLFjxzJr1iyWLVuGh4eHvb1Xr172902bNqVZs2bUrVuXZcuWcfvtt+daztChQ4mJyXmab0pKCqGhocVbvIiIFK3sTJj1EBxZ59h+2zC4abA5NUmpZWoACgwMxNnZmcTERIf2xMREgoODr/jZcePGMXbsWBYvXkyzZs2u2LdOnToEBgayd+/ePAOQu7s77u7u174BIiJivrMnbM/uWv9p7nkNOsONL5Z8TVLqmXoS1M3NjdatWxMbG2tvs1qtxMbGEhkZednPvfPOO4wePZoFCxbQpk2bq67n8OHDnDx5kurVqxdJ3SIiYrLsTDi0Fg6vg3frOoYfv9rw4i64/79w31Q9w0vyZPopsJiYGPr160ebNm1o164d48eP5+zZswwYMACAvn37UqNGDcaMGQPA22+/zfDhw5k5cyZhYWEkJCQA4O3tjbe3N6mpqbzxxht0796d4OBg9u3bx8svv0y9evWIjo42bTtFRKQILX0LVryfuz1qJET8C1w9odmDJV6WlB2mB6CePXty/Phxhg8fTkJCAi1atGDBggX2gdEHDx7E6aLR+lOmTCEjI4MHHnjAYTkjRoxg5MiRODs7s3nzZj777DOSkpIICQnhzjvvZPTo0TrNJSJSHmRl5A4/Pb+ChnfraI/km+n3ASqNdB8gEZFS6PTf8NUDcGK3Y/uNL8Ltw82pSUqVa/n+Nv0IkIiIyBUdWgPLxsK+WMf26Leg5SPgof+oyrVTABIRkdIrPRU+7wqZabnnRfwLnHLf200kPxSARESk9Dn1F6ybDmumQdb5nPbr77cd8WnxsMKPFIoCkIiIlB4ZZ2HTTIgdBekXPZao4wu2K7xEiogCkIiIlA5WK3z7GOz+Naet7m0Q+TSE32xeXVIuKQCJiIj5Dq+HGXdD1jnbtLsv3DfFdmm7SDFQABIREfNsngO/vgznTue03TEKOjxnXk1SISgAiYhIycvOgvPJ8NvrjuGneW9oN8i8uqTCUAASEZGSlRIPX3aHY9ty2m4cDK37g1+oaWVJxaIAJCIiJWPPYti9wHaVV+bZnPbbh+uJ7VLiFIBERKT4nT0BMx8Ew+rY7uoFHWPMqUkqNAUgEREpPhlnc1/aDtBlAmSegwZ36QGmYgoFIBERKXqpx+HA77ByAsT/mdNePxqa9YAm3RV8xFQKQCIiUrT2LIbZfRwfYeFVBe5803aVl4KPlAIKQCIiUnhpp8ArAA6shK+629pcvSCgLgQ3tZ3ycnEzt0aRiygAiYhI4WyeA98PdGyrXB2eXgfu3ubUJHIVTmYXICIiZdhfy3KHH4B7Jyn8SKmmI0AiInLt0s/Ar6/Apq8c2299zfb8rqDrzalLJJ8UgEREJP+Sj0BGqu1OzsmHbG3ewfDwt1CtMTg5m1ufSD4pAImISP6snwE/X/KQ0rq3Q9fJ4FPdlJJECkoBSEREru7wOsfw4xUIT/wBlYPMq0mkEBSAREQkb2cSYeFQ2Ppd7nmd31H4kTJNAUhERHJLT4X3rnNs8wyARxdC1evy/oxIGaIAJCIiNumptnE+55Pg93cd59WLggc+BQ8fMyoTKXIKQCIiAtt/hDl9c7fX7ghRIyCkJTi7lnxdIsVEAUhEpKLLysg7/LToA90+LPl6REqAApCISEV2Yi9891ju9jtGQYfncreLlBMKQCIiFdGexfDHBNj/u2N7t6ngXRXCbzGjKpESowAkIlKRGAYseRP+N86xPaAuDFwCnn6mlCVS0hSAREQqguTDcC4JfvgXJG7Jaa8VCa0HQPOeppUmYgYFIBGR8swwYNv38O2jju2VQ6DPNxDcxJy6REymACQiUl7tXggze+RuD2kFg5aWfD0ipYiT2QWIiEgxySv8VA6BBz8t+VpEShkdARIRKY92/+Y47VsLuoyHWjeAWyVTShIpTRSARETKg+xMOLrR9rI4wfyXbO212sODM/TgUpFLKACJiJQHC4bC2mmObQF14ZHvwdXTnJpESjEFIBGRssyabXtw6aXhx68W9Phc4UfkMhSARETKmu0/wW+vQ/07cwef4KbQezZUDgYnZ3PqEykDFIBERMqS8ykw5xHb+0vDzwvbwb0yePiUfF0iZYwugxcRKStWToSxoY5t7j5QvQX0+RZ8ayj8iOSTjgCJiJQF23+ERcNypl0rQYvecOebGucjUgAKQCIipdnO+fD3SoibZJtucDfcORqq1DW3LpEyTgFIRKS0WvY2LHvLsa3TW+AfZko5IuWJApCISGmScRb2LIJFwyHpb8d5D3+n8CNSRErFIOjJkycTFhaGh4cHERERrFmz5rJ9p02bxo033oi/vz/+/v5ERUXl6m8YBsOHD6d69ep4enoSFRXFnj17inszREQKLvkIrP8M3gqBb/rlhJ+2A2HYSXgtAepFmVujSDliegCaPXs2MTExjBgxgg0bNtC8eXOio6M5duxYnv2XLVtG7969Wbp0KXFxcYSGhnLnnXdy5MgRe5933nmHiRMnMnXqVFavXk2lSpWIjo7m/PnzJbVZIiL5l3QI/tMYfn4297yOL4CziwY6ixQxi2EYhpkFRERE0LZtWyZNsg3ws1qthIaG8swzzzBkyJCrfj47Oxt/f38mTZpE3759MQyDkJAQXnzxRQYPHgxAcnIyQUFBzJgxg169el11mSkpKfj6+pKcnIyPjy4pFZFilBIPH7SGzLM5bdffB/d+YLunj4jk27V8f5s6BigjI4P169czdOhQe5uTkxNRUVHExcXlaxlpaWlkZmYSEBAAwP79+0lISCAqKudQsa+vLxEREcTFxeUZgNLT00lPT7dPp6SkFHSTRETyZ/dvMPPBnGlXL4j4Pwi/Gereal5dIhWEqafATpw4QXZ2NkFBjk8pDgoKIiEhIV/LeOWVVwgJCbEHngufu5ZljhkzBl9fX/srNDQ0z34iIkUi5ahj+AHbjQyjRir8iJQQ08cAFcbYsWOZNWsWP/zwAx4eHgVeztChQ0lOTra/Dh06VIRVioj8I/0M/PAveL+RY3v3TyCsgzk1iVRQpp4CCwwMxNnZmcTERIf2xMREgoODr/jZcePGMXbsWBYvXkyzZs3s7Rc+l5iYSPXq1R2W2aJFizyX5e7ujru7ewG3QkTkKv5aBl/cD0a2Y3vd26DLBNuT20WkRJl6BMjNzY3WrVsTGxtrb7NarcTGxhIZGXnZz73zzjuMHj2aBQsW0KZNG4d54eHhBAcHOywzJSWF1atXX3GZIiLF4u84+LxrTvjx9IcHpsPrx+GRHxR+RExi+o0QY2Ji6NevH23atKFdu3aMHz+es2fPMmDAAAD69u1LjRo1GDNmDABvv/02w4cPZ+bMmYSFhdnH9Xh7e+Pt7Y3FYuH555/nzTffpH79+oSHhzNs2DBCQkLo1q2bWZspIhXRviXwxX050/WjofM7upmhSClgegDq2bMnx48fZ/jw4SQkJNCiRQsWLFhgH8R88OBBnJxyDlRNmTKFjIwMHnjgAYfljBgxgpEjRwLw8ssvc/bsWQYNGkRSUhIdO3ZkwYIFhRonJCKSbzvnwdwn4HxyTtugZRDS0rSSRMSR6fcBKo10HyARuWanD8COX+CvpbB3cU575RAYtBQqX3lco4gUXpm5D5CISJkX/ydsmgn7lsKJXY7zun4IDe4CrwBzahORy1IAEhEpCMOA1R/Bglfynv/cnxrrI1KKlen7AImImGb3wrzDT0BdeGaDwo9IKacjQCIiBbH2vznva3eA66Kh6YPgE2JeTSKSbwpAIiJXE78Zfvg/OP03VG0AZ09A8kHbvGc2QJW65tYnItdMAUhE5HLOJcHMnnBoVU7b0Q0575v2UPgRKaM0BkhEJC/ZmfD7u47h52IN74FuH5ZsTSJSZHQESEQkL7P6wJ6FOdOulWxPaj++y/bg0rvfBydn8+oTkUJRABIRueB8iu3xFcvGwPGdOe3NesHtw8G3hnm1iUiRUgASEQHIPA9T2kPyIcf2Ds/BHaPMqUlEio0CkIiIYcD8wY7hp3J16PeLBjmLlFMKQCJSMRkGWCyw9Tv49tGcdu8geOBTqNEKXD3Nq09EipUCkIhUPH/HwVcPQEaqY/sdo6HDs+bUJCIlSgFIRCqOYzvB3RuWvJk7/Di5QvtnzKlLREqcApCIVAwn98FHN0J2Rk5bzbZgzYb4TfDoAtspMRGpEBSARKR8i/8TPP1hUhswrDnt94yHNgNsNzw8nwyVAk0rUURKngKQiJRfu3+DmQ86tt02DOrfCdWb2aadXRV+RCogBSARKX8Mw3Yzw+VvO7Y7uULHF3QHZxFRABKRcmZOP9g+17HNrza0fBhueknjfEQEUAASkfLk0BrH8FOtse1mhpWqmFaSiJROCkAiUvZt/BIWvgbnk3LabngKbnsN3CqZVpaIlF4KQCJSdiUdhDl94ejGnDYPX3hmgwY2i8gVKQCJSNmSnQm/vgKHVkPiVsd5zm7w4AyFHxG5KgUgESlbVk+FdZ/kbn98CVRrBG5eJV+TiJQ5CkAiUnb89jr88cFFDRboOsl2hZeIyDVQABKR0i3lKMzsAQlbctpqtIZbXwV3Xwhta15tIlJmKQCJSOlkGPDD/8Hm2bnn9fgcfGuWfE0iUm44mV2AiEieDq/NHX7qRcFriQo/IlJoOgIkIqVH5jk49Rd8/3+QeNEpr6YPQos+UOcW3clZRIqEApCImM9qhcUj4I+Jju2VqsIdo6BZTz2/S0SKlAKQiJjDMGDZWPD0g9/HQdoJx/mNu8Hd7+mePiJSLBSARMQc8X/C8rG521v1hfbPQmD9kq9JRCoMBSARKVkHVtrCza5fc88bcgg8fEq+JhGpcBSARKTkbPwSfnzKsa16c2jS3fbwUmf9ShKRkqHfNiJSMo7vzh1+6t0BvWaCi5s5NYlIhVWg+wB99tlnzJs3zz798ssv4+fnR/v27fn777+LrDgRKePSz8CWb+H9xjD5ojs2+4ZCq34KPyJimgIFoLfeegtPT08A4uLimDx5Mu+88w6BgYG88MILRVqgiJRRmefhP9fDd49BypF/Gi3Qfz68sBXunajwIyKmKdApsEOHDlGvXj0A5s6dS/fu3Rk0aBAdOnTglltuKcr6RKQs+msZfN7VsS38ZrjhSQjrYEpJIiIXK1AA8vb25uTJk9SqVYvffvuNmJgYADw8PDh37lyRFigiZcTJffDFfZB0yWnw2h1gwHxzahIRuYwCBaA77riDxx9/nJYtW7J79246d+4MwLZt2wgLCyvK+kSktDuTCIYV5r2YO/x0ehvaPmZOXSIiV1CgADR58mRef/11Dh06xHfffUeVKlUAWL9+Pb179y7SAkWkFMtKh49ugtQEx3YnF9s9fdy8zKlLROQqLIZhGGYXUdqkpKTg6+tLcnIyPj66KZtInpIOwmf3wun9ju1dJkDLvuBUoGssREQK7Fq+vwv0G2rBggWsWLHCPj158mRatGjBQw89xOnTpwuySBEpK6xWWPImjG+aO/z0mgmt+yv8iEipV6DfUi+99BIpKSkAbNmyhRdffJHOnTuzf/9++4BoESmHtv8IX94Pv7+b01a9BdSKhIFLoOHdppUmInItChSA9u/fT+PGjQH47rvvuOeee3jrrbeYPHkyv/6ax/N9rmDy5MmEhYXh4eFBREQEa9asuWzfbdu20b17d8LCwrBYLIwfPz5Xn5EjR2KxWBxeDRs2vKaaROQSyYdh8UiY0xf+WprT/uJu+L/l8OgCqNHatPJERK5VgQKQm5sbaWlpACxevJg777wTgICAAPuRofyYPXs2MTExjBgxgg0bNtC8eXOio6M5duxYnv3T0tKoU6cOY8eOJTg4+LLLvf7664mPj7e/Lj5dJyLXyDDg41thxX9y2pxc4KW/oHKQeXWJiBRCga4C69ixIzExMXTo0IE1a9Ywe/ZsAHbv3k3NmjXzvZz333+fgQMHMmDAAACmTp3KvHnzmD59OkOGDMnVv23btrRta7udfl7zL3BxcbliQBKRfEg7BZu+gjMJcPai/5TU7gA3vQSVqphXm4hIIRXoCNCkSZNwcXHh22+/ZcqUKdSoUQOAX3/9lU6dOuVrGRkZGaxfv56oqKicYpyciIqKIi4uriBl2e3Zs4eQkBDq1KlDnz59OHjw4BX7p6enk5KS4vASqdDOnYZZfeC31yFukuO8fj9D3VvNqUtEpIgU6AhQrVq1+OWXX3K1/+c//8mjd95OnDhBdnY2QUGOh9CDgoLYuXNnQcoCICIighkzZtCgQQPi4+N54403uPHGG9m6dSuVK1fO8zNjxozhjTfeKPA6RcqVnfNhVh7382rcFW4cDE7OJV+TiEgRK1AAAsjOzmbu3Lns2LEDsI27uffee3F2NveX41133WV/36xZMyIiIqhduzZz5szhscfyviPt0KFDHa5eS0lJITQ0tNhrFSlVzp2GxW/A+k9t057+0Oc7qFLH9l5EpBwpUADau3cvnTt35siRIzRo0ACwHUUJDQ1l3rx51K1b96rLCAwMxNnZmcTERIf2xMTEIh2/4+fnx3XXXcfevXsv28fd3R13d/ciW6dImWG1wvkk2w0NE7fktF/XCW56GWrqyi4RKZ8KNAbo2WefpW7duhw6dIgNGzawYcMGDh48SHh4OM8++2y+luHm5kbr1q2JjY21t1mtVmJjY4mMjCxIWXlKTU1l3759VK9evciWKVIurP0vjPKHd8Idw88do+Ch2Qo/IlKuFegI0PLly1m1ahUBAQH2tipVqjB27Fg6dOiQ7+XExMTQr18/2rRpQ7t27Rg/fjxnz561XxXWt29fatSowZgxYwDbwOnt27fb3x85coRNmzbh7e1NvXr1ABg8eDBdunShdu3aHD16lBEjRuDs7KxnlIlc7Mh628NLL/VqvJ7fJSIVQoECkLu7O2fOnMnVnpqaipubW76X07NnT44fP87w4cNJSEigRYsWLFiwwD4w+uDBgzhddEv9o0eP0rJlS/v0uHHjGDduHDfffDPLli0D4PDhw/Tu3ZuTJ09StWpVOnbsyKpVq6hatWpBNlWkfIn/E9x9YEYXx/bK1aHLRIUfEakwCvQw1L59+7JhwwY++eQT2rVrB8Dq1asZOHAgrVu3ZsaMGUVdZ4nSw1ClXIr/Ez66Gbjon3xQE/jXCrBYTCtLRKSoXMv3d4GOAE2cOJF+/foRGRmJq6srAJmZmXTt2jXPx1OIiElSj8HC12DLnNzzmvWCeycq/IhIhVSgAOTn58ePP/7I3r177ZfBN2rUyD4OR0RKiU87w8k9jm1VG0GDTnDra+Dsak5dIiImy3cAutpT3pcuzXlA4vvvv1/wikSk8FKPw8Khl4QfCzTrCfdN1VEfEanw8h2ANm7cmK9+Fv1iFTHP+RRY+m9YPdWxvXE36PGZKSWJiJRG+Q5AFx/hEZFSKPWYbZDzmaM5beE3Qat+UP8O8+oSESmFCvwoDBEpReL/hI9ucmx79DeoFWFOPSIipZwCkEhZdWIvJB+EfUvhj4k57dffB5FPQ8025tUmIlLKKQCJlEWGAV91h9MHHNubPwRdJoBL/m9IKiJSESkAiZQ1Visseyt3+HlmA1S5+oOIRUREAUik7DAM+OFfsHmWY7tXIPT5RuFHROQaKACJlHbHdsC+JVDnFsfwc8NTcNvr4OIOTs6mlSciUhYpAImUZpnn4NtH4dh2x/ZakXDnaAUfEZECUgASKa3Wz4Cfn8vd/sCn0OhehR8RkUJQABIpjXYvzB1+uk2B0AiN9RERKQIKQCKljWHAnL450636QuQzUPU682oSESlnFIBESouT+yDrPMx/yfYTwMUD7noHXD3NrU1EpJxRABIxm9UKKUfgw0jITs9p7/gC3DLUdpWXiIgUKQUgETMdWAEze0HGGcd2dx+4eYjCj4hIMVEAEjGLYcA3AxzDT/tnwdMfIp9S+BERKUYKQCIlzTAg9g1Y8R/H9vs+gua9zKlJRKSCUQASKWk/PwsbPs+Zvn0EtHkUPP1MK0lEpKJRABIpKZvnwIndjuGnenPbYGeLxby6REQqIAUgkeKUlQ7rP7MFnPmDHefVioQeXyj8iIiYQAFIpLgsGgErx+c9r8cX0PjeEi1HRERyOJldgEi5k5UOWRm5w4+bt+1n84cUfkRETKYjQCJFaccvMLtP7vbaHeG+qeBTQ6e8RERKAQUgkaJyJiF3+KndAQbMN6ceERG5LJ0CEykK8X/Cf67P3d7+2ZKvRURErkoBSKSwdvwCH90E1izH9vunQYNO5tQkIiJXpAAkUhiZ5xxPe3WbAiEtIfQGaNLdvLpEROSKNAZIpKDOJ8OMu3OmWz4MLR6yvUREpFRTABK5VoYBuxfC1z1t006u0PdHCOtgbl0iIpJvCkAi1+LASpjR2bHt9mEKPyIiZYwCkEh+HFoL+5fD0rdy2pp0h7vf10NMRUTKIAUgkavZsxi+umhAc5V6cMOT0KofOOufkIhIWaTf3iJX8r/3IHZUznTLR2xHfVzczKtJREQKTQFIJC/WbPj0Lji0OqftscUQ2ta8mkREpMjoPkAieYnf5Bh+nN2gZhvTyhERkaKlACRyqV2/wrTbcqabPABPrtJDTEVEyhGdAhMByDgLB+Ng+4+weU5Oe9+foM7N5tUlIiLFQgFIZP//4KsHIetcTltoBDz8Pbh7m1eXiIgUGwUgqdjOJcFn99jeV6oKQddDg7uhdX9d6SUiUo4pAEnF9OcsWDAUzp3KaesyARreffnPiIhIuaEAJBWPYcAP/+fY5lsLwm40px4RESlxpl8FNnnyZMLCwvDw8CAiIoI1a9Zctu+2bdvo3r07YWFhWCwWxo8fX+hlSgVzbCeMDnRsu+VVeH4zePiYU5OIiJQ4UwPQ7NmziYmJYcSIEWzYsIHmzZsTHR3NsWPH8uyflpZGnTp1GDt2LMHBwUWyzJK091gqP/95lI0HT5tdSsUU/yd8GAHWLNt0UFNo8TBEDNIl7iIiFYzFMAzDrJVHRETQtm1bJk2aBIDVaiU0NJRnnnmGIUOGXPGzYWFhPP/88zz//PNFtswLUlJS8PX1JTk5GR+fojsqsOLzETTd9zFbA++iwzPTi2y5chWpx2HzLNv9ff5emdM+/BQ4OZtXl4iIFKlr+f427QhQRkYG69evJyoqKqcYJyeioqKIi4sr0WWmp6eTkpLi8CoOrk4WfC1puGUWz/IlD4YBc/rCb687hp8uExR+REQqMNMC0IkTJ8jOziYoKMihPSgoiISEhBJd5pgxY/D19bW/QkNDC7T+qzHcKgHgmp1WLMuXPHz3OBz8I2e6aQ8Yftp2mbuIiFRYpg+CLg2GDh1KcnKy/XXo0KHiWZGb7aZ6CkAl4EwifP9/sPVb23T15vDAdOg2BZz0115EpKIz7TL4wMBAnJ2dSUxMdGhPTEy87ADn4lqmu7s77u7uBVrntbD8c1dhdwWg4pWdCZ92glN/5bR1/RCCm5hXk4iIlCqm/VfYzc2N1q1bExsba2+zWq3ExsYSGRlZapZZlJw8KgPgblUAKnLZmTD3SfhvFHxyp2P4uWe8wo+IiDgw9UaIMTEx9OvXjzZt2tCuXTvGjx/P2bNnGTBgAAB9+/alRo0ajBkzBrANct6+fbv9/ZEjR9i0aRPe3t7Uq1cvX8s0k5P7PwHIOG9yJeXQ1u9g01e52wf8CrXbl3w9IiJSqpkagHr27Mnx48cZPnw4CQkJtGjRggULFtgHMR88eBCni8ZrHD16lJYtW9qnx40bx7hx47j55ptZtmxZvpZpJmdPWwDy1BGgopWRlvvOzlUbwcAl4OZlTk0iIlKqmXofoNKquO4DtHXHDprMvoEsnHAZcUo33yssw4B102Hhq5D1z1G1lo9AmwEQ0kr7V0SkgrmW7289C6wEuXrZ/jBcsEJWOrh6mFxRGXY+GX4fB39MzGm7/j7d30dERPJFAagEuXpWxmpYcLIYti9wBaCCSTkK0ztB0t85bQF1oft0XeIuIiL5ogBUgjzcXEmmEv6kwrlTUNn8cUlljmHAvBdt4adSVWj3f7Z7/IS0VPgREZF8UwAqQe4uTpw2vPG3pJJ99hQ6UXMNDq+DmT0h7UROW6+vIbSteTWJiEiZpf8ylyAPV2eSsN0MMSv1pMnVlCFnEmDzHMfwA7YjPyIiIgWgI0AlyMPVmdOG7VL4zNQTFP+9p8uBxG0w9UYwsh3br+sELm7m1CQiImWeAlAJcnaycMaiI0D5lnkOlvzbMfyEtILu/wXfmubVJSIiZZ4CUAlLcfYDA6ypx80upfSb9yLsmufY1nuWBo+LiEihKQCVsNMuVSETLCmHzS6ldFs/w/HRFr614MYYhR8RESkSCkAlLMW1GmSC85mjZpdSOqWfgYWvwYbPbNMWZ3h5H3j6m1uXiIiUKwpAJeyMexCkgdvZeLNLKZ3WTMsJPwCvHwNn/TUVEZGipW+WEpbmEQyA+7ljkJ2lL/cLzp6Ej26ElCM5bS6e2j8iIlIsdB+gEpbpEUiG4YwFK5zRUSAATuyFd+s4hh+vQOg6ybyaRESkXNN/r0uYp7srCUYAtSzHbV/4fqFml2Qew4Af/g82z3Zs7/Md1I8ypyYREakQFIBKmJe7C/FUoRbHIbmCXgmWlQ6T2kDSQcf2GwfDzS+Di24RKSIixUunwEpYZQ8XDlqr2SaO7zK3GLMc2ZA7/NS5FW4fpvAjIiIlQgGohPl7ufGnUdc2cWSducWYIfU4fPVgzrR/ODTuBj2/MK0kERGpeHQKrIT5e7nys7WebeLIerBawakC5NCDq2H6nY5td70LEYPMqUdERCq0CvDNW7r4ebmxywglHXc4nwwn95pdUvFLOpQ7/PSeBW0fN6ceERGp8BSASlhAJTeycGGH0z9HgfYsNLeg4rbhCxjfxLGt7u3Q4K6KceRLRERKJX0DlTB/L1cAfrG2tzVs+dbEaoqRYcA3/eGnp3PaWj4CncfB/dNMK0tERAQUgEqcn5cbAD+nt7A1xG+CuA9Nq6fYbJ8L237Imfbwhbvfg3YDoVIV08oSEREBBaAS5+dpOwKUaPiTVfV6W2PsKDh9wLyiilLqMRjf1Hb054JG98LT63WJu4iIlBoKQCXMxdmJyh62i+8O3jMLvKpA1jlYOcHkyoqAYcB3j+Xc46feHTBwCXT/BLyrmlubiIjIRRSATBBQyXYa7JThDd2m2Br3LrYFiLJs1Yew/3fb+xuehIfmQI3W4OJmbl0iIiKX0H2ATODn5cbfJ9M4nZYJdTuAayXbUZNt30OT7maXd23WTANPf0jY7HgU69ZXdZWXiIiUWgpAJrhwJdjpsxngHgTtn4HlY2HVFLj+frBYTK4wn07sgfmDHds8/KDvj+Be2ZSSRERE8kP/RTdBoLdtMPDx1HRbQ+v+4OIBh9fCzl/MKyy/Ms/b7mD98S2O7Q3vgVcOQEgLE4oSERHJPwUgE1T39QDgaNI5W4NPdduYGYDVH5lUVT4YBhxYCe/UgVH+kJGaM+/eD6DXV2Xn6JWIiFRoCkAmqO7rCUBC8vmcxraPgcUJDvwPju82qbJLZGdB8hHbe8OAuU/AjM6QeTanj7sPxOyAVn3NqVFERKQANAbIBNX9/jkCdHEA8q0J4TfBX8tgyWi47yNw8zKnQIDMc7ZTXMd3QtiNEBoBf37t2Oee/0CbR00pT0REpDB0BMgEIf8cAYpPPuc4IzTC9nPHT/BWdfjhCfMujV/ypi38gO2o1P/GOc5/brPCj4iIlFkKQCa4cAQoKS2TcxnZOTMa3m07DXbBnzPhkzvgfErhV/r7uzCpHaQczXu+Nds2b28sTL4B4ibl7tPkAdvRoHb/B/61C1+TiIiISXQKzAQ+Hq54u7uQmp5FfPI56lT1ts2o3hyGHIRtc3MeInp4rW3czeNLwNkVDCs4OedvRanHbAOVPfxsR3QA1n0Kt71me3/6b9j4JWSnX/5O1M9sAP9wOBMPPiEa5CwiIuWCApBJgn092Hsslfjk8zkBCGz3z2n1iO1o0NwnYPcCSNgCk9tBaiIEXge9v7aFkUulHLV9fvtPcPY4LB4Bzu7QrEdOn/hNsOFz+OmZKxfY5jGIfAqq1LVN+9Yo9DaLiIiUFgpAJqnp78neY6kcPJVGh7w6eAXAQ7Nh5URYNAxO77e1x2+C9xvZ3oe0ghtjYP//4MRu+Gtp7uVkp8PGL3Km9/xme+XFrbLtJoY1WulIj4iIlGsKQCapE+jNsl3H+et46pU7RvzL9piJLd/knnd0A8x+uOBF1O4A55LgpsHQ5P6CL0dERKSMUQAySXjVSgD8dfzslTu6uEH3/8ItQ2H/cmh0Lyx/G9Z8fPnPtB1oGyu05zfoNdMWoIKbwifRtifPN7wHbh8OVRsU4RaJiIiUHQpAJqkb+E8AOnGVAHRBlbo543E6v2t7JR+xDU6uUs92Q8LLPXy0ejPbz0d/hZP7oOkDhaxeRESkbFMAMsmFgc8HT6WRkWXFzaUAdyTwrXFtg5NDWtpeIiIiFZzuA2SSIB93vNycybYaHDyVZnY5IiIiFYoCkEksFgv1q9mOAu2IL4IbHYqIiEi+KQCZqGlNXwC2HEk2uRIREZGKRQHIRM1q+AHw56EkU+sQERGpaEpFAJo8eTJhYWF4eHgQERHBmjVrrtj/m2++oWHDhnh4eNC0aVPmz5/vML9///5YLBaHV6dOnYpzEwqkWajtCNDWI8lYrSY99FRERKQCMj0AzZ49m5iYGEaMGMGGDRto3rw50dHRHDt2LM/+f/zxB7179+axxx5j48aNdOvWjW7durF161aHfp06dSI+Pt7++vrrr0tic65JvareeLg6cTYjO/+Xw4uIiEihmR6A3n//fQYOHMiAAQNo3LgxU6dOxcvLi+nTp+fZf8KECXTq1ImXXnqJRo0aMXr0aFq1asWkSY5PL3d3dyc4ONj+8vf3L4nNuSYuzk40CbkwDijJ3GJEREQqEFMDUEZGBuvXrycqKsre5uTkRFRUFHFxcXl+Ji4uzqE/QHR0dK7+y5Yto1q1ajRo0IAnnniCkydPXraO9PR0UlJSHF4l5cJA6A1/J5XYOkVERCo6UwPQiRMnyM7OJigoyKE9KCiIhISEPD+TkJBw1f6dOnXi888/JzY2lrfffpvly5dz1113kZ2dnecyx4wZg6+vr/0VGhpayC3Lv/Z1AwFYtvsYhqFxQCIiIiWhXN4JulevXvb3TZs2pVmzZtStW5dly5Zx++235+o/dOhQYmJi7NMpKSklFoI61KuCm4sTh06dY++xVOoHVS6R9YqIiFRkph4BCgwMxNnZmcTERIf2xMREgoOD8/xMcHDwNfUHqFOnDoGBgezduzfP+e7u7vj4+Di8SoqXmwuRdaoAELsz74HfIiIiUrRMDUBubm60bt2a2NhYe5vVaiU2NpbIyMg8PxMZGenQH2DRokWX7Q9w+PBhTp48SfXq1Yum8CJ2e6NqACzZoQAkIiJSEky/CiwmJoZp06bx2WefsWPHDp544gnOnj3LgAEDAOjbty9Dhw6193/uuedYsGAB7733Hjt37mTkyJGsW7eOp59+GoDU1FReeuklVq1axYEDB4iNjaVr167Uq1eP6OhoU7bxam5tYAtA6w+eJiktw+RqREREyj/TxwD17NmT48ePM3z4cBISEmjRogULFiywD3Q+ePAgTk45Oa19+/bMnDmT119/nVdffZX69eszd+5cmjRpAoCzszObN2/ms88+IykpiZCQEO68805Gjx6Nu7u7Kdt4NaEBXlwX5M3uxFSW7z5O1xbX8IR3ERERuWYWQ5ce5ZKSkoKvry/JycklNh5o7K87mbp8H/c2D2Fi75Ylsk4REZHy5Fq+v00/BSY2URfGAe08xrmMvC/XFxERkaKhAFRKtKrlT01/T1LTs1i4Le97IImIiEjRUAAqJZycLHRvVROA7zYcNrkaERGR8k0BqBS5EIBW7D3B0aRzJlcjIiJSfikAlSK1qnjRLjwAw4AfNh4xuxwREZFySwGolHmg9T+nwdYf1rPBREREiokCUCnTuWl1PF2d+evEWTYeSjK7HBERkXJJAaiU8XZ34a6mtuea/WfRbpOrERERKZ8UgEqhp2+th4uThf/tOcG+46lmlyMiIlLuKACVQnWqetO+XiAAs9YcNLkaERGR8kcBqJQa0D4MgM/j/iY+WZfEi4iIFCUFoFLqlgZVaRvmT3qWlYmxe8wuR0REpFxRACqlLBYLL3dqCMCcdYf5S2OBREREiowCUCnWNiyA2xpWI9tq8L6uCBMRESkyCkCl3OA7GwDwy+Z4th5JNrkaERGR8kEBqJRrHOJD1xYhAAz+5k/SMrJMrkhERKTsUwAqA4be1YhAbzd2Jpxh8tK9ZpcjIiJS5ikAlQHBvh682a0JAJ//8TeJKedNrkhERKRsUwAqI+5oHEzzmr6cSc/itR+26EGpIiIihaAAVEY4O1l454HmuDpbWLzjGD9uOmp2SSIiImWWAlAZ0iC4Ms/eVh+AV3/YwqLtiSZXJCIiUjYpAJUxT9xSlxvrB5KWkc0TX67nwImzZpckIiJS5igAlTEuzk5M79+WyDpVyLIavD53K1arxgOJiIhcCwWgMsjV2YnX7m6Ep6szK/aeYNiPWzUoWkRE5BooAJVRTWr48sa912OxwFerD/Lx73+ZXZKIiEiZoQBUhvVoG8rILtcDMHbBTr5df9jkikRERMoGBaAyrm9kbXq3q4Vh2B6V8cWqv80uSUREpNRTACrjLBYLo7peT//2YQAM/3ErczceMbcoERGRUk4BqBxwdXZiRJfG9ImwHQl6Yc4mRv60jXMZ2WaXJiIiUiopAJUTFouF0V2b0C+yNoYBM/44QI+P4jiRmm52aSIiIqWOAlA54uRkYeS91/Na50a4OFnYciSZeyauYP3fp8wuTUREpFRRACpnLBYLA2+qw9ynOhBWxYuElPP0+ngVY37dQUaW1ezyRERESgUFoHKqSQ1f5j93I7c2qEpmtsFHy//i7on/Y/nu42aXJiIiYjoFoHLMy82FTwe0Y0KvFvh7ubLnWCr9pq/h1R+2cDY9y+zyRERETKMAVAF0bVGDRTE32y+Vn7n6IFHvL+eLuANkZeu0mIiIVDwWQw+RyiUlJQVfX1+Sk5Px8fExu5wi9ce+E7z0zWaOJJ0DoF41b/q1D+OBVjXxdHM2uToREZGCu5bvbwWgPJTnAARwPjObWWsO8t5vuznzz6mwqpXdebB1TR6/sQ4BldxMrlBEROTaKQAVUnkPQBeknM/ku/WH+WTFfg6fth0RcnNx4p5m1ekTUZtWtfywWCwmVykiIpI/CkCFVFEC0AXpWdks2p7IR8v/YsuRZHt7vWre3FS/Kg+2qUnD4MoKQyIiUqopABVSRQtAFxiGwaZDSXy56iDzthzlfGbOAOlaAV7c1rAaN10XSNuwACp7uJpYqYiISG4KQIVUUQPQxVLOZ/Lrlnh+3ZrAH/tOOtxE0c3ZiaY1fYmsU4V24QG0rOWnQCQiIqZTACokBSBHZ9OzWLH3BEt2HGPV/pP8fTLNYb6TBa4LqkzTGr40rO5Dw+DKNAyuTBVvd5MqFhGRikgBqJAUgC7PMAwOnkpj9f5TrNp3krV/n+LQqXN59g30difQ240GwZWJCK9CWKAXNfw8qe7riZuLbkElIiJFSwGokBSArk1iynk2HUpi29EUdiWksDPhDAdPpXG5v1kuThZCA7wI8fOguq8n3u4u1PT3pG41b6pVdqdaZQ+qVHLDyUmDrkVEJP/KXACaPHky7777LgkJCTRv3pwPPviAdu3aXbb/N998w7Bhwzhw4AD169fn7bffpnPnzvb5hmEwYsQIpk2bRlJSEh06dGDKlCnUr18/X/UoABXe2fQsdieeITElne1Hk9l4KIkjSec4mnTOYXD15bg4Waha2R1/Lzcqe7hQ2cMVH08XfDxc8blourKHK5U9bO2VPVzw8bT9dHfRTR1FRCqaMhWAZs+eTd++fZk6dSoRERGMHz+eb775hl27dlGtWrVc/f/44w9uuukmxowZwz333MPMmTN5++232bBhA02aNAHg7bffZsyYMXz22WeEh4czbNgwtmzZwvbt2/Hw8LhqTQpAxccwDOKTz3PwVBqHT58jMeU8SWkZHDp1jgMnz3IiNZ2TZzMue/Qov9xcnOxhydvDBQ9XZ7zcnPF0/efllvPz4nluLk62l7MTrhd+Ojvh6mz552fOezeXS6adnXTUSkTERGUqAEVERNC2bVsmTZoEgNVqJTQ0lGeeeYYhQ4bk6t+zZ0/Onj3LL7/8Ym+74YYbaNGiBVOnTsUwDEJCQnjxxRcZPHgwAMnJyQQFBTFjxgx69ep11ZoUgMyVlW3leGo6x1LSOZ2WwZnzWZw5n0XK+UzOnM8k5VwWZ85nXtSWRco5288zJj/k1dnJYgtETrYAdXFwcrLY5jtZLLg4W3C2WHBysv10dsp5OVksuDhdfp6zEzg7OeHsBE4Wy0UvcHKyYLHY2p3/acNi4Z8fWLD88/Of6X/u7ZTnPHLm2X5evJx/pv95f6V1wD/Luvhz9vXn9M+9jouWb1+WxXH9lywnz3Vcshxy1XhpvZdZR84S7PJza6xL++RnOXkt99LP5V7u1dedV6/8LCe/CnOvsML+16EwtynL68+kJNZbGOXhtmyV3V3x9SraK4iv5fvbpUjXfI0yMjJYv349Q4cOtbc5OTkRFRVFXFxcnp+Ji4sjJibGoS06Opq5c+cCsH//fhISEoiKirLP9/X1JSIigri4uDwDUHp6Ounp6fbplJSUwmyWFJKLsxPVfW2Dpa9VttUgNT3LISilpmdxLjObcxnZnM/M5lxmNmkZtp/nMy56n5lNepaVjCwrGdlWsrINMrNt7zOzrWRmXTKdbZBtNXKtP9tqcB4rpF+mSBER4clb6vJyp4amrd/UAHTixAmys7MJCgpyaA8KCmLnzp15fiYhISHP/gkJCfb5F9ou1+dSY8aM4Y033ijQNkjp4uxkwdfTFV9PV/Av/vVZrQaZVlsYysyyXhSQ/glLWVayrLb32VYDq9Ug2zDIuvDeamD9Z9r+Ptv2M9sK2Vbb57IN27qyrBfm2d5jGFgNbG2GgfFPvwttxj/zDWzzDPjn9OI/03nMM/hnggttxkXzcqa5+LOXWQd5fO7iabjks5cs58I6rrQcHKYvXo7jOv7Z6stsx6XLzVkOFy3nYpe2XNrFuKRH7vlX/vylPfI6Vp97GcZV5l9b/wIrogUVxWKK6iRHUe2boijn0r9bZZWLyUMGTA1ApcXQoUMdjiqlpKQQGhpqYkVSVjg5WXB3csbdBdBtj0REygxTb8YSGBiIs7MziYmJDu2JiYkEBwfn+Zng4OAr9r/w81qW6e7ujo+Pj8NLREREyi9TA5CbmxutW7cmNjbW3ma1WomNjSUyMjLPz0RGRjr0B1i0aJG9f3h4OMHBwQ59UlJSWL169WWXKSIiIhWL6afAYmJi6NevH23atKFdu3aMHz+es2fPMmDAAAD69u1LjRo1GDNmDADPPfccN998M++99x533303s2bNYt26dXz88ceA7SqE559/njfffJP69evbL4MPCQmhW7duZm2miIiIlCKmB6CePXty/Phxhg8fTkJCAi1atGDBggX2QcwHDx7EySnnQFX79u2ZOXMmr7/+Oq+++ir169dn7ty59nsAAbz88sucPXuWQYMGkZSURMeOHVmwYEG+7gEkIiIi5Z/p9wEqjXQfIBERkbLnWr6/9URKERERqXAUgERERKTCUQASERGRCkcBSERERCocBSARERGpcBSAREREpMJRABIREZEKRwFIREREKhwFIBEREalwTH8URml04ebYKSkpJlciIiIi+XXhezs/D7lQAMrDmTNnAAgNDTW5EhEREblWZ86cwdfX94p99CywPFitVo4ePUrlypWxWCxFuuyUlBRCQ0M5dOiQnjNWjLSfS4b2c8nQfi452tclo7j2s2EYnDlzhpCQEIcHqedFR4Dy4OTkRM2aNYt1HT4+PvrHVQK0n0uG9nPJ0H4uOdrXJaM49vPVjvxcoEHQIiIiUuEoAImIiEiFowBUwtzd3RkxYgTu7u5ml1KuaT+XDO3nkqH9XHK0r0tGadjPGgQtIiIiFY6OAImIiEiFowAkIiIiFY4CkIiIiFQ4CkAiIiJS4SgAlaDJkycTFhaGh4cHERERrFmzxuySypQxY8bQtm1bKleuTLVq1ejWrRu7du1y6HP+/HmeeuopqlSpgre3N927dycxMdGhz8GDB7n77rvx8vKiWrVqvPTSS2RlZZXkppQpY8eOxWKx8Pzzz9vbtJ+LxpEjR3j44YepUqUKnp6eNG3alHXr1tnnG4bB8OHDqV69Op6enkRFRbFnzx6HZZw6dYo+ffrg4+ODn58fjz32GKmpqSW9KaVWdnY2w4YNIzw8HE9PT+rWrcvo0aMdnhWl/Vwwv//+O126dCEkJASLxcLcuXMd5hfVft28eTM33ngjHh4ehIaG8s477xTNBhhSImbNmmW4ubkZ06dPN7Zt22YMHDjQ8PPzMxITE80urcyIjo42Pv30U2Pr1q3Gpk2bjM6dOxu1atUyUlNT7X3+9a9/GaGhoUZsbKyxbt0644YbbjDat29vn5+VlWU0adLEiIqKMjZu3GjMnz/fCAwMNIYOHWrGJpV6a9asMcLCwoxmzZoZzz33nL1d+7nwTp06ZdSuXdvo37+/sXr1auOvv/4yFi5caOzdu9feZ+zYsYavr68xd+5c488//zTuvfdeIzw83Dh37py9T6dOnYzmzZsbq1atMv73v/8Z9erVM3r37m3GJpVK//73v40qVaoYv/zyi7F//37jm2++Mby9vY0JEybY+2g/F8z8+fON1157zfj+++8NwPjhhx8c5hfFfk1OTjaCgoKMPn36GFu3bjW+/vprw9PT0/joo48KXb8CUAlp166d8dRTT9mns7OzjZCQEGPMmDEmVlW2HTt2zACM5cuXG4ZhGElJSYarq6vxzTff2Pvs2LHDAIy4uDjDMGz/YJ2cnIyEhAR7nylTphg+Pj5Genp6yW5AKXfmzBmjfv36xqJFi4ybb77ZHoC0n4vGK6+8YnTs2PGy861WqxEcHGy8++679rakpCTD3d3d+Prrrw3DMIzt27cbgLF27Vp7n19//dWwWCzGkSNHiq/4MuTuu+82Hn30UYe2+++/3+jTp49hGNrPReXSAFRU+/XDDz80/P39HX5vvPLKK0aDBg0KXbNOgZWAjIwM1q9fT1RUlL3NycmJqKgo4uLiTKysbEtOTgYgICAAgPXr15OZmemwnxs2bEitWrXs+zkuLo6mTZsSFBRk7xMdHU1KSgrbtm0rwepLv6eeeoq7777bYX+C9nNR+emnn2jTpg0PPvgg1apVo2XLlkybNs0+f//+/SQkJDjsZ19fXyIiIhz2s5+fH23atLH3iYqKwsnJidWrV5fcxpRi7du3JzY2lt27dwPw559/smLFCu666y5A+7m4FNV+jYuL46abbsLNzc3eJzo6ml27dnH69OlC1aiHoZaAEydOkJ2d7fBlABAUFMTOnTtNqqpss1qtPP/883To0IEmTZoAkJCQgJubG35+fg59g4KCSEhIsPfJ68/hwjyxmTVrFhs2bGDt2rW55mk/F42//vqLKVOmEBMTw6uvvsratWt59tlncXNzo1+/fvb9lNd+vHg/V6tWzWG+i4sLAQEB2s//GDJkCCkpKTRs2BBnZ2eys7P597//TZ8+fQC0n4tJUe3XhIQEwsPDcy3jwjx/f/8C16gAJGXSU089xdatW1mxYoXZpZQ7hw4d4rnnnmPRokV4eHiYXU65ZbVaadOmDW+99RYALVu2ZOvWrUydOpV+/fqZXF35MWfOHL766itmzpzJ9ddfz6ZNm3j++ecJCQnRfq7gdAqsBAQGBuLs7JzrKpnExESCg4NNqqrsevrpp/nll19YunQpNWvWtLcHBweTkZFBUlKSQ/+L93NwcHCefw4X5ontFNexY8do1aoVLi4uuLi4sHz5ciZOnIiLiwtBQUHaz0WgevXqNG7c2KGtUaNGHDx4EMjZT1f6vREcHMyxY8cc5mdlZXHq1Cnt53+89NJLDBkyhF69etG0aVMeeeQRXnjhBcaMGQNoPxeXotqvxfm7RAGoBLi5udG6dWtiY2PtbVarldjYWCIjI02srGwxDIOnn36aH374gSVLluQ6LNq6dWtcXV0d9vOuXbs4ePCgfT9HRkayZcsWh390ixYtwsfHJ9eXUUV1++23s2XLFjZt2mR/tWnThj59+tjfaz8XXocOHXLdxmH37t3Url0bgPDwcIKDgx32c0pKCqtXr3bYz0lJSaxfv97eZ8mSJVitViIiIkpgK0q/tLQ0nJwcv+qcnZ2xWq2A9nNxKar9GhkZye+//05mZqa9z6JFi2jQoEGhTn8Bugy+pMyaNctwd3c3ZsyYYWzfvt0YNGiQ4efn53CVjFzZE088Yfj6+hrLli0z4uPj7a+0tDR7n3/9619GrVq1jCVLlhjr1q0zIiMjjcjISPv8C5dn33nnncamTZuMBQsWGFWrVtXl2Vdx8VVghqH9XBTWrFljuLi4GP/+97+NPXv2GF999ZXh5eVlfPnll/Y+Y8eONfz8/Iwff/zR2Lx5s9G1a9c8LyNu2bKlsXr1amPFihVG/fr1K/zl2Rfr16+fUaNGDftl8N9//70RGBhovPzyy/Y+2s8Fc+bMGWPjxo3Gxo0bDcB4//33jY0bNxp///23YRhFs1+TkpKMoKAg45FHHjG2bt1qzJo1y/Dy8tJl8GXNBx98YNSqVctwc3Mz2rVrZ6xatcrsksoUIM/Xp59+au9z7tw548knnzT8/f0NLy8v47777jPi4+MdlnPgwAHjrrvuMjw9PY3AwEDjxRdfNDIzM0t4a8qWSwOQ9nPR+Pnnn40mTZoY7u7uRsOGDY2PP/7YYb7VajWGDRtmBAUFGe7u7sbtt99u7Nq1y6HPyZMnjd69exve3t6Gj4+PMWDAAOPMmTMluRmlWkpKivHcc88ZtWrVMjw8PIw6deoYr732msNl1drPBbN06dI8fyf369fPMIyi269//vmn0bFjR8Pd3d2oUaOGMXbs2CKp32IYF90OU0RERKQC0BggERERqXAUgERERKTCUQASERGRCkcBSERERCocBSARERGpcBSAREREpMJRABIREZEKRwFIRCQfli1bhsViyfUMNBEpmxSAREREpMJRABIREZEKRwFIRMoEq9XKmDFjCA8Px9PTk+bNm/Ptt98COaen5s2bR7NmzfDw8OCGG25g69atDsv47rvvuP7663F3dycsLIz33nvPYX56ejqvvPIKoaGhuLu7U69ePT755BOHPuvXr6dNmzZ4eXnRvn37XE90F5GyQQFIRMqEMWPG8PnnnzN16lS2bdvGCy+8wMMPP8zy5cvtfV566SXee+891q5dS9WqVenSpQuZmZmALbj06NGDXr16sWXLFkaOHMmwYcOYMWOG/fN9+/bl66+/ZuLEiezYsYOPPvoIb29vhzpee+013nvvPdatW4eLiwuPPvpoiWy/iBQtPQxVREq99PR0AgICWLx4MZGRkfb2xx9/nLS0NAYNGsStt97KrFmz6NmzJwCnTp2iZs2azJgxgx49etCnTx+OHz/Ob7/9Zv/8yy+/zLx589i2bRu7d++mQYMGLFq0iKioqFw1LFu2jFtvvZXFixdz++23AzB//nzuvvtuzp07h4eHRzHvBREpSjoCJCKl3t69e0lLS+OOO+7A29vb/vr888/Zt2+fvd/F4SggIIAGDRqwY8cOAHbs2EGHDh0cltuhQwf27NlDdnY2mzZtwtnZmZtvvvmKtTRr1sz+vnr16gAcO3as0NsoIiXLxewCRESuJjU1FYB58+ZRo0YNh3nu7u4OIaigPD0989XP1dXV/t5isQC28UkiUrboCJCIlHqNGzfG3d2dgwcPUq9ePYdXaGiovd+qVavs70+fPs3u3btp1KgRAI0aNWLlypUOy125ciXXXXcdzs7ONG3aFKvV6jCmSETKLx0BEpFSr3LlygwePJgXXngBq9VKx44dSU5OZuXKlfj4+FC7dm0ARo0aRZUqVQgKCuK1114jMDCQbt26AfDiiy/Stm1bRo8eTc+ePYmLi2PSpEl8+OGHAISFhdGvXz8effRRJk6cSPPmzfn77785duwYPXr0MGvTRaSYKACJSJkwevRoqlatypgxY/jrr7/w8/OjVatWvPrqq/ZTUGPHjuW5555jz549tGjRgp9//hk3NzcAWrVqxZw5cxg+fDijR4+mevXqjBo1iv79+9vXMWXKFF599VWefPJJTp48Sa1atXj11VfN2FwRKWa6CkxEyrwLV2idPn0aPz8/s8sRkTJAY4BERESkwlEAEhERkQpHp8BERESkwtERIBEREalwFIBERESkwlEAEhERkQpHAUhEREQqHAUgERERqXAUgERERKTCUQASERGRCkcBSERERCocBSARERGpcP4fHKiOcDLE8A0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.legend(['training data', 'validation data'], loc = 'upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8df502f5-7c4f-4651-8b9e-609f5fbb6074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3867 - accuracy: 0.9474\n",
      "0.9473684430122375\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test_std, Y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d291d949-257f-4997-b0ff-b9cf2989f99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bf31dc68-301b-4f68-9195-a00eef72c6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114, 2)\n",
      "[0.47770968 0.9948013 ]\n"
     ]
    }
   ],
   "source": [
    "print(Y_pred.shape)\n",
    "print(Y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1ff815f9-da67-4fbe-b6ae-56c5169bd1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.04462793 -1.41612656 -0.05903514 ... -0.18278004 -1.23064515\n",
      "  -0.6268286 ]\n",
      " [ 0.24583601 -0.06219797  0.21802678 ...  0.54129749  0.11047691\n",
      "   0.0483572 ]\n",
      " [-1.26115925 -0.29051645 -1.26499659 ... -1.35138617  0.269338\n",
      "  -0.28231213]\n",
      " ...\n",
      " [ 0.72709489  0.45836817  0.75277276 ...  1.46701686  1.19909344\n",
      "   0.65319961]\n",
      " [ 0.25437907  1.33054477  0.15659489 ... -1.29043534 -2.22561725\n",
      "  -1.59557344]\n",
      " [ 0.84100232 -0.06676434  0.8929529  ...  2.15137705  0.35629355\n",
      "   0.37459546]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cfb3d277-9cb0-434d-9e83-ac3a96320a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.77709681e-01 9.94801283e-01]\n",
      " [5.84650673e-02 9.97657537e-01]\n",
      " [1.34252614e-05 1.00000000e+00]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [1.59715101e-01 9.87370729e-01]\n",
      " [1.00000000e+00 3.41872043e-24]\n",
      " [1.43481608e-04 9.99997616e-01]\n",
      " [3.85199655e-07 1.00000000e+00]\n",
      " [2.34127219e-05 1.00000000e+00]\n",
      " [1.09652660e-06 1.00000000e+00]\n",
      " [9.99999404e-01 1.06718915e-04]\n",
      " [9.97278869e-01 8.88700724e-01]\n",
      " [6.57784760e-01 9.99785244e-01]\n",
      " [1.11246273e-01 9.99704421e-01]\n",
      " [1.98468797e-06 1.00000000e+00]\n",
      " [1.00000000e+00 4.01924757e-14]\n",
      " [1.77496855e-04 9.99999881e-01]\n",
      " [2.37221043e-09 1.00000000e+00]\n",
      " [3.57857975e-03 9.99997258e-01]\n",
      " [1.00000000e+00 9.68613553e-21]\n",
      " [7.88586249e-07 9.99991059e-01]\n",
      " [1.07737129e-07 1.00000000e+00]\n",
      " [5.06522520e-05 9.99999881e-01]\n",
      " [7.79833620e-09 1.00000000e+00]\n",
      " [7.57828238e-05 9.99997497e-01]\n",
      " [1.00000000e+00 2.93069491e-18]\n",
      " [6.16804638e-04 9.99992967e-01]\n",
      " [9.95812476e-01 6.96713209e-01]\n",
      " [1.00000000e+00 2.66363920e-17]\n",
      " [1.00000000e+00 5.51761232e-18]\n",
      " [8.71275924e-03 9.99901295e-01]\n",
      " [5.00010401e-07 1.00000000e+00]\n",
      " [2.69318491e-07 1.00000000e+00]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 4.47652784e-23]\n",
      " [7.63505341e-06 9.99999881e-01]\n",
      " [4.12266957e-07 1.00000000e+00]\n",
      " [4.49325948e-04 9.99997973e-01]\n",
      " [1.70293606e-05 1.00000000e+00]\n",
      " [6.07473612e-06 1.00000000e+00]\n",
      " [1.00000000e+00 1.37923530e-38]\n",
      " [1.00000000e+00 7.81990384e-09]\n",
      " [3.99341952e-04 1.00000000e+00]\n",
      " [1.11156604e-08 1.00000000e+00]\n",
      " [1.00000000e+00 1.17806848e-10]\n",
      " [2.56978683e-06 1.00000000e+00]\n",
      " [1.23192933e-06 1.00000000e+00]\n",
      " [9.67779190e-09 1.00000000e+00]\n",
      " [1.00000000e+00 2.33948326e-37]\n",
      " [1.00000000e+00 4.28254266e-17]\n",
      " [4.60741845e-08 1.00000000e+00]\n",
      " [1.00000000e+00 1.51795767e-08]\n",
      " [9.83548939e-01 1.32993475e-01]\n",
      " [7.95264714e-06 1.00000000e+00]\n",
      " [5.07227078e-08 1.00000000e+00]\n",
      " [9.99589503e-01 1.72664374e-02]\n",
      " [9.91336703e-01 9.68446255e-01]\n",
      " [1.09742090e-10 1.00000000e+00]\n",
      " [9.99870062e-01 1.65987171e-08]\n",
      " [1.05198453e-07 1.00000000e+00]\n",
      " [7.13731572e-02 9.98061240e-01]\n",
      " [1.00000000e+00 2.02112826e-10]\n",
      " [4.27987334e-09 1.00000000e+00]\n",
      " [1.00000000e+00 9.33747365e-22]\n",
      " [1.00000000e+00 1.54743738e-14]\n",
      " [6.72791930e-06 9.99998689e-01]\n",
      " [1.00000000e+00 4.72071149e-31]\n",
      " [1.00000000e+00 8.42084835e-15]\n",
      " [9.96702015e-01 2.31463000e-01]\n",
      " [2.81853765e-01 1.26232415e-01]\n",
      " [9.99999404e-01 9.67692770e-08]\n",
      " [1.00000000e+00 4.90735135e-19]\n",
      " [1.33044145e-08 1.00000000e+00]\n",
      " [1.00000000e+00 1.35677386e-10]\n",
      " [4.15070645e-08 1.00000000e+00]\n",
      " [1.00000000e+00 2.00389816e-09]\n",
      " [3.60857201e-04 1.00000000e+00]\n",
      " [2.97750688e-07 1.00000000e+00]\n",
      " [3.16010788e-03 9.99943137e-01]\n",
      " [1.00000000e+00 2.47948826e-08]\n",
      " [1.00000000e+00 4.36907974e-22]\n",
      " [1.00000000e+00 1.45744763e-10]\n",
      " [1.00000000e+00 4.67452172e-20]\n",
      " [1.55610138e-07 1.00000000e+00]\n",
      " [1.64723446e-07 1.00000000e+00]\n",
      " [1.36162832e-01 9.98388410e-01]\n",
      " [1.62631193e-11 1.00000000e+00]\n",
      " [1.21768329e-09 1.00000000e+00]\n",
      " [7.36581796e-06 9.99999642e-01]\n",
      " [1.00000000e+00 1.21556474e-24]\n",
      " [2.31868239e-06 1.00000000e+00]\n",
      " [1.10897068e-04 9.99998450e-01]\n",
      " [1.41116528e-11 1.00000000e+00]\n",
      " [1.00000000e+00 1.70883334e-18]\n",
      " [1.00000000e+00 1.16007026e-09]\n",
      " [4.32667591e-08 1.00000000e+00]\n",
      " [1.00000000e+00 9.66669414e-26]\n",
      " [1.00000000e+00 9.72090352e-19]\n",
      " [2.06074685e-01 9.99832749e-01]\n",
      " [2.09297195e-06 1.00000000e+00]\n",
      " [1.83112729e-06 1.00000000e+00]\n",
      " [9.99999881e-01 7.24671418e-06]\n",
      " [1.00000000e+00 2.21304515e-36]\n",
      " [1.00000000e+00 2.91037225e-34]\n",
      " [7.70322233e-02 9.99933481e-01]\n",
      " [7.70396991e-09 1.00000000e+00]\n",
      " [4.67603712e-13 1.00000000e+00]\n",
      " [2.18511698e-08 1.00000000e+00]\n",
      " [2.37274523e-12 1.00000000e+00]\n",
      " [3.47991079e-01 9.99664187e-01]\n",
      " [1.00000000e+00 2.84553653e-26]\n",
      " [1.00000000e+00 8.82574700e-30]\n",
      " [1.00000000e+00 1.11664031e-05]\n",
      " [1.00000000e+00 8.80925779e-17]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93a3414-e154-47a5-a7a5-1f33ba75b2db",
   "metadata": {},
   "source": [
    "model.predict() gives the prediction probability of each class for that data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0b3e5c01-02fb-4521-8704-db6734dd70b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25, 0.56]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#  argmax function\n",
    "\n",
    "my_list = [0.25, 0.56]\n",
    "\n",
    "index_of_max_value = np.argmax(my_list)\n",
    "print(my_list)\n",
    "print(index_of_max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5c612bba-dd48-4693-8a6d-2f3b46aee148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# converting the prediction probability to class labels\n",
    "\n",
    "Y_pred_labels = [np.argmax(i) for i in Y_pred]\n",
    "print(Y_pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad481ff3-6aeb-4c96-ba99-f8c7e0c8a00e",
   "metadata": {},
   "source": [
    "**Building the predictive system**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "355f5203-5a76-40e5-bdea-91e20373c1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "[[1.9963164e-04 9.9999976e-01]]\n",
      "[1]\n",
      "The tumor is Benign\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\wf_tf\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "input_data = (11.76,21.6,74.72,427.9,0.08637,0.04966,0.01657,0.01115,0.1495,0.05888,0.4062,1.21,2.635,28.47,0.005857,0.009758,0.01168,0.007445,0.02406,0.001769,12.98,25.72,82.98,516.5,0.1085,0.08615,0.05523,0.03715,0.2433,0.06563)\n",
    "\n",
    "# change the input_data to a numpy array\n",
    "input_data_as_numpy_array = np.asarray(input_data)\n",
    "\n",
    "# reshape the numpy array as we are predicting for one data point\n",
    "input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)\n",
    "\n",
    "# standardizing the input data\n",
    "input_data_std = scaler.transform(input_data_reshaped)\n",
    "\n",
    "prediction = model.predict(input_data_std)\n",
    "print(prediction)\n",
    "\n",
    "prediction_label = [np.argmax(prediction)]\n",
    "print(prediction_label)\n",
    "\n",
    "if(prediction_label[0] == 0):\n",
    "  print('The tumor is Malignant')\n",
    "\n",
    "else:\n",
    "  print('The tumor is Benign')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "da908259-c614-4bed-913b-99d70cd58b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 30)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe30987-e8c4-444f-9b5a-f7dff0d6181e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929e8db4-c53b-4cb4-82df-fa8bf669b2f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e7be05-94ac-4e82-9e78-bd0345e09dc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc243ca-84ed-42bc-bc99-11cb6ea9e204",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wf_tf",
   "language": "python",
   "name": "wf_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
